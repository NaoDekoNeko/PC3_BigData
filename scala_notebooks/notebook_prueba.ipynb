{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2624406b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/06/08 22:41:44 INFO SparkContext: Running Spark version 3.5.6\n",
      "25/06/08 22:41:44 INFO SparkContext: OS info Mac OS X, 15.5, aarch64\n",
      "25/06/08 22:41:44 INFO SparkContext: Java version 1.8.0_451\n",
      "25/06/08 22:41:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/08 22:41:44 INFO ResourceUtils: ==============================================================\n",
      "25/06/08 22:41:44 INFO ResourceUtils: No custom resources configured for spark.driver.\n",
      "25/06/08 22:41:44 INFO ResourceUtils: ==============================================================\n",
      "25/06/08 22:41:44 INFO SparkContext: Submitted application: PostgreSQL-Notebook\n",
      "25/06/08 22:41:44 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)\n",
      "25/06/08 22:41:44 INFO ResourceProfile: Limiting resource is cpu\n",
      "25/06/08 22:41:44 INFO ResourceProfileManager: Added ResourceProfile id: 0\n",
      "25/06/08 22:41:44 INFO SecurityManager: Changing view acls to: naodeko\n",
      "25/06/08 22:41:44 INFO SecurityManager: Changing modify acls to: naodeko\n",
      "25/06/08 22:41:44 INFO SecurityManager: Changing view acls groups to: \n",
      "25/06/08 22:41:44 INFO SecurityManager: Changing modify acls groups to: \n",
      "25/06/08 22:41:44 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: naodeko; groups with view permissions: EMPTY; users with modify permissions: naodeko; groups with modify permissions: EMPTY\n",
      "25/06/08 22:41:45 INFO Utils: Successfully started service 'sparkDriver' on port 57343.\n",
      "25/06/08 22:41:45 INFO SparkEnv: Registering MapOutputTracker\n",
      "25/06/08 22:41:45 INFO SparkEnv: Registering BlockManagerMaster\n",
      "25/06/08 22:41:45 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\n",
      "25/06/08 22:41:45 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\n",
      "25/06/08 22:41:45 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "25/06/08 22:41:45 INFO DiskBlockManager: Created local directory at /private/var/folders/m_/_6wk_nxd4xv00ts1kyyz4r3c0000gn/T/blockmgr-0c5a051e-3bb7-476c-a0cc-a9527e7a6f6c\n",
      "25/06/08 22:41:45 INFO MemoryStore: MemoryStore started with capacity 2004.6 MiB\n",
      "25/06/08 22:41:45 INFO SparkEnv: Registering OutputCommitCoordinator\n",
      "25/06/08 22:41:45 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI\n",
      "25/06/08 22:41:45 INFO Utils: Successfully started service 'SparkUI' on port 4040.\n",
      "25/06/08 22:41:45 INFO Executor: Starting executor ID driver on host 192.168.18.245\n",
      "25/06/08 22:41:45 INFO Executor: OS info Mac OS X, 15.5, aarch64\n",
      "25/06/08 22:41:45 INFO Executor: Java version 1.8.0_451\n",
      "25/06/08 22:41:45 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''\n",
      "25/06/08 22:41:45 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@7f0b1c77 for default.\n",
      "25/06/08 22:41:45 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57344.\n",
      "25/06/08 22:41:45 INFO NettyBlockTransferService: Server created on 192.168.18.245:57344\n",
      "25/06/08 22:41:45 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\n",
      "25/06/08 22:41:45 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.18.245, 57344, None)\n",
      "25/06/08 22:41:45 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.18.245:57344 with 2004.6 MiB RAM, BlockManagerId(driver, 192.168.18.245, 57344, None)\n",
      "25/06/08 22:41:45 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.18.245, 57344, None)\n",
      "25/06/08 22:41:45 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.18.245, 57344, None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Spark configurado y listo para conectar con PostgreSQL\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.SparkSession\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.{DataFrame, SaveMode}\u001b[39m\n",
       "\u001b[36mspark\u001b[39m: \u001b[32mSparkSession\u001b[39m = org.apache.spark.sql.SparkSession@646da869\n",
       "\u001b[32mimport \u001b[39m\u001b[36mspark.implicits._\u001b[39m\n",
       "\u001b[36mjdbcUrl\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"jdbc:postgresql://localhost:5432/postgres\"\u001b[39m\n",
       "\u001b[36mconnectionProperties\u001b[39m: \u001b[32mjava\u001b[39m.\u001b[32mutil\u001b[39m.\u001b[32mProperties\u001b[39m = {user=postgres, password=postgres, driver=org.postgresql.Driver}\n",
       "\u001b[36mres1_9\u001b[39m: \u001b[32mObject\u001b[39m = \u001b[32mnull\u001b[39m\n",
       "\u001b[36mres1_10\u001b[39m: \u001b[32mObject\u001b[39m = \u001b[32mnull\u001b[39m\n",
       "\u001b[36mres1_11\u001b[39m: \u001b[32mObject\u001b[39m = \u001b[32mnull\u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`org.apache.spark::spark-sql:3.5.6`\n",
    "import $ivy.`org.apache.spark::spark-core:3.5.6`\n",
    "import $ivy.`org.postgresql:postgresql:42.7.3`  // Driver JDBC de PostgreSQL\n",
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.sql.{DataFrame, SaveMode}\n",
    "\n",
    "val spark = SparkSession.builder()\n",
    "  .appName(\"PostgreSQL-Notebook\")\n",
    "  .master(\"local[*]\")\n",
    "  .config(\"spark.sql.adaptive.enabled\", \"true\")\n",
    "  .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\")\n",
    "  .getOrCreate()\n",
    "\n",
    "import spark.implicits._\n",
    "\n",
    "// Configuración de conexión a PostgreSQL\n",
    "val jdbcUrl = \"jdbc:postgresql://localhost:5432/postgres\"\n",
    "val connectionProperties = new java.util.Properties()\n",
    "connectionProperties.setProperty(\"user\", \"postgres\")\n",
    "connectionProperties.setProperty(\"password\", \"postgres\")\n",
    "connectionProperties.setProperty(\"driver\", \"org.postgresql.Driver\")\n",
    "\n",
    "println(\"✅ Spark configurado y listo para conectar con PostgreSQL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1325d946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Funciones de PostgreSQL definidas\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mleerTablaPostgres\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mescribirTablaPostgres\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mejecutarQuery\u001b[39m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Función para leer tabla desde PostgreSQL\n",
    "def leerTablaPostgres(tableName: String): DataFrame = {\n",
    "  spark.read\n",
    "    .jdbc(jdbcUrl, tableName, connectionProperties)\n",
    "}\n",
    "\n",
    "// Función para escribir DataFrame a PostgreSQL\n",
    "def escribirTablaPostgres(df: DataFrame, tableName: String, mode: SaveMode = SaveMode.Overwrite): Unit = {\n",
    "  df.write\n",
    "    .mode(mode)\n",
    "    .jdbc(jdbcUrl, tableName, connectionProperties)\n",
    "}\n",
    "\n",
    "// Función para ejecutar query SQL directamente\n",
    "def ejecutarQuery(query: String): DataFrame = {\n",
    "  spark.read\n",
    "    .format(\"jdbc\")\n",
    "    .option(\"url\", jdbcUrl)\n",
    "    .option(\"query\", query)\n",
    "    .option(\"user\", \"postgres\")\n",
    "    .option(\"password\", \"postgres\")\n",
    "    .option(\"driver\", \"org.postgresql.Driver\")\n",
    "    .load()\n",
    "}\n",
    "\n",
    "println(\"🔧 Funciones de PostgreSQL definidas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a36ab6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/08 22:41:46 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.\n",
      "25/06/08 22:41:46 INFO SharedState: Warehouse path is 'file:/Users/naodeko/uni/bigdata/scala_notebooks/scala_notebooks/spark-warehouse'.\n",
      "25/06/08 22:41:47 INFO CodeGenerator: Code generated in 87.904084 ms\n",
      "25/06/08 22:41:47 INFO DAGScheduler: Registering RDD 2 (count at cmd3.sc:16) as input to shuffle 0\n",
      "25/06/08 22:41:47 INFO DAGScheduler: Got map stage job 0 (count at cmd3.sc:16) with 1 output partitions\n",
      "25/06/08 22:41:47 INFO DAGScheduler: Final stage: ShuffleMapStage 0 (count at cmd3.sc:16)\n",
      "25/06/08 22:41:47 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/06/08 22:41:47 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/08 22:41:47 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at count at cmd3.sc:16), which has no missing parents\n",
      "25/06/08 22:41:47 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 13.8 KiB, free 2004.6 MiB)\n",
      "25/06/08 22:41:47 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 2004.6 MiB)\n",
      "25/06/08 22:41:47 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.18.245:57344 (size: 7.2 KiB, free: 2004.6 MiB)\n",
      "25/06/08 22:41:47 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1611\n",
      "25/06/08 22:41:47 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at count at cmd3.sc:16) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/08 22:41:47 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0\n",
      "25/06/08 22:41:47 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (192.168.18.245, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) \n",
      "25/06/08 22:41:47 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)\n",
      "25/06/08 22:41:47 INFO CodeGenerator: Code generated in 5.9285 ms\n",
      "25/06/08 22:41:47 INFO JDBCRDD: closed connection\n",
      "25/06/08 22:41:47 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1973 bytes result sent to driver\n",
      "25/06/08 22:41:47 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 178 ms on 192.168.18.245 (executor driver) (1/1)\n",
      "25/06/08 22:41:47 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool \n",
      "25/06/08 22:41:47 INFO DAGScheduler: ShuffleMapStage 0 (count at cmd3.sc:16) finished in 0.265 s\n",
      "25/06/08 22:41:47 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/06/08 22:41:47 INFO DAGScheduler: running: Set()\n",
      "25/06/08 22:41:47 INFO DAGScheduler: waiting: Set()\n",
      "25/06/08 22:41:47 INFO DAGScheduler: failed: Set()\n",
      "25/06/08 22:41:47 INFO CodeGenerator: Code generated in 6.150458 ms\n",
      "25/06/08 22:41:47 INFO SparkContext: Starting job: count at cmd3.sc:16\n",
      "25/06/08 22:41:47 INFO DAGScheduler: Got job 1 (count at cmd3.sc:16) with 1 output partitions\n",
      "25/06/08 22:41:47 INFO DAGScheduler: Final stage: ResultStage 2 (count at cmd3.sc:16)\n",
      "25/06/08 22:41:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)\n",
      "25/06/08 22:41:47 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/08 22:41:47 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[5] at count at cmd3.sc:16), which has no missing parents\n",
      "25/06/08 22:41:48 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 12.5 KiB, free 2004.6 MiB)\n",
      "25/06/08 22:41:48 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 2004.6 MiB)\n",
      "25/06/08 22:41:48 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.18.245:57344 (size: 5.9 KiB, free: 2004.6 MiB)\n",
      "25/06/08 22:41:48 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1611\n",
      "25/06/08 22:41:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[5] at count at cmd3.sc:16) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/08 22:41:48 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0\n",
      "25/06/08 22:41:48 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 1) (192.168.18.245, executor driver, partition 0, NODE_LOCAL, 8999 bytes) \n",
      "25/06/08 22:41:48 INFO Executor: Running task 0.0 in stage 2.0 (TID 1)\n",
      "25/06/08 22:41:48 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:41:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms\n",
      "25/06/08 22:41:48 INFO CodeGenerator: Code generated in 7.727417 ms\n",
      "25/06/08 22:41:48 INFO Executor: Finished task 0.0 in stage 2.0 (TID 1). 4038 bytes result sent to driver\n",
      "25/06/08 22:41:48 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 1) in 64 ms on 192.168.18.245 (executor driver) (1/1)\n",
      "25/06/08 22:41:48 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool \n",
      "25/06/08 22:41:48 INFO DAGScheduler: ResultStage 2 (count at cmd3.sc:16) finished in 0.072 s\n",
      "25/06/08 22:41:48 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/06/08 22:41:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished\n",
      "25/06/08 22:41:48 INFO DAGScheduler: Job 1 finished: count at cmd3.sc:16, took 0.081056 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Registros en la tabla: 220832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/08 22:41:48 INFO CodeGenerator: Code generated in 34.745458 ms\n",
      "25/06/08 22:41:48 INFO SparkContext: Starting job: show at cmd3.sc:17\n",
      "25/06/08 22:41:48 INFO DAGScheduler: Got job 2 (show at cmd3.sc:17) with 1 output partitions\n",
      "25/06/08 22:41:48 INFO DAGScheduler: Final stage: ResultStage 3 (show at cmd3.sc:17)\n",
      "25/06/08 22:41:48 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/06/08 22:41:48 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/08 22:41:48 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[8] at show at cmd3.sc:17), which has no missing parents\n",
      "25/06/08 22:41:48 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 18.9 KiB, free 2004.5 MiB)\n",
      "25/06/08 22:41:48 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 2004.5 MiB)\n",
      "25/06/08 22:41:48 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.18.245:57344 (size: 7.6 KiB, free: 2004.6 MiB)\n",
      "25/06/08 22:41:48 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1611\n",
      "25/06/08 22:41:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[8] at show at cmd3.sc:17) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/08 22:41:48 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0\n",
      "25/06/08 22:41:48 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (192.168.18.245, executor driver, partition 0, PROCESS_LOCAL, 8845 bytes) \n",
      "25/06/08 22:41:48 INFO Executor: Running task 0.0 in stage 3.0 (TID 2)\n",
      "25/06/08 22:41:48 INFO CodeGenerator: Code generated in 15.907417 ms\n",
      "25/06/08 22:41:48 INFO JDBCRDD: closed connection\n",
      "25/06/08 22:41:48 INFO Executor: Finished task 0.0 in stage 3.0 (TID 2). 2916 bytes result sent to driver\n",
      "25/06/08 22:41:48 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 187 ms on 192.168.18.245 (executor driver) (1/1)\n",
      "25/06/08 22:41:48 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool \n",
      "25/06/08 22:41:48 INFO DAGScheduler: ResultStage 3 (show at cmd3.sc:17) finished in 0.196 s\n",
      "25/06/08 22:41:48 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/06/08 22:41:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished\n",
      "25/06/08 22:41:48 INFO DAGScheduler: Job 2 finished: show at cmd3.sc:17, took 0.199076 s\n",
      "25/06/08 22:41:48 INFO CodeGenerator: Code generated in 14.440958 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+--------------------+--------------------+--------------------+---------------------+-------------------+---------------+----------------------+--------------------+-----------------------------+------------------------+-----------------------------------------+----------------------------+------------+---------+----------+---------+\n",
      "|fecha_corte|periodo|   cod_contribuyente|   nom_contribuyente|          cod_predio|porcentaje_condominio|monto_parque_jardin|monto_serenazgo|monto_residuos_solidos|monto_barrido_calles|descuento_tope__parque_jardin|descuento_tope_serenazgo|descuento_tope_recoleccion_residuo_solido|descuento_tope_barrido_calle|departamento|provincia|  distrito|   ubigeo|\n",
      "+-----------+-------+--------------------+--------------------+--------------------+---------------------+-------------------+---------------+----------------------+--------------------+-----------------------------+------------------------+-----------------------------------------+----------------------------+------------+---------+----------+---------+\n",
      "|   20250424|   2025|1185ae73bff8b13e1...|7e20d48ae503eb211...|31b23941576ec8133...|               100.00|             272.40|         333.36|                112.44|                8.04|                         0.00|                    0.00|                                    54.84|                        0.00|        LIMA|     LIMA|JESUS MARI|150113.00|\n",
      "|   20250424|   2025|8d8953f65b09e4c51...|07b1cb4052aa5504b...|de7e62336bccc0dec...|               100.00|             272.40|         333.36|                 78.36|                5.52|                         0.00|                    0.00|                                    20.76|                        0.00|        LIMA|     LIMA|JESUS MARI|150113.00|\n",
      "|   20250424|   2025|4ae0fb6f97d77457c...|ad1dea02c10f5c000...|b2af184aede6135bb...|               100.00|             272.40|         333.36|                 96.96|                6.96|                         0.00|                    0.00|                                    39.36|                        0.00|        LIMA|     LIMA|JESUS MARI|150113.00|\n",
      "|   20250424|   2025|c2b54eb47f53d21f8...|d3f1dbf145de05357...|8b976a451189da8a6...|               100.00|             272.40|         333.36|                113.40|                8.04|                         0.00|                    0.00|                                    55.80|                        0.00|        LIMA|     LIMA|JESUS MARI|150113.00|\n",
      "|   20250424|   2025|23e90633bf8fc6a60...|66712d322d45b9c4b...|01f957edc47e19d6e...|               100.00|             272.40|         333.36|                 96.96|                6.96|                         0.00|                    0.00|                                    39.36|                        0.00|        LIMA|     LIMA|JESUS MARI|150113.00|\n",
      "+-----------+-------+--------------------+--------------------+--------------------+---------------------+-------------------+---------------+----------------------+--------------------+-----------------------------+------------------------+-----------------------------------------+----------------------------+------------+---------+----------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Probar la conexión\n",
    "try {\n",
    "  /*\n",
    "  // Listar todas las tablas\n",
    "  val tablas = ejecutarQuery(\"\"\"\n",
    "    SELECT table_name \n",
    "    FROM information_schema.tables \n",
    "    WHERE table_schema = 'public'\n",
    "  \"\"\")\n",
    "  \n",
    "  println(\"📋 Tablas disponibles en PostgreSQL:\")\n",
    "  tablas.show()\n",
    "  */\n",
    "  \n",
    "  val miTabla = leerTablaPostgres(\"arbitrios_jm\")\n",
    "  println(s\"📊 Registros en la tabla: ${miTabla.count()}\")\n",
    "  miTabla.show(5)\n",
    "  \n",
    "} catch {\n",
    "  case e: Exception => \n",
    "    println(s\"❌ Error conectando a PostgreSQL: ${e.getMessage}\")\n",
    "    println(\"🔍 Verifica que PostgreSQL esté ejecutándose y las credenciales sean correctas\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77721e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/08 22:41:48 INFO DAGScheduler: Registering RDD 11 (count at cmd4.sc:4) as input to shuffle 1\n",
      "25/06/08 22:41:48 INFO DAGScheduler: Got map stage job 3 (count at cmd4.sc:4) with 1 output partitions\n",
      "25/06/08 22:41:48 INFO DAGScheduler: Final stage: ShuffleMapStage 4 (count at cmd4.sc:4)\n",
      "25/06/08 22:41:48 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/06/08 22:41:48 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/08 22:41:48 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[11] at count at cmd4.sc:4), which has no missing parents\n",
      "25/06/08 22:41:48 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 13.8 KiB, free 2004.6 MiB)\n",
      "25/06/08 22:41:48 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 2004.6 MiB)\n",
      "25/06/08 22:41:48 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.18.245:57344 (size: 7.2 KiB, free: 2004.6 MiB)\n",
      "25/06/08 22:41:48 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1611\n",
      "25/06/08 22:41:48 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[11] at count at cmd4.sc:4) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/08 22:41:48 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0\n",
      "25/06/08 22:41:48 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 3) (192.168.18.245, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) \n",
      "25/06/08 22:41:48 INFO Executor: Running task 0.0 in stage 4.0 (TID 3)\n",
      "25/06/08 22:41:48 INFO JDBCRDD: closed connection\n",
      "25/06/08 22:41:48 INFO Executor: Finished task 0.0 in stage 4.0 (TID 3). 1887 bytes result sent to driver\n",
      "25/06/08 22:41:48 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 3) in 61 ms on 192.168.18.245 (executor driver) (1/1)\n",
      "25/06/08 22:41:48 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool \n",
      "25/06/08 22:41:48 INFO DAGScheduler: ShuffleMapStage 4 (count at cmd4.sc:4) finished in 0.068 s\n",
      "25/06/08 22:41:48 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/06/08 22:41:48 INFO DAGScheduler: running: Set()\n",
      "25/06/08 22:41:48 INFO DAGScheduler: waiting: Set()\n",
      "25/06/08 22:41:48 INFO DAGScheduler: failed: Set()\n",
      "25/06/08 22:41:48 INFO SparkContext: Starting job: count at cmd4.sc:4\n",
      "25/06/08 22:41:48 INFO DAGScheduler: Got job 4 (count at cmd4.sc:4) with 1 output partitions\n",
      "25/06/08 22:41:48 INFO DAGScheduler: Final stage: ResultStage 6 (count at cmd4.sc:4)\n",
      "25/06/08 22:41:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)\n",
      "25/06/08 22:41:48 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/08 22:41:48 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[14] at count at cmd4.sc:4), which has no missing parents\n",
      "25/06/08 22:41:48 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 12.5 KiB, free 2004.6 MiB)\n",
      "25/06/08 22:41:48 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 2004.6 MiB)\n",
      "25/06/08 22:41:48 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.18.245:57344 (size: 5.9 KiB, free: 2004.6 MiB)\n",
      "25/06/08 22:41:48 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1611\n",
      "25/06/08 22:41:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[14] at count at cmd4.sc:4) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/08 22:41:48 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0\n",
      "25/06/08 22:41:48 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 4) (192.168.18.245, executor driver, partition 0, NODE_LOCAL, 8999 bytes) \n",
      "25/06/08 22:41:48 INFO Executor: Running task 0.0 in stage 6.0 (TID 4)\n",
      "25/06/08 22:41:48 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:41:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms\n",
      "25/06/08 22:41:48 INFO Executor: Finished task 0.0 in stage 6.0 (TID 4). 3995 bytes result sent to driver\n",
      "25/06/08 22:41:48 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 4) in 33 ms on 192.168.18.245 (executor driver) (1/1)\n",
      "25/06/08 22:41:48 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool \n",
      "25/06/08 22:41:48 INFO DAGScheduler: ResultStage 6 (count at cmd4.sc:4) finished in 0.040 s\n",
      "25/06/08 22:41:48 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/06/08 22:41:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished\n",
      "25/06/08 22:41:48 INFO DAGScheduler: Job 4 finished: count at cmd4.sc:4, took 0.041923 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Registros en la tabla: 220832\n",
      "✅ Vista temporal 'arbitrios_jm' creada\n",
      "🔧 Funciones importadas y listas para MapReduce\n"
     ]
    }
   ],
   "source": [
    "// PASO 1: Cargar datos y crear vista temporal\n",
    "try {\n",
    "  val miTabla = leerTablaPostgres(\"arbitrios_jm\")\n",
    "  println(s\"📊 Registros en la tabla: ${miTabla.count()}\")\n",
    "  \n",
    "  // Crear vista temporal para usar con spark.sql()\n",
    "  miTabla.createOrReplaceTempView(\"arbitrios_jm\")\n",
    "  println(\"✅ Vista temporal 'arbitrios_jm' creada\")\n",
    "  \n",
    "  // Importar funciones necesarias\n",
    "  import org.apache.spark.sql.functions._\n",
    "  import org.apache.spark.sql.expressions.Window\n",
    "  \n",
    "  println(\"🔧 Funciones importadas y listas para MapReduce\")\n",
    "  \n",
    "} catch {\n",
    "  case e: Exception => \n",
    "    println(s\"❌ Error: ${e.getMessage}\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e0a81cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 CONSULTA 1: MapReduce - Montos totales por contribuyente\n",
      "📊 Resultado Consulta 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/08 22:41:49 INFO CodeGenerator: Code generated in 29.585958 ms\n",
      "25/06/08 22:41:49 INFO DAGScheduler: Registering RDD 17 (show at cmd5.sc:33) as input to shuffle 2\n",
      "25/06/08 22:41:49 INFO DAGScheduler: Got map stage job 5 (show at cmd5.sc:33) with 1 output partitions\n",
      "25/06/08 22:41:49 INFO DAGScheduler: Final stage: ShuffleMapStage 7 (show at cmd5.sc:33)\n",
      "25/06/08 22:41:49 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/06/08 22:41:49 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/08 22:41:49 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[17] at show at cmd5.sc:33), which has no missing parents\n",
      "25/06/08 22:41:49 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 54.5 KiB, free 2004.5 MiB)\n",
      "25/06/08 22:41:49 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 23.2 KiB, free 2004.5 MiB)\n",
      "25/06/08 22:41:49 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.18.245:57344 (size: 23.2 KiB, free: 2004.6 MiB)\n",
      "25/06/08 22:41:49 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1611\n",
      "25/06/08 22:41:49 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[17] at show at cmd5.sc:33) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/08 22:41:49 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0\n",
      "25/06/08 22:41:49 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 5) (192.168.18.245, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) \n",
      "25/06/08 22:41:49 INFO Executor: Running task 0.0 in stage 7.0 (TID 5)\n",
      "25/06/08 22:41:49 INFO CodeGenerator: Code generated in 39.170542 ms\n",
      "25/06/08 22:41:49 INFO CodeGenerator: Code generated in 6.832084 ms\n",
      "25/06/08 22:41:49 INFO CodeGenerator: Code generated in 3.127041 ms\n",
      "25/06/08 22:41:49 INFO CodeGenerator: Code generated in 5.94525 ms\n",
      "25/06/08 22:41:49 INFO CodeGenerator: Code generated in 3.036708 ms\n",
      "25/06/08 22:41:49 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 192.168.18.245:57344 in memory (size: 7.2 KiB, free: 2004.6 MiB)\n",
      "25/06/08 22:41:49 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 192.168.18.245:57344 in memory (size: 5.9 KiB, free: 2004.6 MiB)\n",
      "25/06/08 22:41:49 INFO JDBCRDD: closed connection\n",
      "25/06/08 22:41:49 INFO Executor: Finished task 0.0 in stage 7.0 (TID 5). 2493 bytes result sent to driver\n",
      "25/06/08 22:41:49 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 5) in 454 ms on 192.168.18.245 (executor driver) (1/1)\n",
      "25/06/08 22:41:49 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool \n",
      "25/06/08 22:41:49 INFO DAGScheduler: ShuffleMapStage 7 (show at cmd5.sc:33) finished in 0.463 s\n",
      "25/06/08 22:41:49 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/06/08 22:41:49 INFO DAGScheduler: running: Set()\n",
      "25/06/08 22:41:49 INFO DAGScheduler: waiting: Set()\n",
      "25/06/08 22:41:49 INFO DAGScheduler: failed: Set()\n",
      "25/06/08 22:41:49 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "25/06/08 22:41:50 INFO CodeGenerator: Code generated in 6.265458 ms\n",
      "25/06/08 22:41:50 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.\n",
      "25/06/08 22:41:50 INFO CodeGenerator: Code generated in 8.741709 ms\n",
      "25/06/08 22:41:50 INFO SparkContext: Starting job: show at cmd5.sc:33\n",
      "25/06/08 22:41:50 INFO DAGScheduler: Got job 6 (show at cmd5.sc:33) with 3 output partitions\n",
      "25/06/08 22:41:50 INFO DAGScheduler: Final stage: ResultStage 9 (show at cmd5.sc:33)\n",
      "25/06/08 22:41:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)\n",
      "25/06/08 22:41:50 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/08 22:41:50 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[21] at show at cmd5.sc:33), which has no missing parents\n",
      "25/06/08 22:41:50 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 192.168.18.245:57344 in memory (size: 23.2 KiB, free: 2004.6 MiB)\n",
      "25/06/08 22:41:50 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 61.2 KiB, free 2004.5 MiB)\n",
      "25/06/08 22:41:50 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 25.6 KiB, free 2004.5 MiB)\n",
      "25/06/08 22:41:50 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 192.168.18.245:57344 (size: 25.6 KiB, free: 2004.6 MiB)\n",
      "25/06/08 22:41:50 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1611\n",
      "25/06/08 22:41:50 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 9 (MapPartitionsRDD[21] at show at cmd5.sc:33) (first 15 tasks are for partitions Vector(0, 1, 2))\n",
      "25/06/08 22:41:50 INFO TaskSchedulerImpl: Adding task set 9.0 with 3 tasks resource profile 0\n",
      "25/06/08 22:41:50 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 6) (192.168.18.245, executor driver, partition 0, NODE_LOCAL, 8999 bytes) \n",
      "25/06/08 22:41:50 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 7) (192.168.18.245, executor driver, partition 1, NODE_LOCAL, 8999 bytes) \n",
      "25/06/08 22:41:50 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 8) (192.168.18.245, executor driver, partition 2, NODE_LOCAL, 8999 bytes) \n",
      "25/06/08 22:41:50 INFO Executor: Running task 0.0 in stage 9.0 (TID 6)\n",
      "25/06/08 22:41:50 INFO Executor: Running task 2.0 in stage 9.0 (TID 8)\n",
      "25/06/08 22:41:50 INFO Executor: Running task 1.0 in stage 9.0 (TID 7)\n",
      "25/06/08 22:41:50 INFO CodeGenerator: Code generated in 4.911709 ms\n",
      "25/06/08 22:41:50 INFO ShuffleBlockFetcherIterator: Getting 1 (1034.1 KiB) non-empty blocks including 1 (1034.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:41:50 INFO ShuffleBlockFetcherIterator: Getting 1 (1024.2 KiB) non-empty blocks including 1 (1024.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:41:50 INFO ShuffleBlockFetcherIterator: Getting 1 (1769.5 KiB) non-empty blocks including 1 (1769.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:41:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:41:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:41:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:41:50 INFO CodeGenerator: Code generated in 7.559667 ms\n",
      "25/06/08 22:41:50 INFO Executor: Finished task 0.0 in stage 9.0 (TID 6). 6373 bytes result sent to driver\n",
      "25/06/08 22:41:50 INFO Executor: Finished task 1.0 in stage 9.0 (TID 7). 6373 bytes result sent to driver\n",
      "25/06/08 22:41:50 INFO Executor: Finished task 2.0 in stage 9.0 (TID 8). 6373 bytes result sent to driver\n",
      "25/06/08 22:41:50 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 6) in 91 ms on 192.168.18.245 (executor driver) (1/3)\n",
      "25/06/08 22:41:50 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 7) in 92 ms on 192.168.18.245 (executor driver) (2/3)\n",
      "25/06/08 22:41:50 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 8) in 91 ms on 192.168.18.245 (executor driver) (3/3)\n",
      "25/06/08 22:41:50 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool \n",
      "25/06/08 22:41:50 INFO DAGScheduler: ResultStage 9 (show at cmd5.sc:33) finished in 0.102 s\n",
      "25/06/08 22:41:50 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/06/08 22:41:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished\n",
      "25/06/08 22:41:50 INFO DAGScheduler: Job 6 finished: show at cmd5.sc:33, took 0.119438 s\n",
      "25/06/08 22:41:50 INFO CodeGenerator: Code generated in 4.75525 ms\n",
      "25/06/08 22:41:50 INFO CodeGenerator: Code generated in 2.718917 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+-----------+------------------+-------------------+--------------+\n",
      "|   cod_contribuyente|  distrito|num_predios|       monto_total|promedio_condominio|ultimo_periodo|\n",
      "+--------------------+----------+-----------+------------------+-------------------+--------------+\n",
      "|55351ada81c0f27f8...|JESUS MARI|        599| 963183.3599999999|              100.0|          2025|\n",
      "|8b23a5f47f37eaa52...|JESUS MARI|         33|         739913.52|              100.0|          2025|\n",
      "|39ed9d9016f301c73...|JESUS MARI|        368| 593574.1200000013|              100.0|          2025|\n",
      "|9e17ffa1e26b269ea...|JESUS MARI|        201| 364319.6400000001|              100.0|          2025|\n",
      "|c7d7cd94d59a8b17c...|JESUS MARI|        147|339312.60000000003|              100.0|          2025|\n",
      "|139af841d2e577a63...|JESUS MARI|        414| 320959.0800000003|              100.0|          2025|\n",
      "|2a0199bb8f20b9035...|JESUS MARI|         19|304931.16000000003|              100.0|          2025|\n",
      "|2119b2fb48bfa34d8...|JESUS MARI|         11|         295865.64|              100.0|          2025|\n",
      "|e50b873fbaacca239...|JESUS MARI|         12|283900.07999999996|              100.0|          2025|\n",
      "|76186f0fef1d04e20...|JESUS MARI|        353| 251863.9600000001|  6.161444759206798|          2025|\n",
      "+--------------------+----------+-----------+------------------+-------------------+--------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.functions._\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.expressions.Window\u001b[39m\n",
       "\u001b[36mdf\u001b[39m: \u001b[32mDataFrame\u001b[39m = [fecha_corte: int, periodo: int ... 16 more fields]\n",
       "\u001b[36mmapped1\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mDataset\u001b[39m[\u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mRow\u001b[39m] = [cod_contribuyente: string, distrito: string ... 3 more fields]\n",
       "\u001b[36mreduced1\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mDataset\u001b[39m[\u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mRow\u001b[39m] = [cod_contribuyente: string, distrito: string ... 4 more fields]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// CONSULTA 1: MapReduce - Montos totales por contribuyente\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.expressions.Window\n",
    "\n",
    "println(\"🔍 CONSULTA 1: MapReduce - Montos totales por contribuyente\")\n",
    "\n",
    "val df = spark.table(\"arbitrios_jm\")\n",
    "\n",
    "// MapReduce 1: Map - Calcular monto total por registro\n",
    "val mapped1 = df.select(\n",
    "  col(\"cod_contribuyente\"),\n",
    "  col(\"distrito\"),\n",
    "  col(\"periodo\"),\n",
    "  (col(\"monto_parque_jardin\").cast(\"double\") + \n",
    "   col(\"monto_serenazgo\").cast(\"double\") + \n",
    "   col(\"monto_residuos_solidos\").cast(\"double\") + \n",
    "   col(\"monto_barrido_calles\").cast(\"double\")).as(\"monto_total_registro\"),\n",
    "  col(\"porcentaje_condominio\").cast(\"double\").as(\"porcentaje\")\n",
    ").filter(col(\"monto_parque_jardin\").isNotNull)\n",
    "\n",
    "// Reduce 1: Agrupar por contribuyente\n",
    "val reduced1 = mapped1.groupBy(\"cod_contribuyente\", \"distrito\")\n",
    "  .agg(\n",
    "    count(\"*\").as(\"num_predios\"),\n",
    "    sum(\"monto_total_registro\").as(\"monto_total\"),\n",
    "    avg(\"porcentaje\").as(\"promedio_condominio\"),\n",
    "    max(\"periodo\").as(\"ultimo_periodo\")\n",
    "  )\n",
    "  .orderBy(desc(\"monto_total\"))\n",
    "  .limit(10)\n",
    "\n",
    "println(\"📊 Resultado Consulta 1:\")\n",
    "reduced1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9db51edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 CONSULTA 2: MapReduce - Análisis por distrito y período\n",
      "📊 Resultado Consulta 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/08 22:41:50 INFO CodeGenerator: Code generated in 21.797042 ms\n",
      "25/06/08 22:41:50 INFO DAGScheduler: Registering RDD 24 (show at cmd6.sc:30) as input to shuffle 3\n",
      "25/06/08 22:41:50 INFO DAGScheduler: Got map stage job 7 (show at cmd6.sc:30) with 1 output partitions\n",
      "25/06/08 22:41:50 INFO DAGScheduler: Final stage: ShuffleMapStage 10 (show at cmd6.sc:30)\n",
      "25/06/08 22:41:50 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/06/08 22:41:50 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/08 22:41:50 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[24] at show at cmd6.sc:30), which has no missing parents\n",
      "25/06/08 22:41:50 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 56.4 KiB, free 2004.5 MiB)\n",
      "25/06/08 22:41:50 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 23.4 KiB, free 2004.4 MiB)\n",
      "25/06/08 22:41:50 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 192.168.18.245:57344 (size: 23.4 KiB, free: 2004.6 MiB)\n",
      "25/06/08 22:41:50 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1611\n",
      "25/06/08 22:41:50 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[24] at show at cmd6.sc:30) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/08 22:41:50 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0\n",
      "25/06/08 22:41:50 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 9) (192.168.18.245, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) \n",
      "25/06/08 22:41:50 INFO Executor: Running task 0.0 in stage 10.0 (TID 9)\n",
      "25/06/08 22:41:50 INFO CodeGenerator: Code generated in 18.303416 ms\n",
      "25/06/08 22:41:50 INFO CodeGenerator: Code generated in 5.347208 ms\n",
      "25/06/08 22:41:50 INFO CodeGenerator: Code generated in 1.88425 ms\n",
      "25/06/08 22:41:50 INFO CodeGenerator: Code generated in 2.324166 ms\n",
      "25/06/08 22:41:50 INFO CodeGenerator: Code generated in 13.376875 ms\n",
      "25/06/08 22:41:50 INFO JDBCRDD: closed connection\n",
      "25/06/08 22:41:50 INFO Executor: Finished task 0.0 in stage 10.0 (TID 9). 2506 bytes result sent to driver\n",
      "25/06/08 22:41:50 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 9) in 238 ms on 192.168.18.245 (executor driver) (1/1)\n",
      "25/06/08 22:41:50 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool \n",
      "25/06/08 22:41:50 INFO DAGScheduler: ShuffleMapStage 10 (show at cmd6.sc:30) finished in 0.243 s\n",
      "25/06/08 22:41:50 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/06/08 22:41:50 INFO DAGScheduler: running: Set()\n",
      "25/06/08 22:41:50 INFO DAGScheduler: waiting: Set()\n",
      "25/06/08 22:41:50 INFO DAGScheduler: failed: Set()\n",
      "25/06/08 22:41:50 INFO ShufflePartitionsUtil: For shuffle(3), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "25/06/08 22:41:50 INFO CodeGenerator: Code generated in 3.273833 ms\n",
      "25/06/08 22:41:50 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.\n",
      "25/06/08 22:41:50 INFO CodeGenerator: Code generated in 7.616584 ms\n",
      "25/06/08 22:41:50 INFO SparkContext: Starting job: show at cmd6.sc:30\n",
      "25/06/08 22:41:50 INFO DAGScheduler: Got job 8 (show at cmd6.sc:30) with 1 output partitions\n",
      "25/06/08 22:41:50 INFO DAGScheduler: Final stage: ResultStage 12 (show at cmd6.sc:30)\n",
      "25/06/08 22:41:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)\n",
      "25/06/08 22:41:50 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/08 22:41:50 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[28] at show at cmd6.sc:30), which has no missing parents\n",
      "25/06/08 22:41:50 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 67.4 KiB, free 2004.4 MiB)\n",
      "25/06/08 22:41:50 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 27.6 KiB, free 2004.3 MiB)\n",
      "25/06/08 22:41:50 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 192.168.18.245:57344 (size: 27.6 KiB, free: 2004.5 MiB)\n",
      "25/06/08 22:41:50 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1611\n",
      "25/06/08 22:41:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[28] at show at cmd6.sc:30) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/08 22:41:50 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0\n",
      "25/06/08 22:41:50 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 192.168.18.245:57344 in memory (size: 25.6 KiB, free: 2004.6 MiB)\n",
      "25/06/08 22:41:50 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 10) (192.168.18.245, executor driver, partition 0, NODE_LOCAL, 8999 bytes) \n",
      "25/06/08 22:41:50 INFO Executor: Running task 0.0 in stage 12.0 (TID 10)\n",
      "25/06/08 22:41:50 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 192.168.18.245:57344 in memory (size: 23.4 KiB, free: 2004.6 MiB)\n",
      "25/06/08 22:41:50 INFO CodeGenerator: Code generated in 3.131625 ms\n",
      "25/06/08 22:41:50 INFO ShuffleBlockFetcherIterator: Getting 1 (387.0 B) non-empty blocks including 1 (387.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:41:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:41:50 INFO CodeGenerator: Code generated in 8.026375 ms\n",
      "25/06/08 22:41:50 INFO Executor: Finished task 0.0 in stage 12.0 (TID 10). 5185 bytes result sent to driver\n",
      "25/06/08 22:41:50 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 10) in 24 ms on 192.168.18.245 (executor driver) (1/1)\n",
      "25/06/08 22:41:50 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool \n",
      "25/06/08 22:41:50 INFO DAGScheduler: ResultStage 12 (show at cmd6.sc:30) finished in 0.039 s\n",
      "25/06/08 22:41:50 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/06/08 22:41:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 12: Stage finished\n",
      "25/06/08 22:41:50 INFO DAGScheduler: Job 8 finished: show at cmd6.sc:30, took 0.042548 s\n",
      "25/06/08 22:41:50 INFO CodeGenerator: Code generated in 4.083041 ms\n",
      "25/06/08 22:41:50 INFO CodeGenerator: Code generated in 2.48025 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+-------------+---------------------+----------------+--------------------+----------------------+\n",
      "|  distrito|periodo|total_predios|total_serenazgo_bruto|total_descuentos|total_serenazgo_neto|promedio_participacion|\n",
      "+----------+-------+-------------+---------------------+----------------+--------------------+----------------------+\n",
      "|JESUS MARI|   2023|        69172|        1.783041608E7|      2477705.57|       1.535271051E7|                 83.74|\n",
      "|JESUS MARI|   2024|        73329|        1.949122927E7|       637110.38|       1.885411889E7|                 83.14|\n",
      "|JESUS MARI|   2025|        78294|        2.079256492E7|         85947.0|       2.070661792E7|                 83.03|\n",
      "+----------+-------+-------------+---------------------+----------------+--------------------+----------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.functions._\u001b[39m\n",
       "\u001b[36mdf\u001b[39m: \u001b[32mDataFrame\u001b[39m = [fecha_corte: int, periodo: int ... 16 more fields]\n",
       "\u001b[36mmapped2\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mDataset\u001b[39m[\u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mRow\u001b[39m] = [distrito: string, periodo: int ... 4 more fields]\n",
       "\u001b[36mreduced2\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mDataset\u001b[39m[\u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mRow\u001b[39m] = [distrito: string, periodo: int ... 5 more fields]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// CONSULTA 2: MapReduce - Análisis por distrito y período\n",
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "println(\"🔍 CONSULTA 2: MapReduce - Análisis por distrito y período\")\n",
    "\n",
    "val df = spark.table(\"arbitrios_jm\")\n",
    "\n",
    "// MapReduce 2: Map - Calcular montos con descuentos\n",
    "val mapped2 = df.select(\n",
    "  col(\"distrito\"),\n",
    "  col(\"periodo\").cast(\"int\").as(\"periodo\"),\n",
    "  col(\"monto_serenazgo\").cast(\"double\").as(\"monto_serenazgo\"),\n",
    "  col(\"descuento_tope_serenazgo\").cast(\"double\").as(\"descuento_serenazgo\"),\n",
    "  (col(\"monto_serenazgo\").cast(\"double\") - col(\"descuento_tope_serenazgo\").cast(\"double\")).as(\"monto_neto_serenazgo\"),\n",
    "  col(\"porcentaje_condominio\").cast(\"double\").as(\"porcentaje\")\n",
    ").filter(col(\"monto_serenazgo\").isNotNull && col(\"distrito\").isNotNull)\n",
    "\n",
    "// Reduce 2: Agrupar por distrito y período\n",
    "val reduced2 = mapped2.groupBy(\"distrito\", \"periodo\")\n",
    "  .agg(\n",
    "    count(\"*\").as(\"total_predios\"),\n",
    "    round(sum(\"monto_serenazgo\"), 2).as(\"total_serenazgo_bruto\"),\n",
    "    round(sum(\"descuento_serenazgo\"), 2).as(\"total_descuentos\"),\n",
    "    round(sum(\"monto_neto_serenazgo\"), 2).as(\"total_serenazgo_neto\"),\n",
    "    round(avg(\"porcentaje\"), 2).as(\"promedio_participacion\")\n",
    "  )\n",
    "  .orderBy(\"distrito\", \"periodo\")\n",
    "\n",
    "println(\"📊 Resultado Consulta 2:\")\n",
    "reduced2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bdfdd7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 CONSULTA 3: MapReduce - Eficiencia de cobro por contribuyente\n",
      "📊 Resultado Consulta 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/08 22:41:51 INFO CodeGenerator: Code generated in 11.542375 ms\n",
      "25/06/08 22:41:51 INFO DAGScheduler: Registering RDD 31 (show at cmd7.sc:37) as input to shuffle 4\n",
      "25/06/08 22:41:51 INFO DAGScheduler: Got map stage job 9 (show at cmd7.sc:37) with 1 output partitions\n",
      "25/06/08 22:41:51 INFO DAGScheduler: Final stage: ShuffleMapStage 13 (show at cmd7.sc:37)\n",
      "25/06/08 22:41:51 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/06/08 22:41:51 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/08 22:41:51 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[31] at show at cmd7.sc:37), which has no missing parents\n",
      "25/06/08 22:41:51 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 59.8 KiB, free 2004.4 MiB)\n",
      "25/06/08 22:41:51 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 2004.4 MiB)\n",
      "25/06/08 22:41:51 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 192.168.18.245:57344 (size: 24.0 KiB, free: 2004.5 MiB)\n",
      "25/06/08 22:41:51 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1611\n",
      "25/06/08 22:41:51 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[31] at show at cmd7.sc:37) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/08 22:41:51 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0\n",
      "25/06/08 22:41:51 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 11) (192.168.18.245, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) \n",
      "25/06/08 22:41:51 INFO Executor: Running task 0.0 in stage 13.0 (TID 11)\n",
      "25/06/08 22:41:51 INFO CodeGenerator: Code generated in 10.359917 ms\n",
      "25/06/08 22:41:51 INFO CodeGenerator: Code generated in 2.045042 ms\n",
      "25/06/08 22:41:51 INFO CodeGenerator: Code generated in 2.017125 ms\n",
      "25/06/08 22:41:51 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 192.168.18.245:57344 in memory (size: 27.6 KiB, free: 2004.6 MiB)\n",
      "25/06/08 22:41:51 INFO JDBCRDD: closed connection\n",
      "25/06/08 22:41:51 INFO Executor: Finished task 0.0 in stage 13.0 (TID 11). 2549 bytes result sent to driver\n",
      "25/06/08 22:41:51 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 11) in 310 ms on 192.168.18.245 (executor driver) (1/1)\n",
      "25/06/08 22:41:51 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool \n",
      "25/06/08 22:41:51 INFO DAGScheduler: ShuffleMapStage 13 (show at cmd7.sc:37) finished in 0.314 s\n",
      "25/06/08 22:41:51 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/06/08 22:41:51 INFO DAGScheduler: running: Set()\n",
      "25/06/08 22:41:51 INFO DAGScheduler: waiting: Set()\n",
      "25/06/08 22:41:51 INFO DAGScheduler: failed: Set()\n",
      "25/06/08 22:41:51 INFO ShufflePartitionsUtil: For shuffle(4), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "25/06/08 22:41:51 INFO CodeGenerator: Code generated in 3.429125 ms\n",
      "25/06/08 22:41:51 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.\n",
      "25/06/08 22:41:51 INFO CodeGenerator: Code generated in 6.36 ms\n",
      "25/06/08 22:41:51 INFO SparkContext: Starting job: show at cmd7.sc:37\n",
      "25/06/08 22:41:51 INFO DAGScheduler: Got job 10 (show at cmd7.sc:37) with 3 output partitions\n",
      "25/06/08 22:41:51 INFO DAGScheduler: Final stage: ResultStage 15 (show at cmd7.sc:37)\n",
      "25/06/08 22:41:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)\n",
      "25/06/08 22:41:51 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/08 22:41:51 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[35] at show at cmd7.sc:37), which has no missing parents\n",
      "25/06/08 22:41:51 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 74.5 KiB, free 2004.4 MiB)\n",
      "25/06/08 22:41:51 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 29.0 KiB, free 2004.4 MiB)\n",
      "25/06/08 22:41:51 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 192.168.18.245:57344 (size: 29.0 KiB, free: 2004.5 MiB)\n",
      "25/06/08 22:41:51 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1611\n",
      "25/06/08 22:41:51 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 15 (MapPartitionsRDD[35] at show at cmd7.sc:37) (first 15 tasks are for partitions Vector(0, 1, 2))\n",
      "25/06/08 22:41:51 INFO TaskSchedulerImpl: Adding task set 15.0 with 3 tasks resource profile 0\n",
      "25/06/08 22:41:51 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 12) (192.168.18.245, executor driver, partition 0, NODE_LOCAL, 8999 bytes) \n",
      "25/06/08 22:41:51 INFO TaskSetManager: Starting task 1.0 in stage 15.0 (TID 13) (192.168.18.245, executor driver, partition 1, NODE_LOCAL, 8999 bytes) \n",
      "25/06/08 22:41:51 INFO TaskSetManager: Starting task 2.0 in stage 15.0 (TID 14) (192.168.18.245, executor driver, partition 2, NODE_LOCAL, 8999 bytes) \n",
      "25/06/08 22:41:51 INFO Executor: Running task 0.0 in stage 15.0 (TID 12)\n",
      "25/06/08 22:41:51 INFO Executor: Running task 1.0 in stage 15.0 (TID 13)\n",
      "25/06/08 22:41:51 INFO Executor: Running task 2.0 in stage 15.0 (TID 14)\n",
      "25/06/08 22:41:51 INFO CodeGenerator: Code generated in 4.29675 ms\n",
      "25/06/08 22:41:51 INFO ShuffleBlockFetcherIterator: Getting 1 (1024.1 KiB) non-empty blocks including 1 (1024.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:41:51 INFO ShuffleBlockFetcherIterator: Getting 1 (1039.8 KiB) non-empty blocks including 1 (1039.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:41:51 INFO ShuffleBlockFetcherIterator: Getting 1 (1856.1 KiB) non-empty blocks including 1 (1856.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:41:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:41:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:41:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:41:51 INFO CodeGenerator: Code generated in 8.65525 ms\n",
      "25/06/08 22:41:51 INFO Executor: Finished task 1.0 in stage 15.0 (TID 13). 7615 bytes result sent to driver\n",
      "25/06/08 22:41:51 INFO Executor: Finished task 0.0 in stage 15.0 (TID 12). 7615 bytes result sent to driver\n",
      "25/06/08 22:41:51 INFO TaskSetManager: Finished task 1.0 in stage 15.0 (TID 13) in 97 ms on 192.168.18.245 (executor driver) (1/3)\n",
      "25/06/08 22:41:51 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 12) in 97 ms on 192.168.18.245 (executor driver) (2/3)\n",
      "25/06/08 22:41:51 INFO Executor: Finished task 2.0 in stage 15.0 (TID 14). 7615 bytes result sent to driver\n",
      "25/06/08 22:41:51 INFO TaskSetManager: Finished task 2.0 in stage 15.0 (TID 14) in 105 ms on 192.168.18.245 (executor driver) (3/3)\n",
      "25/06/08 22:41:51 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool \n",
      "25/06/08 22:41:51 INFO DAGScheduler: ResultStage 15 (show at cmd7.sc:37) finished in 0.110 s\n",
      "25/06/08 22:41:51 INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/06/08 22:41:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished\n",
      "25/06/08 22:41:51 INFO DAGScheduler: Job 10 finished: show at cmd7.sc:37, took 0.117163 s\n",
      "25/06/08 22:41:51 INFO CodeGenerator: Code generated in 3.704833 ms\n",
      "25/06/08 22:41:51 INFO CodeGenerator: Code generated in 2.088125 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+-----------+------------+---------------+-----------------+--------------------+----------+----------------+\n",
      "|   cod_contribuyente|  distrito|num_predios|total_parque|total_serenazgo|total_desc_parque|total_desc_serenazgo|total_neto|eficiencia_cobro|\n",
      "+--------------------+----------+-----------+------------+---------------+-----------------+--------------------+----------+----------------+\n",
      "|55351ada81c0f27f8...|JESUS MARI|        599|   160163.16|      657369.24|              0.0|            70384.32| 747148.08|           91.39|\n",
      "|8b23a5f47f37eaa52...|JESUS MARI|         33|     9724.32|       709412.4|              0.0|             79134.6| 640002.12|            89.0|\n",
      "|9e17ffa1e26b269ea...|JESUS MARI|        201|    53996.64|       283911.6|              0.0|            31641.72| 306266.52|           90.64|\n",
      "|c7d7cd94d59a8b17c...|JESUS MARI|        147|    38205.72|      275865.72|              0.0|             23238.0| 290833.44|            92.6|\n",
      "|2119b2fb48bfa34d8...|JESUS MARI|         11|     3225.36|      286145.28|              0.0|                 0.0| 289370.64|           100.0|\n",
      "|39ed9d9016f301c73...|JESUS MARI|        368|   106209.48|      190247.52|              0.0|            21164.52| 275292.48|           92.86|\n",
      "|2a0199bb8f20b9035...|JESUS MARI|         19|     5450.52|      288995.52|              0.0|            29280.24|  265165.8|           90.06|\n",
      "|e50b873fbaacca239...|JESUS MARI|         12|     3050.88|      277559.04|              0.0|            30901.92|  249708.0|           88.99|\n",
      "|bb2027fde5fabef9a...|JESUS MARI|        270|    70882.08|      172533.36|              0.0|              757.92| 242657.52|           99.69|\n",
      "|139af841d2e577a63...|JESUS MARI|        414|    53949.96|      204642.96|              0.0|            22893.48| 235699.44|           91.15|\n",
      "|76186f0fef1d04e20...|JESUS MARI|        353|     98185.1|       125911.0|             6.24|            14302.08| 209787.78|           93.62|\n",
      "|3602b54fdd65ed73c...|JESUS MARI|        252|     69657.0|      139203.48|              0.0|            23765.76| 185094.72|           88.62|\n",
      "|38548de48f1bfb8e5...|JESUS MARI|         39|    10476.96|      191669.76|              0.0|             21362.4| 180784.32|           89.43|\n",
      "|aec78ce615f724235...|JESUS MARI|        298|     79179.0|       92334.84|              0.0|                 0.0| 171513.84|           100.0|\n",
      "|64ffb68d3a59f24ac...|JESUS MARI|        174|    46743.36|       107813.4|              0.0|              329.52| 154227.24|           99.79|\n",
      "+--------------------+----------+-----------+------------+---------------+-----------------+--------------------+----------+----------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.functions._\u001b[39m\n",
       "\u001b[36mdf\u001b[39m: \u001b[32mDataFrame\u001b[39m = [fecha_corte: int, periodo: int ... 16 more fields]\n",
       "\u001b[36mmapped3\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mDataset\u001b[39m[\u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mRow\u001b[39m] = [cod_contribuyente: string, distrito: string ... 5 more fields]\n",
       "\u001b[36mreduced3\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mDataset\u001b[39m[\u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mRow\u001b[39m] = [cod_contribuyente: string, distrito: string ... 7 more fields]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// CONSULTA 3: MapReduce - Eficiencia de cobro por contribuyente\n",
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "println(\"🔍 CONSULTA 3: MapReduce - Eficiencia de cobro por contribuyente\")\n",
    "\n",
    "val df = spark.table(\"arbitrios_jm\")\n",
    "\n",
    "// MapReduce 3: Map - Calcular eficiencia por registro\n",
    "val mapped3 = df.select(\n",
    "  col(\"cod_contribuyente\"),\n",
    "  col(\"distrito\"),\n",
    "  col(\"monto_parque_jardin\").cast(\"double\").as(\"monto_parque\"),\n",
    "  col(\"monto_serenazgo\").cast(\"double\").as(\"monto_serenazgo\"),\n",
    "  col(\"descuento_tope__parque_jardin\").cast(\"double\").as(\"desc_parque\"),\n",
    "  col(\"descuento_tope_serenazgo\").cast(\"double\").as(\"desc_serenazgo\"),\n",
    "  ((col(\"monto_parque_jardin\").cast(\"double\") + col(\"monto_serenazgo\").cast(\"double\")) - \n",
    "   (col(\"descuento_tope__parque_jardin\").cast(\"double\") + col(\"descuento_tope_serenazgo\").cast(\"double\"))).as(\"monto_neto_total\")\n",
    ").filter(col(\"monto_parque_jardin\").isNotNull && col(\"monto_serenazgo\").isNotNull)\n",
    "\n",
    "// Reduce 3: Agrupar por contribuyente y calcular eficiencia\n",
    "val reduced3 = mapped3.groupBy(\"cod_contribuyente\", \"distrito\")\n",
    "  .agg(\n",
    "    count(\"*\").as(\"num_predios\"),\n",
    "    round(sum(\"monto_parque\"), 2).as(\"total_parque\"),\n",
    "    round(sum(\"monto_serenazgo\"), 2).as(\"total_serenazgo\"),\n",
    "    round(sum(\"desc_parque\"), 2).as(\"total_desc_parque\"),\n",
    "    round(sum(\"desc_serenazgo\"), 2).as(\"total_desc_serenazgo\"),\n",
    "    round(sum(\"monto_neto_total\"), 2).as(\"total_neto\")\n",
    "  )\n",
    "  .filter(col(\"num_predios\") > 1)\n",
    "  .withColumn(\"eficiencia_cobro\", \n",
    "              round(col(\"total_neto\") / (col(\"total_parque\") + col(\"total_serenazgo\")) * 100, 2))\n",
    "  .orderBy(desc(\"total_neto\"))\n",
    "  .limit(15)\n",
    "\n",
    "println(\"📊 Resultado Consulta 3:\")\n",
    "reduced3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1875c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 ANÁLISIS MapReduce: Agrupación por distrito con extremos\n",
      "📊 Máximos y mínimos por distrito:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/08 22:41:52 INFO CodeGenerator: Code generated in 9.605125 ms\n",
      "25/06/08 22:41:52 INFO DAGScheduler: Registering RDD 38 (show at cmd8.sc:36) as input to shuffle 5\n",
      "25/06/08 22:41:52 INFO DAGScheduler: Got map stage job 11 (show at cmd8.sc:36) with 1 output partitions\n",
      "25/06/08 22:41:52 INFO DAGScheduler: Final stage: ShuffleMapStage 16 (show at cmd8.sc:36)\n",
      "25/06/08 22:41:52 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/06/08 22:41:52 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/08 22:41:52 INFO DAGScheduler: Submitting ShuffleMapStage 16 (MapPartitionsRDD[38] at show at cmd8.sc:36), which has no missing parents\n",
      "25/06/08 22:41:52 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 62.5 KiB, free 2004.4 MiB)\n",
      "25/06/08 22:41:52 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 24.4 KiB, free 2004.3 MiB)\n",
      "25/06/08 22:41:52 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 192.168.18.245:57344 (size: 24.4 KiB, free: 2004.5 MiB)\n",
      "25/06/08 22:41:52 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1611\n",
      "25/06/08 22:41:52 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[38] at show at cmd8.sc:36) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/08 22:41:52 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks resource profile 0\n",
      "25/06/08 22:41:52 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 15) (192.168.18.245, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) \n",
      "25/06/08 22:41:52 INFO Executor: Running task 0.0 in stage 16.0 (TID 15)\n",
      "25/06/08 22:41:52 INFO CodeGenerator: Code generated in 10.542875 ms\n",
      "25/06/08 22:41:52 INFO CodeGenerator: Code generated in 3.311291 ms\n",
      "25/06/08 22:41:52 INFO CodeGenerator: Code generated in 1.633416 ms\n",
      "25/06/08 22:41:52 INFO CodeGenerator: Code generated in 3.065917 ms\n",
      "25/06/08 22:41:52 INFO CodeGenerator: Code generated in 2.002458 ms\n",
      "25/06/08 22:41:52 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 192.168.18.245:57344 in memory (size: 29.0 KiB, free: 2004.6 MiB)\n",
      "25/06/08 22:41:52 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 192.168.18.245:57344 in memory (size: 24.0 KiB, free: 2004.6 MiB)\n",
      "25/06/08 22:41:52 INFO JDBCRDD: closed connection\n",
      "25/06/08 22:41:52 INFO Executor: Finished task 0.0 in stage 16.0 (TID 15). 2493 bytes result sent to driver\n",
      "25/06/08 22:41:52 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 15) in 217 ms on 192.168.18.245 (executor driver) (1/1)\n",
      "25/06/08 22:41:52 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool \n",
      "25/06/08 22:41:52 INFO DAGScheduler: ShuffleMapStage 16 (show at cmd8.sc:36) finished in 0.222 s\n",
      "25/06/08 22:41:52 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/06/08 22:41:52 INFO DAGScheduler: running: Set()\n",
      "25/06/08 22:41:52 INFO DAGScheduler: waiting: Set()\n",
      "25/06/08 22:41:52 INFO DAGScheduler: failed: Set()\n",
      "25/06/08 22:41:52 INFO ShufflePartitionsUtil: For shuffle(5), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "25/06/08 22:41:52 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.\n",
      "25/06/08 22:41:52 INFO CodeGenerator: Code generated in 8.689292 ms\n",
      "25/06/08 22:41:52 INFO SparkContext: Starting job: show at cmd8.sc:36\n",
      "25/06/08 22:41:52 INFO DAGScheduler: Got job 12 (show at cmd8.sc:36) with 1 output partitions\n",
      "25/06/08 22:41:52 INFO DAGScheduler: Final stage: ResultStage 18 (show at cmd8.sc:36)\n",
      "25/06/08 22:41:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)\n",
      "25/06/08 22:41:52 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/08 22:41:52 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[41] at show at cmd8.sc:36), which has no missing parents\n",
      "25/06/08 22:41:52 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 80.8 KiB, free 2004.4 MiB)\n",
      "25/06/08 22:41:52 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 30.0 KiB, free 2004.4 MiB)\n",
      "25/06/08 22:41:52 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 192.168.18.245:57344 (size: 30.0 KiB, free: 2004.5 MiB)\n",
      "25/06/08 22:41:52 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1611\n",
      "25/06/08 22:41:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[41] at show at cmd8.sc:36) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/08 22:41:52 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks resource profile 0\n",
      "25/06/08 22:41:52 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 16) (192.168.18.245, executor driver, partition 0, NODE_LOCAL, 8999 bytes) \n",
      "25/06/08 22:41:52 INFO Executor: Running task 0.0 in stage 18.0 (TID 16)\n",
      "25/06/08 22:41:52 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:41:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:41:52 INFO CodeGenerator: Code generated in 10.048459 ms\n",
      "25/06/08 22:41:52 INFO Executor: Finished task 0.0 in stage 18.0 (TID 16). 5021 bytes result sent to driver\n",
      "25/06/08 22:41:52 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 16) in 20 ms on 192.168.18.245 (executor driver) (1/1)\n",
      "25/06/08 22:41:52 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool \n",
      "25/06/08 22:41:52 INFO DAGScheduler: ResultStage 18 (show at cmd8.sc:36) finished in 0.026 s\n",
      "25/06/08 22:41:52 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/06/08 22:41:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 18: Stage finished\n",
      "25/06/08 22:41:52 INFO DAGScheduler: Job 12 finished: show at cmd8.sc:36, took 0.028968 s\n",
      "25/06/08 22:41:52 INFO CodeGenerator: Code generated in 2.604666 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+-------------+-------------+----------+----------+------------+------------+--------------+--------------+------------------+\n",
      "|  distrito|total_registros|max_serenazgo|min_serenazgo|max_parque|min_parque|max_residuos|min_residuos|max_porcentaje|min_porcentaje|promedio_serenazgo|\n",
      "+----------+---------------+-------------+-------------+----------+----------+------------+------------+--------------+--------------+------------------+\n",
      "|JESUS MARI|         220795|     27102.12|          0.0|    308.64|       0.0|      998.04|         0.0|         100.0|          0.16|             263.2|\n",
      "+----------+---------------+-------------+-------------+----------+----------+------------+------------+--------------+--------------+------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.functions._\u001b[39m\n",
       "\u001b[36mdf\u001b[39m: \u001b[32mDataFrame\u001b[39m = [fecha_corte: int, periodo: int ... 16 more fields]\n",
       "\u001b[36mmappedDistritos\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mDataset\u001b[39m[\u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mRow\u001b[39m] = [distrito: string, serenazgo: double ... 3 more fields]\n",
       "\u001b[36mreducedDistritos\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mDataset\u001b[39m[\u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mRow\u001b[39m] = [distrito: string, total_registros: bigint ... 9 more fields]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// AGRUPAR POR TIPOS Y ENCONTRAR MAYORES Y MENORES\n",
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "println(\"📊 ANÁLISIS MapReduce: Agrupación por distrito con extremos\")\n",
    "\n",
    "val df = spark.table(\"arbitrios_jm\")\n",
    "\n",
    "// Map: Preparar datos por distrito\n",
    "val mappedDistritos = df.select(\n",
    "  col(\"distrito\"),\n",
    "  col(\"monto_serenazgo\").cast(\"double\").as(\"serenazgo\"),\n",
    "  col(\"monto_parque_jardin\").cast(\"double\").as(\"parque\"),\n",
    "  col(\"monto_residuos_solidos\").cast(\"double\").as(\"residuos\"),\n",
    "  col(\"porcentaje_condominio\").cast(\"double\").as(\"porcentaje\")\n",
    ").filter(col(\"distrito\").isNotNull && \n",
    "         col(\"monto_serenazgo\").isNotNull && \n",
    "         col(\"monto_parque_jardin\").isNotNull)\n",
    "\n",
    "// Reduce: Encontrar máximos y mínimos por distrito\n",
    "val reducedDistritos = mappedDistritos.groupBy(\"distrito\")\n",
    "  .agg(\n",
    "    count(\"*\").as(\"total_registros\"),\n",
    "    round(max(\"serenazgo\"), 2).as(\"max_serenazgo\"),\n",
    "    round(min(\"serenazgo\"), 2).as(\"min_serenazgo\"),\n",
    "    round(max(\"parque\"), 2).as(\"max_parque\"),\n",
    "    round(min(\"parque\"), 2).as(\"min_parque\"),\n",
    "    round(max(\"residuos\"), 2).as(\"max_residuos\"),\n",
    "    round(min(\"residuos\"), 2).as(\"min_residuos\"),\n",
    "    round(max(\"porcentaje\"), 2).as(\"max_porcentaje\"),\n",
    "    round(min(\"porcentaje\"), 2).as(\"min_porcentaje\"),\n",
    "    round(avg(\"serenazgo\"), 2).as(\"promedio_serenazgo\")\n",
    "  )\n",
    "  .orderBy(desc(\"promedio_serenazgo\"))\n",
    "\n",
    "println(\"📊 Máximos y mínimos por distrito:\")\n",
    "reducedDistritos.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e91ef284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 ESTADÍSTICAS DESCRIPTIVAS MapReduce para MONTO_RESIDUOS_SOLIDOS\n",
      "📊 Estadísticas generales:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/08 22:41:52 INFO CodeGenerator: Code generated in 1.926042 ms\n",
      "25/06/08 22:41:52 INFO DAGScheduler: Registering RDD 45 (show at cmd9.sc:24) as input to shuffle 6\n",
      "25/06/08 22:41:52 INFO DAGScheduler: Got map stage job 13 (show at cmd9.sc:24) with 1 output partitions\n",
      "25/06/08 22:41:52 INFO DAGScheduler: Final stage: ShuffleMapStage 19 (show at cmd9.sc:24)\n",
      "25/06/08 22:41:52 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/06/08 22:41:52 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/08 22:41:52 INFO DAGScheduler: Submitting ShuffleMapStage 19 (MapPartitionsRDD[45] at show at cmd9.sc:24), which has no missing parents\n",
      "25/06/08 22:41:52 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 34.1 KiB, free 2004.4 MiB)\n",
      "25/06/08 22:41:52 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 16.2 KiB, free 2004.4 MiB)\n",
      "25/06/08 22:41:52 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 192.168.18.245:57344 (size: 16.2 KiB, free: 2004.5 MiB)\n",
      "25/06/08 22:41:52 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1611\n",
      "25/06/08 22:41:52 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 19 (MapPartitionsRDD[45] at show at cmd9.sc:24) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/08 22:41:52 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks resource profile 0\n",
      "25/06/08 22:41:52 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 17) (192.168.18.245, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) \n",
      "25/06/08 22:41:52 INFO Executor: Running task 0.0 in stage 19.0 (TID 17)\n",
      "25/06/08 22:41:52 INFO CodeGenerator: Code generated in 2.078167 ms\n",
      "25/06/08 22:41:52 INFO CodeGenerator: Code generated in 1.791166 ms\n",
      "25/06/08 22:41:52 INFO CodeGenerator: Code generated in 5.974625 ms\n",
      "25/06/08 22:41:52 INFO CodeGenerator: Code generated in 2.066875 ms\n",
      "25/06/08 22:41:52 INFO CodeGenerator: Code generated in 1.966042 ms\n",
      "25/06/08 22:41:52 INFO CodeGenerator: Code generated in 4.613291 ms\n",
      "25/06/08 22:41:52 INFO JDBCRDD: closed connection\n",
      "25/06/08 22:41:52 INFO Executor: Finished task 0.0 in stage 19.0 (TID 17). 2046 bytes result sent to driver\n",
      "25/06/08 22:41:52 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 17) in 228 ms on 192.168.18.245 (executor driver) (1/1)\n",
      "25/06/08 22:41:52 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool \n",
      "25/06/08 22:41:52 INFO DAGScheduler: ShuffleMapStage 19 (show at cmd9.sc:24) finished in 0.238 s\n",
      "25/06/08 22:41:52 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/06/08 22:41:52 INFO DAGScheduler: running: Set()\n",
      "25/06/08 22:41:52 INFO DAGScheduler: waiting: Set()\n",
      "25/06/08 22:41:52 INFO DAGScheduler: failed: Set()\n",
      "25/06/08 22:41:52 INFO SparkContext: Starting job: show at cmd9.sc:24\n",
      "25/06/08 22:41:52 INFO DAGScheduler: Got job 14 (show at cmd9.sc:24) with 1 output partitions\n",
      "25/06/08 22:41:52 INFO DAGScheduler: Final stage: ResultStage 21 (show at cmd9.sc:24)\n",
      "25/06/08 22:41:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 20)\n",
      "25/06/08 22:41:52 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/08 22:41:52 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[48] at show at cmd9.sc:24), which has no missing parents\n",
      "25/06/08 22:41:52 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 43.1 KiB, free 2004.3 MiB)\n",
      "25/06/08 22:41:52 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 19.7 KiB, free 2004.3 MiB)\n",
      "25/06/08 22:41:52 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 192.168.18.245:57344 (size: 19.7 KiB, free: 2004.5 MiB)\n",
      "25/06/08 22:41:52 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1611\n",
      "25/06/08 22:41:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[48] at show at cmd9.sc:24) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/08 22:41:52 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks resource profile 0\n",
      "25/06/08 22:41:52 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 18) (192.168.18.245, executor driver, partition 0, NODE_LOCAL, 8999 bytes) \n",
      "25/06/08 22:41:52 INFO Executor: Running task 0.0 in stage 21.0 (TID 18)\n",
      "25/06/08 22:41:52 INFO ShuffleBlockFetcherIterator: Getting 1 (46.5 KiB) non-empty blocks including 1 (46.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:41:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:41:52 INFO CodeGenerator: Code generated in 3.305334 ms\n",
      "25/06/08 22:41:52 INFO CodeGenerator: Code generated in 2.911667 ms\n",
      "25/06/08 22:41:52 INFO Executor: Finished task 0.0 in stage 21.0 (TID 18). 4589 bytes result sent to driver\n",
      "25/06/08 22:41:52 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 18) in 28 ms on 192.168.18.245 (executor driver) (1/1)\n",
      "25/06/08 22:41:52 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool \n",
      "25/06/08 22:41:52 INFO DAGScheduler: ResultStage 21 (show at cmd9.sc:24) finished in 0.031 s\n",
      "25/06/08 22:41:52 INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/06/08 22:41:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 21: Stage finished\n",
      "25/06/08 22:41:52 INFO DAGScheduler: Job 14 finished: show at cmd9.sc:24, took 0.033416 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------+-------------------+------+------+------------------+\n",
      "|total_registros|promedio|desviacion_estandar|maximo|minimo|mediana_aproximada|\n",
      "+---------------+--------+-------------------+------+------+------------------+\n",
      "|         220795|   57.98|              80.43|998.04|   0.0|             39.96|\n",
      "+---------------+--------+-------------------+------+------+------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.functions._\u001b[39m\n",
       "\u001b[36mdf\u001b[39m: \u001b[32mDataFrame\u001b[39m = [fecha_corte: int, periodo: int ... 16 more fields]\n",
       "\u001b[36mmappedEstadisticas\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mDataset\u001b[39m[\u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mRow\u001b[39m] = [residuos: double]\n",
       "\u001b[36mestadisticasBasicas\u001b[39m: \u001b[32mDataFrame\u001b[39m = [total_registros: bigint, promedio: double ... 4 more fields]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// ESTADÍSTICAS DESCRIPTIVAS\n",
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "println(\"📊 ESTADÍSTICAS DESCRIPTIVAS MapReduce para MONTO_RESIDUOS_SOLIDOS\")\n",
    "\n",
    "val df = spark.table(\"arbitrios_jm\")\n",
    "\n",
    "// Map: Preparar datos para estadísticas\n",
    "val mappedEstadisticas = df.select(\n",
    "  col(\"monto_residuos_solidos\").cast(\"double\").as(\"residuos\")\n",
    ").filter(col(\"monto_residuos_solidos\").isNotNull)\n",
    "\n",
    "// Reduce 1: Estadísticas básicas\n",
    "val estadisticasBasicas = mappedEstadisticas.agg(\n",
    "  count(\"residuos\").as(\"total_registros\"),\n",
    "  round(avg(\"residuos\"), 2).as(\"promedio\"),\n",
    "  round(stddev(\"residuos\"), 2).as(\"desviacion_estandar\"),\n",
    "  round(max(\"residuos\"), 2).as(\"maximo\"),\n",
    "  round(min(\"residuos\"), 2).as(\"minimo\"),\n",
    "  expr(\"percentile_approx(residuos, 0.5)\").as(\"mediana_aproximada\")\n",
    ")\n",
    "\n",
    "println(\"📊 Estadísticas generales:\")\n",
    "estadisticasBasicas.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6228dbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/08 22:41:52 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 192.168.18.245:57344 in memory (size: 16.2 KiB, free: 2004.5 MiB)\n",
      "25/06/08 22:41:52 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 192.168.18.245:57344 in memory (size: 24.4 KiB, free: 2004.6 MiB)\n",
      "25/06/08 22:41:52 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 192.168.18.245:57344 in memory (size: 30.0 KiB, free: 2004.6 MiB)\n",
      "25/06/08 22:41:52 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 192.168.18.245:57344 in memory (size: 19.7 KiB, free: 2004.6 MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 ESTADÍSTICAS por DISTRITO:\n",
      "📊 Estadísticas por distrito:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/08 22:41:53 INFO CodeGenerator: Code generated in 2.111709 ms\n",
      "25/06/08 22:41:53 INFO DAGScheduler: Registering RDD 52 (show at cmd10.sc:22) as input to shuffle 7\n",
      "25/06/08 22:41:53 INFO DAGScheduler: Got map stage job 15 (show at cmd10.sc:22) with 1 output partitions\n",
      "25/06/08 22:41:53 INFO DAGScheduler: Final stage: ShuffleMapStage 22 (show at cmd10.sc:22)\n",
      "25/06/08 22:41:53 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/06/08 22:41:53 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/08 22:41:53 INFO DAGScheduler: Submitting ShuffleMapStage 22 (MapPartitionsRDD[52] at show at cmd10.sc:22), which has no missing parents\n",
      "25/06/08 22:41:53 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 35.0 KiB, free 2004.6 MiB)\n",
      "25/06/08 22:41:53 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 16.5 KiB, free 2004.5 MiB)\n",
      "25/06/08 22:41:53 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 192.168.18.245:57344 (size: 16.5 KiB, free: 2004.6 MiB)\n",
      "25/06/08 22:41:53 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1611\n",
      "25/06/08 22:41:53 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[52] at show at cmd10.sc:22) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/08 22:41:53 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks resource profile 0\n",
      "25/06/08 22:41:53 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 19) (192.168.18.245, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) \n",
      "25/06/08 22:41:53 INFO Executor: Running task 0.0 in stage 22.0 (TID 19)\n",
      "25/06/08 22:41:53 INFO CodeGenerator: Code generated in 2.526875 ms\n",
      "25/06/08 22:41:53 INFO CodeGenerator: Code generated in 4.35325 ms\n",
      "25/06/08 22:41:53 INFO CodeGenerator: Code generated in 3.701584 ms\n",
      "25/06/08 22:41:53 INFO JDBCRDD: closed connection\n",
      "25/06/08 22:41:53 INFO Executor: Finished task 0.0 in stage 22.0 (TID 19). 2248 bytes result sent to driver\n",
      "25/06/08 22:41:53 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 19) in 180 ms on 192.168.18.245 (executor driver) (1/1)\n",
      "25/06/08 22:41:53 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool \n",
      "25/06/08 22:41:53 INFO DAGScheduler: ShuffleMapStage 22 (show at cmd10.sc:22) finished in 0.186 s\n",
      "25/06/08 22:41:53 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/06/08 22:41:53 INFO DAGScheduler: running: Set()\n",
      "25/06/08 22:41:53 INFO DAGScheduler: waiting: Set()\n",
      "25/06/08 22:41:53 INFO DAGScheduler: failed: Set()\n",
      "25/06/08 22:41:53 INFO ShufflePartitionsUtil: For shuffle(7), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "25/06/08 22:41:53 INFO CodeGenerator: Code generated in 3.037916 ms\n",
      "25/06/08 22:41:53 INFO SparkContext: Starting job: show at cmd10.sc:22\n",
      "25/06/08 22:41:53 INFO DAGScheduler: Got job 16 (show at cmd10.sc:22) with 1 output partitions\n",
      "25/06/08 22:41:53 INFO DAGScheduler: Final stage: ResultStage 24 (show at cmd10.sc:22)\n",
      "25/06/08 22:41:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 23)\n",
      "25/06/08 22:41:53 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/08 22:41:53 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[56] at show at cmd10.sc:22), which has no missing parents\n",
      "25/06/08 22:41:53 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 49.5 KiB, free 2004.5 MiB)\n",
      "25/06/08 22:41:53 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 22.0 KiB, free 2004.5 MiB)\n",
      "25/06/08 22:41:53 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 192.168.18.245:57344 (size: 22.0 KiB, free: 2004.6 MiB)\n",
      "25/06/08 22:41:53 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1611\n",
      "25/06/08 22:41:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[56] at show at cmd10.sc:22) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/08 22:41:53 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks resource profile 0\n",
      "25/06/08 22:41:53 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 20) (192.168.18.245, executor driver, partition 0, NODE_LOCAL, 8999 bytes) \n",
      "25/06/08 22:41:53 INFO Executor: Running task 0.0 in stage 24.0 (TID 20)\n",
      "25/06/08 22:41:53 INFO ShuffleBlockFetcherIterator: Getting 1 (46.5 KiB) non-empty blocks including 1 (46.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:41:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:41:53 INFO CodeGenerator: Code generated in 4.507 ms\n",
      "25/06/08 22:41:53 INFO CodeGenerator: Code generated in 2.706458 ms\n",
      "25/06/08 22:41:53 INFO CodeGenerator: Code generated in 9.666042 ms\n",
      "25/06/08 22:41:53 INFO Executor: Finished task 0.0 in stage 24.0 (TID 20). 4723 bytes result sent to driver\n",
      "25/06/08 22:41:53 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 20) in 33 ms on 192.168.18.245 (executor driver) (1/1)\n",
      "25/06/08 22:41:53 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool \n",
      "25/06/08 22:41:53 INFO DAGScheduler: ResultStage 24 (show at cmd10.sc:22) finished in 0.037 s\n",
      "25/06/08 22:41:53 INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/06/08 22:41:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 24: Stage finished\n",
      "25/06/08 22:41:53 INFO DAGScheduler: Job 16 finished: show at cmd10.sc:22, took 0.039362 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+--------+----------+------+------+-------+\n",
      "|  distrito|registros|promedio|desviacion|maximo|minimo|mediana|\n",
      "+----------+---------+--------+----------+------+------+-------+\n",
      "|JESUS MARI|   220795|   57.98|     80.43|998.04|   0.0|  39.96|\n",
      "+----------+---------+--------+----------+------+------+-------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mmappedPorDistrito\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mDataset\u001b[39m[\u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mRow\u001b[39m] = [distrito: string, residuos: double]\n",
       "\u001b[36mestadisticasPorDistrito\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mDataset\u001b[39m[\u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mRow\u001b[39m] = [distrito: string, registros: bigint ... 5 more fields]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Map-Reduce por distrito\n",
    "println(\"📊 ESTADÍSTICAS por DISTRITO:\")\n",
    "\n",
    "val mappedPorDistrito = df.select(\n",
    "  col(\"distrito\"),\n",
    "  col(\"monto_residuos_solidos\").cast(\"double\").as(\"residuos\")\n",
    ").filter(col(\"distrito\").isNotNull && col(\"monto_residuos_solidos\").isNotNull)\n",
    "\n",
    "val estadisticasPorDistrito = mappedPorDistrito.groupBy(\"distrito\")\n",
    "  .agg(\n",
    "    count(\"residuos\").as(\"registros\"),\n",
    "    round(avg(\"residuos\"), 2).as(\"promedio\"),\n",
    "    round(stddev(\"residuos\"), 2).as(\"desviacion\"),\n",
    "    round(max(\"residuos\"), 2).as(\"maximo\"),\n",
    "    round(min(\"residuos\"), 2).as(\"minimo\"),\n",
    "    expr(\"percentile_approx(residuos, 0.5)\").as(\"mediana\")\n",
    "  )\n",
    "  .filter(col(\"registros\") > 100)\n",
    "  .orderBy(desc(\"promedio\"))\n",
    "\n",
    "println(\"📊 Estadísticas por distrito:\")\n",
    "estadisticasPorDistrito.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7050e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💰 CONSULTA DECIMAL 1: Análisis de ratios complejos (3 MapReduce)\n",
      "📊 Resultado Consulta Decimal 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/08 22:41:53 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/08 22:41:53 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/08 22:41:53 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/08 22:41:53 INFO CodeGenerator: Code generated in 10.798458 ms\n",
      "25/06/08 22:41:53 INFO DAGScheduler: Registering RDD 59 (show at cmd11.sc:45) as input to shuffle 8\n",
      "25/06/08 22:41:53 INFO DAGScheduler: Got map stage job 17 (show at cmd11.sc:45) with 1 output partitions\n",
      "25/06/08 22:41:53 INFO DAGScheduler: Final stage: ShuffleMapStage 25 (show at cmd11.sc:45)\n",
      "25/06/08 22:41:53 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/06/08 22:41:53 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/08 22:41:53 INFO DAGScheduler: Submitting ShuffleMapStage 25 (MapPartitionsRDD[59] at show at cmd11.sc:45), which has no missing parents\n",
      "25/06/08 22:41:53 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 66.9 KiB, free 2004.4 MiB)\n",
      "25/06/08 22:41:53 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 2004.4 MiB)\n",
      "25/06/08 22:41:53 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 192.168.18.245:57344 (size: 27.2 KiB, free: 2004.5 MiB)\n",
      "25/06/08 22:41:53 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1611\n",
      "25/06/08 22:41:53 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 25 (MapPartitionsRDD[59] at show at cmd11.sc:45) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/08 22:41:53 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks resource profile 0\n",
      "25/06/08 22:41:53 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 21) (192.168.18.245, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) \n",
      "25/06/08 22:41:53 INFO Executor: Running task 0.0 in stage 25.0 (TID 21)\n",
      "25/06/08 22:41:53 INFO CodeGenerator: Code generated in 9.310375 ms\n",
      "25/06/08 22:41:53 INFO CodeGenerator: Code generated in 1.51525 ms\n",
      "25/06/08 22:41:53 INFO CodeGenerator: Code generated in 1.61975 ms\n",
      "25/06/08 22:41:53 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 192.168.18.245:57344 in memory (size: 22.0 KiB, free: 2004.6 MiB)\n",
      "25/06/08 22:41:53 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 192.168.18.245:57344 in memory (size: 16.5 KiB, free: 2004.6 MiB)\n",
      "25/06/08 22:41:53 INFO JDBCRDD: closed connection\n",
      "25/06/08 22:41:53 INFO Executor: Finished task 0.0 in stage 25.0 (TID 21). 2493 bytes result sent to driver\n",
      "25/06/08 22:41:53 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 21) in 314 ms on 192.168.18.245 (executor driver) (1/1)\n",
      "25/06/08 22:41:53 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool \n",
      "25/06/08 22:41:53 INFO DAGScheduler: ShuffleMapStage 25 (show at cmd11.sc:45) finished in 0.318 s\n",
      "25/06/08 22:41:53 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/06/08 22:41:53 INFO DAGScheduler: running: Set()\n",
      "25/06/08 22:41:53 INFO DAGScheduler: waiting: Set()\n",
      "25/06/08 22:41:53 INFO DAGScheduler: failed: Set()\n",
      "25/06/08 22:41:53 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/08 22:41:53 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/08 22:41:53 INFO ShufflePartitionsUtil: For shuffle(8), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "25/06/08 22:41:53 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.\n",
      "25/06/08 22:41:53 INFO CodeGenerator: Code generated in 6.062625 ms\n",
      "25/06/08 22:41:53 INFO DAGScheduler: Registering RDD 62 (show at cmd11.sc:45) as input to shuffle 9\n",
      "25/06/08 22:41:53 INFO DAGScheduler: Got map stage job 18 (show at cmd11.sc:45) with 1 output partitions\n",
      "25/06/08 22:41:53 INFO DAGScheduler: Final stage: ShuffleMapStage 27 (show at cmd11.sc:45)\n",
      "25/06/08 22:41:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 26)\n",
      "25/06/08 22:41:53 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/08 22:41:53 INFO DAGScheduler: Submitting ShuffleMapStage 27 (MapPartitionsRDD[62] at show at cmd11.sc:45), which has no missing parents\n",
      "25/06/08 22:41:53 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 80.2 KiB, free 2004.4 MiB)\n",
      "25/06/08 22:41:53 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 31.7 KiB, free 2004.4 MiB)\n",
      "25/06/08 22:41:53 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 192.168.18.245:57344 (size: 31.7 KiB, free: 2004.5 MiB)\n",
      "25/06/08 22:41:53 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1611\n",
      "25/06/08 22:41:53 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 27 (MapPartitionsRDD[62] at show at cmd11.sc:45) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/08 22:41:53 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks resource profile 0\n",
      "25/06/08 22:41:53 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 22) (192.168.18.245, executor driver, partition 0, NODE_LOCAL, 8988 bytes) \n",
      "25/06/08 22:41:53 INFO Executor: Running task 0.0 in stage 27.0 (TID 22)\n",
      "25/06/08 22:41:53 INFO ShuffleBlockFetcherIterator: Getting 1 (156.0 B) non-empty blocks including 1 (156.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:41:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:41:54 INFO CodeGenerator: Code generated in 9.587584 ms\n",
      "25/06/08 22:41:54 INFO Executor: Finished task 0.0 in stage 27.0 (TID 22). 5086 bytes result sent to driver\n",
      "25/06/08 22:41:54 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 22) in 21 ms on 192.168.18.245 (executor driver) (1/1)\n",
      "25/06/08 22:41:54 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool \n",
      "25/06/08 22:41:54 INFO DAGScheduler: ShuffleMapStage 27 (show at cmd11.sc:45) finished in 0.027 s\n",
      "25/06/08 22:41:54 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/06/08 22:41:54 INFO DAGScheduler: running: Set()\n",
      "25/06/08 22:41:54 INFO DAGScheduler: waiting: Set()\n",
      "25/06/08 22:41:54 INFO DAGScheduler: failed: Set()\n",
      "25/06/08 22:41:54 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/08 22:41:54 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/08 22:41:54 INFO CodeGenerator: Code generated in 2.881958 ms\n",
      "25/06/08 22:41:54 INFO CodeGenerator: Code generated in 3.795542 ms\n",
      "25/06/08 22:41:54 INFO SparkContext: Starting job: show at cmd11.sc:45\n",
      "25/06/08 22:41:54 INFO DAGScheduler: Got job 19 (show at cmd11.sc:45) with 1 output partitions\n",
      "25/06/08 22:41:54 INFO DAGScheduler: Final stage: ResultStage 30 (show at cmd11.sc:45)\n",
      "25/06/08 22:41:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 29)\n",
      "25/06/08 22:41:54 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/08 22:41:54 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[67] at show at cmd11.sc:45), which has no missing parents\n",
      "25/06/08 22:41:54 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 73.6 KiB, free 2004.3 MiB)\n",
      "25/06/08 22:41:54 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 30.0 KiB, free 2004.3 MiB)\n",
      "25/06/08 22:41:54 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 192.168.18.245:57344 (size: 30.0 KiB, free: 2004.5 MiB)\n",
      "25/06/08 22:41:54 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1611\n",
      "25/06/08 22:41:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[67] at show at cmd11.sc:45) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/08 22:41:54 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks resource profile 0\n",
      "25/06/08 22:41:54 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 23) (192.168.18.245, executor driver, partition 0, NODE_LOCAL, 8999 bytes) \n",
      "25/06/08 22:41:54 INFO Executor: Running task 0.0 in stage 30.0 (TID 23)\n",
      "25/06/08 22:41:54 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:41:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:41:54 INFO CodeGenerator: Code generated in 3.128208 ms\n",
      "25/06/08 22:41:54 INFO CodeGenerator: Code generated in 3.009958 ms\n",
      "25/06/08 22:41:54 INFO CodeGenerator: Code generated in 3.192125 ms\n",
      "25/06/08 22:41:54 INFO CodeGenerator: Code generated in 1.6995 ms\n",
      "25/06/08 22:41:54 INFO CodeGenerator: Code generated in 1.307667 ms\n",
      "25/06/08 22:41:54 INFO CodeGenerator: Code generated in 1.135 ms\n",
      "25/06/08 22:41:54 INFO CodeGenerator: Code generated in 0.917708 ms\n",
      "25/06/08 22:41:54 INFO CodeGenerator: Code generated in 2.293292 ms\n",
      "25/06/08 22:41:54 INFO Executor: Finished task 0.0 in stage 30.0 (TID 23). 6636 bytes result sent to driver\n",
      "25/06/08 22:41:54 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 23) in 52 ms on 192.168.18.245 (executor driver) (1/1)\n",
      "25/06/08 22:41:54 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool \n",
      "25/06/08 22:41:54 INFO DAGScheduler: ResultStage 30 (show at cmd11.sc:45) finished in 0.058 s\n",
      "25/06/08 22:41:54 INFO DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/06/08 22:41:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 30: Stage finished\n",
      "25/06/08 22:41:54 INFO DAGScheduler: Job 19 finished: show at cmd11.sc:45, took 0.059515 s\n",
      "25/06/08 22:41:54 INFO CodeGenerator: Code generated in 2.115292 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+----------------------+----------------------+----------------+----------------------+------------------+-------+\n",
      "|  distrito|total_predios|ratio_promedio_ser_par|ratio_promedio_res_ser|desviacion_ratio|promedio_participacion|indice_complejidad|ranking|\n",
      "+----------+-------------+----------------------+----------------------+----------------+----------------------+------------------+-------+\n",
      "|JESUS MARI|       220795|                1.7186|                0.2727|          4.1802|                 83.29|          1.959102|      1|\n",
      "+----------+-------------+----------------------+----------------------+----------------+----------------------+------------------+-------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.functions._\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.expressions.Window\u001b[39m\n",
       "\u001b[36mdf\u001b[39m: \u001b[32mDataFrame\u001b[39m = [fecha_corte: int, periodo: int ... 16 more fields]\n",
       "\u001b[36mmapReduce1_Ratios\u001b[39m: \u001b[32mDataFrame\u001b[39m = [distrito: string, cod_contribuyente: string ... 6 more fields]\n",
       "\u001b[36mmapReduce2_Agrupado\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mDataset\u001b[39m[\u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mRow\u001b[39m] = [distrito: string, total_predios: bigint ... 4 more fields]\n",
       "\u001b[36mmapReduce3_Final\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mDataset\u001b[39m[\u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mRow\u001b[39m] = [distrito: string, total_predios: bigint ... 6 more fields]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// CONSULTA DECIMAL 1: Análisis de ratios complejos (3 MapReduce)\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.expressions.Window\n",
    "\n",
    "println(\"💰 CONSULTA DECIMAL 1: Análisis de ratios complejos (3 MapReduce)\")\n",
    "\n",
    "val df = spark.table(\"arbitrios_jm\")\n",
    "\n",
    "// MapReduce 1: Calcular ratios básicos por registro\n",
    "val mapReduce1_Ratios = df.select(\n",
    "  col(\"distrito\"),\n",
    "  col(\"cod_contribuyente\"),\n",
    "  col(\"monto_serenazgo\").cast(\"double\").as(\"serenazgo\"),\n",
    "  col(\"monto_parque_jardin\").cast(\"double\").as(\"parque\"),\n",
    "  col(\"monto_residuos_solidos\").cast(\"double\").as(\"residuos\"),\n",
    "  col(\"porcentaje_condominio\").cast(\"double\").as(\"porcentaje\")\n",
    ").filter(col(\"monto_serenazgo\").isNotNull && \n",
    "         col(\"monto_parque_jardin\").isNotNull && \n",
    "         col(\"distrito\").isNotNull)\n",
    ".withColumn(\"ratio_serenazgo_parque\", \n",
    "            round(when(col(\"parque\") =!= 0, col(\"serenazgo\") / col(\"parque\")).otherwise(null), 4))\n",
    ".withColumn(\"ratio_residuos_serenazgo\", \n",
    "            round(when(col(\"serenazgo\") =!= 0, col(\"residuos\") / col(\"serenazgo\")).otherwise(null), 4))\n",
    "\n",
    "// MapReduce 2: Agrupar por distrito y calcular promedios\n",
    "val mapReduce2_Agrupado = mapReduce1_Ratios.groupBy(\"distrito\")\n",
    "  .agg(\n",
    "    count(\"*\").as(\"total_predios\"),\n",
    "    round(avg(\"ratio_serenazgo_parque\"), 4).as(\"ratio_promedio_ser_par\"),\n",
    "    round(avg(\"ratio_residuos_serenazgo\"), 4).as(\"ratio_promedio_res_ser\"),\n",
    "    round(stddev(\"ratio_serenazgo_parque\"), 4).as(\"desviacion_ratio\"),\n",
    "    round(avg(\"porcentaje\"), 2).as(\"promedio_participacion\")\n",
    "  )\n",
    "  .filter(col(\"total_predios\") > 50)\n",
    "\n",
    "// MapReduce 3: Calcular ranking y métricas finales\n",
    "val mapReduce3_Final = mapReduce2_Agrupado\n",
    "  .withColumn(\"indice_complejidad\", \n",
    "              round(col(\"ratio_promedio_ser_par\") * col(\"ratio_promedio_res_ser\") * col(\"desviacion_ratio\"), 6))\n",
    "  .withColumn(\"ranking\", \n",
    "              row_number().over(Window.orderBy(desc(\"indice_complejidad\"))))\n",
    "  .orderBy(\"ranking\")\n",
    "\n",
    "println(\"📊 Resultado Consulta Decimal 1:\")\n",
    "mapReduce3_Final.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c28ca794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💰 CONSULTA DECIMAL 2: Análisis de concentración financiera (3 MapReduce)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/08 22:41:54 INFO CodeGenerator: Code generated in 8.897625 ms\n",
      "25/06/08 22:41:54 INFO DAGScheduler: Registering RDD 70 (collect at cmd12.sc:30) as input to shuffle 10\n",
      "25/06/08 22:41:54 INFO DAGScheduler: Got map stage job 20 (collect at cmd12.sc:30) with 1 output partitions\n",
      "25/06/08 22:41:54 INFO DAGScheduler: Final stage: ShuffleMapStage 31 (collect at cmd12.sc:30)\n",
      "25/06/08 22:41:54 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/06/08 22:41:54 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/08 22:41:54 INFO DAGScheduler: Submitting ShuffleMapStage 31 (MapPartitionsRDD[70] at collect at cmd12.sc:30), which has no missing parents\n",
      "25/06/08 22:41:54 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 46.5 KiB, free 2004.3 MiB)\n",
      "25/06/08 22:41:54 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 21.0 KiB, free 2004.2 MiB)\n",
      "25/06/08 22:41:54 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 192.168.18.245:57344 (size: 21.0 KiB, free: 2004.5 MiB)\n",
      "25/06/08 22:41:54 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1611\n",
      "25/06/08 22:41:54 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 31 (MapPartitionsRDD[70] at collect at cmd12.sc:30) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/08 22:41:54 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks resource profile 0\n",
      "25/06/08 22:41:54 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 24) (192.168.18.245, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) \n",
      "25/06/08 22:41:54 INFO Executor: Running task 0.0 in stage 31.0 (TID 24)\n",
      "25/06/08 22:41:54 INFO CodeGenerator: Code generated in 8.3025 ms\n",
      "25/06/08 22:41:54 INFO CodeGenerator: Code generated in 1.400625 ms\n",
      "25/06/08 22:41:54 INFO CodeGenerator: Code generated in 1.33075 ms\n",
      "25/06/08 22:41:54 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 192.168.18.245:57344 in memory (size: 30.0 KiB, free: 2004.5 MiB)\n",
      "25/06/08 22:41:54 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 192.168.18.245:57344 in memory (size: 31.7 KiB, free: 2004.6 MiB)\n",
      "25/06/08 22:41:54 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 192.168.18.245:57344 in memory (size: 27.2 KiB, free: 2004.6 MiB)\n",
      "25/06/08 22:41:54 INFO JDBCRDD: closed connection\n",
      "25/06/08 22:41:54 INFO Executor: Finished task 0.0 in stage 31.0 (TID 24). 2493 bytes result sent to driver\n",
      "25/06/08 22:41:54 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 24) in 316 ms on 192.168.18.245 (executor driver) (1/1)\n",
      "25/06/08 22:41:54 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool \n",
      "25/06/08 22:41:54 INFO DAGScheduler: ShuffleMapStage 31 (collect at cmd12.sc:30) finished in 0.321 s\n",
      "25/06/08 22:41:54 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/06/08 22:41:54 INFO DAGScheduler: running: Set()\n",
      "25/06/08 22:41:54 INFO DAGScheduler: waiting: Set()\n",
      "25/06/08 22:41:54 INFO DAGScheduler: failed: Set()\n",
      "25/06/08 22:41:54 INFO ShufflePartitionsUtil: For shuffle(10), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "25/06/08 22:41:54 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.\n",
      "25/06/08 22:41:54 INFO CodeGenerator: Code generated in 4.14625 ms\n",
      "25/06/08 22:41:54 INFO DAGScheduler: Registering RDD 73 (collect at cmd12.sc:30) as input to shuffle 11\n",
      "25/06/08 22:41:54 INFO DAGScheduler: Got map stage job 21 (collect at cmd12.sc:30) with 3 output partitions\n",
      "25/06/08 22:41:54 INFO DAGScheduler: Final stage: ShuffleMapStage 33 (collect at cmd12.sc:30)\n",
      "25/06/08 22:41:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 32)\n",
      "25/06/08 22:41:54 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/08 22:41:54 INFO DAGScheduler: Submitting ShuffleMapStage 33 (MapPartitionsRDD[73] at collect at cmd12.sc:30), which has no missing parents\n",
      "25/06/08 22:41:54 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 54.5 KiB, free 2004.5 MiB)\n",
      "25/06/08 22:41:54 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 23.8 KiB, free 2004.5 MiB)\n",
      "25/06/08 22:41:54 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 192.168.18.245:57344 (size: 23.8 KiB, free: 2004.6 MiB)\n",
      "25/06/08 22:41:54 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1611\n",
      "25/06/08 22:41:54 INFO DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 33 (MapPartitionsRDD[73] at collect at cmd12.sc:30) (first 15 tasks are for partitions Vector(0, 1, 2))\n",
      "25/06/08 22:41:54 INFO TaskSchedulerImpl: Adding task set 33.0 with 3 tasks resource profile 0\n",
      "25/06/08 22:41:54 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 25) (192.168.18.245, executor driver, partition 0, NODE_LOCAL, 8988 bytes) \n",
      "25/06/08 22:41:54 INFO TaskSetManager: Starting task 1.0 in stage 33.0 (TID 26) (192.168.18.245, executor driver, partition 1, NODE_LOCAL, 8988 bytes) \n",
      "25/06/08 22:41:54 INFO TaskSetManager: Starting task 2.0 in stage 33.0 (TID 27) (192.168.18.245, executor driver, partition 2, NODE_LOCAL, 8988 bytes) \n",
      "25/06/08 22:41:54 INFO Executor: Running task 1.0 in stage 33.0 (TID 26)\n",
      "25/06/08 22:41:54 INFO Executor: Running task 0.0 in stage 33.0 (TID 25)\n",
      "25/06/08 22:41:54 INFO Executor: Running task 2.0 in stage 33.0 (TID 27)\n",
      "25/06/08 22:41:54 INFO ShuffleBlockFetcherIterator: Getting 1 (1033.0 KiB) non-empty blocks including 1 (1033.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:41:54 INFO ShuffleBlockFetcherIterator: Getting 1 (1039.0 KiB) non-empty blocks including 1 (1039.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:41:54 INFO ShuffleBlockFetcherIterator: Getting 1 (1470.2 KiB) non-empty blocks including 1 (1470.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:41:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:41:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:41:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:41:54 INFO CodeGenerator: Code generated in 22.211834 ms\n",
      "25/06/08 22:41:54 INFO Executor: Finished task 1.0 in stage 33.0 (TID 26). 5422 bytes result sent to driver\n",
      "25/06/08 22:41:54 INFO Executor: Finished task 0.0 in stage 33.0 (TID 25). 5422 bytes result sent to driver\n",
      "25/06/08 22:41:54 INFO TaskSetManager: Finished task 1.0 in stage 33.0 (TID 26) in 69 ms on 192.168.18.245 (executor driver) (1/3)\n",
      "25/06/08 22:41:54 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 25) in 69 ms on 192.168.18.245 (executor driver) (2/3)\n",
      "25/06/08 22:41:54 INFO Executor: Finished task 2.0 in stage 33.0 (TID 27). 5422 bytes result sent to driver\n",
      "25/06/08 22:41:54 INFO TaskSetManager: Finished task 2.0 in stage 33.0 (TID 27) in 71 ms on 192.168.18.245 (executor driver) (3/3)\n",
      "25/06/08 22:41:54 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool \n",
      "25/06/08 22:41:54 INFO DAGScheduler: ShuffleMapStage 33 (collect at cmd12.sc:30) finished in 0.075 s\n",
      "25/06/08 22:41:54 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/06/08 22:41:54 INFO DAGScheduler: running: Set()\n",
      "25/06/08 22:41:54 INFO DAGScheduler: waiting: Set()\n",
      "25/06/08 22:41:54 INFO DAGScheduler: failed: Set()\n",
      "25/06/08 22:41:54 INFO CodeGenerator: Code generated in 2.262542 ms\n",
      "25/06/08 22:41:54 INFO SparkContext: Starting job: collect at cmd12.sc:30\n",
      "25/06/08 22:41:54 INFO DAGScheduler: Got job 22 (collect at cmd12.sc:30) with 1 output partitions\n",
      "25/06/08 22:41:54 INFO DAGScheduler: Final stage: ResultStage 36 (collect at cmd12.sc:30)\n",
      "25/06/08 22:41:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 35)\n",
      "25/06/08 22:41:54 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/08 22:41:54 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[76] at collect at cmd12.sc:30), which has no missing parents\n",
      "25/06/08 22:41:54 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 13.7 KiB, free 2004.4 MiB)\n",
      "25/06/08 22:41:54 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 2004.4 MiB)\n",
      "25/06/08 22:41:54 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 192.168.18.245:57344 (size: 6.4 KiB, free: 2004.6 MiB)\n",
      "25/06/08 22:41:54 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1611\n",
      "25/06/08 22:41:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[76] at collect at cmd12.sc:30) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/08 22:41:54 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks resource profile 0\n",
      "25/06/08 22:41:54 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 28) (192.168.18.245, executor driver, partition 0, NODE_LOCAL, 8999 bytes) \n",
      "25/06/08 22:41:54 INFO Executor: Running task 0.0 in stage 36.0 (TID 28)\n",
      "25/06/08 22:41:54 INFO ShuffleBlockFetcherIterator: Getting 3 (180.0 B) non-empty blocks including 3 (180.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:41:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:41:54 INFO CodeGenerator: Code generated in 3.715667 ms\n",
      "25/06/08 22:41:54 INFO Executor: Finished task 0.0 in stage 36.0 (TID 28). 3995 bytes result sent to driver\n",
      "25/06/08 22:41:54 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 28) in 9 ms on 192.168.18.245 (executor driver) (1/1)\n",
      "25/06/08 22:41:54 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool \n",
      "25/06/08 22:41:54 INFO DAGScheduler: ResultStage 36 (collect at cmd12.sc:30) finished in 0.011 s\n",
      "25/06/08 22:41:54 INFO DAGScheduler: Job 22 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/06/08 22:41:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 36: Stage finished\n",
      "25/06/08 22:41:54 INFO DAGScheduler: Job 22 finished: collect at cmd12.sc:30, took 0.013660 s\n",
      "25/06/08 22:41:54 INFO CodeGenerator: Code generated in 2.118583 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Resultado Consulta Decimal 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/08 22:41:54 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/08 22:41:54 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/08 22:41:54 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/08 22:41:54 INFO CodeGenerator: Code generated in 7.854208 ms\n",
      "25/06/08 22:41:54 INFO DAGScheduler: Registering RDD 79 (show at cmd12.sc:41) as input to shuffle 12\n",
      "25/06/08 22:41:54 INFO DAGScheduler: Got map stage job 23 (show at cmd12.sc:41) with 1 output partitions\n",
      "25/06/08 22:41:54 INFO DAGScheduler: Final stage: ShuffleMapStage 37 (show at cmd12.sc:41)\n",
      "25/06/08 22:41:54 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/06/08 22:41:54 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/08 22:41:54 INFO DAGScheduler: Submitting ShuffleMapStage 37 (MapPartitionsRDD[79] at show at cmd12.sc:41), which has no missing parents\n",
      "25/06/08 22:41:54 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 52.1 KiB, free 2004.4 MiB)\n",
      "25/06/08 22:41:54 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 22.7 KiB, free 2004.4 MiB)\n",
      "25/06/08 22:41:54 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 192.168.18.245:57344 (size: 22.7 KiB, free: 2004.5 MiB)\n",
      "25/06/08 22:41:54 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1611\n",
      "25/06/08 22:41:54 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 37 (MapPartitionsRDD[79] at show at cmd12.sc:41) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/08 22:41:54 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks resource profile 0\n",
      "25/06/08 22:41:54 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 29) (192.168.18.245, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) \n",
      "25/06/08 22:41:54 INFO Executor: Running task 0.0 in stage 37.0 (TID 29)\n",
      "25/06/08 22:41:54 INFO CodeGenerator: Code generated in 8.799083 ms\n",
      "25/06/08 22:41:54 INFO CodeGenerator: Code generated in 1.491125 ms\n",
      "25/06/08 22:41:54 INFO CodeGenerator: Code generated in 1.52875 ms\n",
      "25/06/08 22:41:55 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 192.168.18.245:57344 in memory (size: 6.4 KiB, free: 2004.5 MiB)\n",
      "25/06/08 22:41:55 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 192.168.18.245:57344 in memory (size: 23.8 KiB, free: 2004.6 MiB)\n",
      "25/06/08 22:41:55 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 192.168.18.245:57344 in memory (size: 21.0 KiB, free: 2004.6 MiB)\n",
      "25/06/08 22:41:55 INFO JDBCRDD: closed connection\n",
      "25/06/08 22:41:55 INFO Executor: Finished task 0.0 in stage 37.0 (TID 29). 2493 bytes result sent to driver\n",
      "25/06/08 22:41:55 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 29) in 343 ms on 192.168.18.245 (executor driver) (1/1)\n",
      "25/06/08 22:41:55 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool \n",
      "25/06/08 22:41:55 INFO DAGScheduler: ShuffleMapStage 37 (show at cmd12.sc:41) finished in 0.346 s\n",
      "25/06/08 22:41:55 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/06/08 22:41:55 INFO DAGScheduler: running: Set()\n",
      "25/06/08 22:41:55 INFO DAGScheduler: waiting: Set()\n",
      "25/06/08 22:41:55 INFO DAGScheduler: failed: Set()\n",
      "25/06/08 22:41:55 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/08 22:41:55 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/08 22:41:55 INFO ShufflePartitionsUtil: For shuffle(12), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "25/06/08 22:41:55 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.\n",
      "25/06/08 22:41:55 INFO CodeGenerator: Code generated in 6.677334 ms\n",
      "25/06/08 22:41:55 INFO DAGScheduler: Registering RDD 82 (show at cmd12.sc:41) as input to shuffle 13\n",
      "25/06/08 22:41:55 INFO DAGScheduler: Got map stage job 24 (show at cmd12.sc:41) with 3 output partitions\n",
      "25/06/08 22:41:55 INFO DAGScheduler: Final stage: ShuffleMapStage 39 (show at cmd12.sc:41)\n",
      "25/06/08 22:41:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 38)\n",
      "25/06/08 22:41:55 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/08 22:41:55 INFO DAGScheduler: Submitting ShuffleMapStage 39 (MapPartitionsRDD[82] at show at cmd12.sc:41), which has no missing parents\n",
      "25/06/08 22:41:55 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 60.3 KiB, free 2004.5 MiB)\n",
      "25/06/08 22:41:55 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 25.8 KiB, free 2004.4 MiB)\n",
      "25/06/08 22:41:55 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 192.168.18.245:57344 (size: 25.8 KiB, free: 2004.6 MiB)\n",
      "25/06/08 22:41:55 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1611\n",
      "25/06/08 22:41:55 INFO DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 39 (MapPartitionsRDD[82] at show at cmd12.sc:41) (first 15 tasks are for partitions Vector(0, 1, 2))\n",
      "25/06/08 22:41:55 INFO TaskSchedulerImpl: Adding task set 39.0 with 3 tasks resource profile 0\n",
      "25/06/08 22:41:55 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 30) (192.168.18.245, executor driver, partition 0, NODE_LOCAL, 8988 bytes) \n",
      "25/06/08 22:41:55 INFO TaskSetManager: Starting task 1.0 in stage 39.0 (TID 31) (192.168.18.245, executor driver, partition 1, NODE_LOCAL, 8988 bytes) \n",
      "25/06/08 22:41:55 INFO TaskSetManager: Starting task 2.0 in stage 39.0 (TID 32) (192.168.18.245, executor driver, partition 2, NODE_LOCAL, 8988 bytes) \n",
      "25/06/08 22:41:55 INFO Executor: Running task 1.0 in stage 39.0 (TID 31)\n",
      "25/06/08 22:41:55 INFO Executor: Running task 2.0 in stage 39.0 (TID 32)\n",
      "25/06/08 22:41:55 INFO Executor: Running task 0.0 in stage 39.0 (TID 30)\n",
      "25/06/08 22:41:55 INFO ShuffleBlockFetcherIterator: Getting 1 (1650.7 KiB) non-empty blocks including 1 (1650.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:41:55 INFO ShuffleBlockFetcherIterator: Getting 1 (1039.0 KiB) non-empty blocks including 1 (1039.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:41:55 INFO ShuffleBlockFetcherIterator: Getting 1 (1024.3 KiB) non-empty blocks including 1 (1024.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:41:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:41:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:41:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:41:55 INFO CodeGenerator: Code generated in 5.723875 ms\n",
      "25/06/08 22:41:55 INFO Executor: Finished task 1.0 in stage 39.0 (TID 31). 5086 bytes result sent to driver\n",
      "25/06/08 22:41:55 INFO TaskSetManager: Finished task 1.0 in stage 39.0 (TID 31) in 77 ms on 192.168.18.245 (executor driver) (1/3)\n",
      "25/06/08 22:41:55 INFO Executor: Finished task 0.0 in stage 39.0 (TID 30). 5086 bytes result sent to driver\n",
      "25/06/08 22:41:55 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 30) in 78 ms on 192.168.18.245 (executor driver) (2/3)\n",
      "25/06/08 22:41:55 INFO Executor: Finished task 2.0 in stage 39.0 (TID 32). 5086 bytes result sent to driver\n",
      "25/06/08 22:41:55 INFO TaskSetManager: Finished task 2.0 in stage 39.0 (TID 32) in 84 ms on 192.168.18.245 (executor driver) (3/3)\n",
      "25/06/08 22:41:55 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool \n",
      "25/06/08 22:41:55 INFO DAGScheduler: ShuffleMapStage 39 (show at cmd12.sc:41) finished in 0.090 s\n",
      "25/06/08 22:41:55 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/06/08 22:41:55 INFO DAGScheduler: running: Set()\n",
      "25/06/08 22:41:55 INFO DAGScheduler: waiting: Set()\n",
      "25/06/08 22:41:55 INFO DAGScheduler: failed: Set()\n",
      "25/06/08 22:41:55 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/08 22:41:55 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/06/08 22:41:55 INFO CodeGenerator: Code generated in 3.648916 ms\n",
      "25/06/08 22:41:55 INFO SparkContext: Starting job: show at cmd12.sc:41\n",
      "25/06/08 22:41:55 INFO DAGScheduler: Got job 25 (show at cmd12.sc:41) with 1 output partitions\n",
      "25/06/08 22:41:55 INFO DAGScheduler: Final stage: ResultStage 42 (show at cmd12.sc:41)\n",
      "25/06/08 22:41:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 41)\n",
      "25/06/08 22:41:55 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/08 22:41:55 INFO DAGScheduler: Submitting ResultStage 42 (MapPartitionsRDD[87] at show at cmd12.sc:41), which has no missing parents\n",
      "25/06/08 22:41:55 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 64.1 KiB, free 2004.4 MiB)\n",
      "25/06/08 22:41:55 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 2004.4 MiB)\n",
      "25/06/08 22:41:55 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 192.168.18.245:57344 (size: 27.9 KiB, free: 2004.5 MiB)\n",
      "25/06/08 22:41:55 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1611\n",
      "25/06/08 22:41:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 42 (MapPartitionsRDD[87] at show at cmd12.sc:41) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/08 22:41:55 INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks resource profile 0\n",
      "25/06/08 22:41:55 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 33) (192.168.18.245, executor driver, partition 0, NODE_LOCAL, 8999 bytes) \n",
      "25/06/08 22:41:55 INFO Executor: Running task 0.0 in stage 42.0 (TID 33)\n",
      "25/06/08 22:41:55 INFO CodeGenerator: Code generated in 4.504458 ms\n",
      "25/06/08 22:41:55 INFO ShuffleBlockFetcherIterator: Getting 3 (3.8 MiB) non-empty blocks including 3 (3.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:41:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:41:55 INFO CodeGenerator: Code generated in 3.321625 ms\n",
      "25/06/08 22:41:55 INFO CodeGenerator: Code generated in 2.076125 ms\n",
      "25/06/08 22:41:55 INFO CodeGenerator: Code generated in 2.035 ms\n",
      "25/06/08 22:41:55 INFO CodeGenerator: Code generated in 3.33975 ms\n",
      "25/06/08 22:41:55 INFO CodeGenerator: Code generated in 1.581917 ms\n",
      "25/06/08 22:41:55 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter\n",
      "25/06/08 22:41:55 INFO Executor: Finished task 0.0 in stage 42.0 (TID 33). 10774 bytes result sent to driver\n",
      "25/06/08 22:41:55 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 33) in 110 ms on 192.168.18.245 (executor driver) (1/1)\n",
      "25/06/08 22:41:55 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool \n",
      "25/06/08 22:41:55 INFO DAGScheduler: ResultStage 42 (show at cmd12.sc:41) finished in 0.113 s\n",
      "25/06/08 22:41:55 INFO DAGScheduler: Job 25 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/06/08 22:41:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 42: Stage finished\n",
      "25/06/08 22:41:55 INFO DAGScheduler: Job 25 finished: show at cmd12.sc:41, took 0.115491 s\n",
      "25/06/08 22:41:55 INFO CodeGenerator: Code generated in 2.994916 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+-------------------+----------------------+-----------+-----------------------+-----+\n",
      "|   cod_contribuyente|  distrito|total_contribuyente|participacion_promedio|num_predios|participacion_total_pct|decil|\n",
      "+--------------------+----------+-------------------+----------------------+-----------+-----------------------+-----+\n",
      "|55351ada81c0f27f8...|JESUS MARI|  963183.3599999999|                 100.0|        599|                 0.8545|    1|\n",
      "|8b23a5f47f37eaa52...|JESUS MARI|          739913.52|                 100.0|         33|                 0.6564|    1|\n",
      "|39ed9d9016f301c73...|JESUS MARI|  593574.1200000013|                 100.0|        368|                 0.5266|    1|\n",
      "|9e17ffa1e26b269ea...|JESUS MARI|  364319.6400000001|                 100.0|        201|                 0.3232|    1|\n",
      "|c7d7cd94d59a8b17c...|JESUS MARI| 339312.60000000003|                 100.0|        147|                  0.301|    1|\n",
      "|139af841d2e577a63...|JESUS MARI|  320959.0800000003|                 100.0|        414|                 0.2847|    1|\n",
      "|2a0199bb8f20b9035...|JESUS MARI| 304931.16000000003|                 100.0|         19|                 0.2705|    1|\n",
      "|2119b2fb48bfa34d8...|JESUS MARI|          295865.64|                 100.0|         11|                 0.2625|    1|\n",
      "|e50b873fbaacca239...|JESUS MARI| 283900.07999999996|                 100.0|         12|                 0.2519|    1|\n",
      "|76186f0fef1d04e20...|JESUS MARI|  251863.9600000001|     6.161444759206798|        353|                 0.2234|    1|\n",
      "|bb2027fde5fabef9a...|JESUS MARI|  247912.8000000002|                 100.0|        270|                 0.2199|    1|\n",
      "|3602b54fdd65ed73c...|JESUS MARI|          238220.88|                 100.0|        252|                 0.2113|    1|\n",
      "|38548de48f1bfb8e5...|JESUS MARI| 210514.91999999998|                 100.0|         39|                 0.1868|    1|\n",
      "|aec78ce615f724235...|JESUS MARI| 188256.71999999986|                 100.0|        298|                  0.167|    1|\n",
      "|64ffb68d3a59f24ac...|JESUS MARI| 161976.96000000005|                 100.0|        174|                 0.1437|    1|\n",
      "|7d5b30392307cb999...|JESUS MARI| 161665.44000000018|                 100.0|        309|                 0.1434|    1|\n",
      "|618096cd051332f24...|JESUS MARI| 159407.52000000008|                 100.0|        213|                 0.1414|    1|\n",
      "|f146cbc8ac205c1da...|JESUS MARI| 151618.55999999994|                 100.0|        409|                 0.1345|    1|\n",
      "|c6fb659ceb11f4b37...|JESUS MARI| 145614.95999999985|                 100.0|        152|                 0.1292|    1|\n",
      "|c53a71558749ce459...|JESUS MARI| 143584.43999999994|                 100.0|        117|                 0.1274|    1|\n",
      "+--------------------+----------+-------------------+----------------------+-----------+-----------------------+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.functions._\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.expressions.Window\u001b[39m\n",
       "\u001b[36mdf\u001b[39m: \u001b[32mDataFrame\u001b[39m = [fecha_corte: int, periodo: int ... 16 more fields]\n",
       "\u001b[36mmapReduce1_Concentracion\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mDataset\u001b[39m[\u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mRow\u001b[39m] = [cod_contribuyente: string, distrito: string ... 2 more fields]\n",
       "\u001b[36mmapReduce2_TotalesContrib\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mDataset\u001b[39m[\u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mRow\u001b[39m] = [cod_contribuyente: string, distrito: string ... 3 more fields]\n",
       "\u001b[36mtotalGeneral\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m1.127245111600002E8\u001b[39m\n",
       "\u001b[36mmapReduce3_Concentracion\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mDataset\u001b[39m[\u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mRow\u001b[39m] = [cod_contribuyente: string, distrito: string ... 5 more fields]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// CONSULTA DECIMAL 2: Análisis de concentración financiera (3 MapReduce)\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.expressions.Window\n",
    "\n",
    "println(\"💰 CONSULTA DECIMAL 2: Análisis de concentración financiera (3 MapReduce)\")\n",
    "\n",
    "val df = spark.table(\"arbitrios_jm\")\n",
    "\n",
    "// MapReduce 1: Calcular monto total por contribuyente\n",
    "val mapReduce1_Concentracion = df.select(\n",
    "  col(\"cod_contribuyente\"),\n",
    "  col(\"distrito\"),\n",
    "  (col(\"monto_parque_jardin\").cast(\"double\") + \n",
    "   col(\"monto_serenazgo\").cast(\"double\") + \n",
    "   col(\"monto_residuos_solidos\").cast(\"double\") + \n",
    "   col(\"monto_barrido_calles\").cast(\"double\")).as(\"monto_total_contrib\"),\n",
    "  col(\"porcentaje_condominio\").cast(\"double\").as(\"participacion\")\n",
    ").filter(col(\"monto_parque_jardin\").isNotNull)\n",
    "\n",
    "// MapReduce 2: Agrupar por contribuyente y calcular totales\n",
    "val mapReduce2_TotalesContrib = mapReduce1_Concentracion.groupBy(\"cod_contribuyente\", \"distrito\")\n",
    "  .agg(\n",
    "    sum(\"monto_total_contrib\").as(\"total_contribuyente\"),\n",
    "    avg(\"participacion\").as(\"participacion_promedio\"),\n",
    "    count(\"*\").as(\"num_predios\")\n",
    "  )\n",
    "  .filter(col(\"num_predios\") > 0)\n",
    "\n",
    "// MapReduce 3: Calcular percentiles y concentración\n",
    "val totalGeneral = mapReduce2_TotalesContrib.agg(sum(\"total_contribuyente\")).collect()(0)(0).asInstanceOf[Double]\n",
    "\n",
    "val mapReduce3_Concentracion = mapReduce2_TotalesContrib\n",
    "  .withColumn(\"participacion_total_pct\", \n",
    "              round(col(\"total_contribuyente\") / lit(totalGeneral) * 100, 4))\n",
    "  .withColumn(\"decil\", \n",
    "              ntile(10).over(Window.orderBy(desc(\"total_contribuyente\"))))\n",
    "  .orderBy(desc(\"total_contribuyente\"))\n",
    "  .limit(20)\n",
    "\n",
    "println(\"📊 Resultado Consulta Decimal 2:\")\n",
    "mapReduce3_Concentracion.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acfcb53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💰 CONSULTA DECIMAL 3: Análisis de eficiencia temporal (3 MapReduce)\n",
      "📊 Resultado Consulta Decimal 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/08 22:41:55 INFO CodeGenerator: Code generated in 9.290125 ms\n",
      "25/06/08 22:41:55 INFO DAGScheduler: Registering RDD 90 (show at cmd13.sc:43) as input to shuffle 14\n",
      "25/06/08 22:41:55 INFO DAGScheduler: Got map stage job 26 (show at cmd13.sc:43) with 1 output partitions\n",
      "25/06/08 22:41:55 INFO DAGScheduler: Final stage: ShuffleMapStage 43 (show at cmd13.sc:43)\n",
      "25/06/08 22:41:55 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/06/08 22:41:55 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/08 22:41:55 INFO DAGScheduler: Submitting ShuffleMapStage 43 (MapPartitionsRDD[90] at show at cmd13.sc:43), which has no missing parents\n",
      "25/06/08 22:41:55 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 63.8 KiB, free 2004.3 MiB)\n",
      "25/06/08 22:41:55 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 26.1 KiB, free 2004.3 MiB)\n",
      "25/06/08 22:41:55 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 192.168.18.245:57344 (size: 26.1 KiB, free: 2004.5 MiB)\n",
      "25/06/08 22:41:55 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1611\n",
      "25/06/08 22:41:55 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 43 (MapPartitionsRDD[90] at show at cmd13.sc:43) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/08 22:41:55 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks resource profile 0\n",
      "25/06/08 22:41:55 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 34) (192.168.18.245, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) \n",
      "25/06/08 22:41:55 INFO Executor: Running task 0.0 in stage 43.0 (TID 34)\n",
      "25/06/08 22:41:55 INFO CodeGenerator: Code generated in 10.3155 ms\n",
      "25/06/08 22:41:55 INFO CodeGenerator: Code generated in 3.287958 ms\n",
      "25/06/08 22:41:55 INFO CodeGenerator: Code generated in 1.295208 ms\n",
      "25/06/08 22:41:55 INFO CodeGenerator: Code generated in 1.764792 ms\n",
      "25/06/08 22:41:55 INFO CodeGenerator: Code generated in 1.771 ms\n",
      "25/06/08 22:41:55 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 192.168.18.245:57344 in memory (size: 25.8 KiB, free: 2004.5 MiB)\n",
      "25/06/08 22:41:55 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 192.168.18.245:57344 in memory (size: 27.9 KiB, free: 2004.6 MiB)\n",
      "25/06/08 22:41:55 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 192.168.18.245:57344 in memory (size: 22.7 KiB, free: 2004.6 MiB)\n",
      "25/06/08 22:41:55 INFO JDBCRDD: closed connection\n",
      "25/06/08 22:41:55 INFO Executor: Finished task 0.0 in stage 43.0 (TID 34). 2493 bytes result sent to driver\n",
      "25/06/08 22:41:55 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 34) in 227 ms on 192.168.18.245 (executor driver) (1/1)\n",
      "25/06/08 22:41:55 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool \n",
      "25/06/08 22:41:55 INFO DAGScheduler: ShuffleMapStage 43 (show at cmd13.sc:43) finished in 0.230 s\n",
      "25/06/08 22:41:55 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/06/08 22:41:55 INFO DAGScheduler: running: Set()\n",
      "25/06/08 22:41:55 INFO DAGScheduler: waiting: Set()\n",
      "25/06/08 22:41:55 INFO DAGScheduler: failed: Set()\n",
      "25/06/08 22:41:55 INFO ShufflePartitionsUtil: For shuffle(14), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "25/06/08 22:41:55 INFO CodeGenerator: Code generated in 3.738334 ms\n",
      "25/06/08 22:41:55 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.\n",
      "25/06/08 22:41:55 INFO CodeGenerator: Code generated in 5.510167 ms\n",
      "25/06/08 22:41:55 INFO SparkContext: Starting job: show at cmd13.sc:43\n",
      "25/06/08 22:41:55 INFO DAGScheduler: Got job 27 (show at cmd13.sc:43) with 1 output partitions\n",
      "25/06/08 22:41:55 INFO DAGScheduler: Final stage: ResultStage 45 (show at cmd13.sc:43)\n",
      "25/06/08 22:41:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 44)\n",
      "25/06/08 22:41:55 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/08 22:41:55 INFO DAGScheduler: Submitting ResultStage 45 (MapPartitionsRDD[94] at show at cmd13.sc:43), which has no missing parents\n",
      "25/06/08 22:41:55 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 79.5 KiB, free 2004.4 MiB)\n",
      "25/06/08 22:41:55 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 31.6 KiB, free 2004.4 MiB)\n",
      "25/06/08 22:41:55 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 192.168.18.245:57344 (size: 31.6 KiB, free: 2004.5 MiB)\n",
      "25/06/08 22:41:55 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1611\n",
      "25/06/08 22:41:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 45 (MapPartitionsRDD[94] at show at cmd13.sc:43) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/08 22:41:55 INFO TaskSchedulerImpl: Adding task set 45.0 with 1 tasks resource profile 0\n",
      "25/06/08 22:41:55 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 35) (192.168.18.245, executor driver, partition 0, NODE_LOCAL, 8999 bytes) \n",
      "25/06/08 22:41:55 INFO Executor: Running task 0.0 in stage 45.0 (TID 35)\n",
      "25/06/08 22:41:55 INFO CodeGenerator: Code generated in 3.772083 ms\n",
      "25/06/08 22:41:55 INFO ShuffleBlockFetcherIterator: Getting 1 (426.0 B) non-empty blocks including 1 (426.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:41:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:41:55 INFO CodeGenerator: Code generated in 6.569417 ms\n",
      "25/06/08 22:41:56 INFO Executor: Finished task 0.0 in stage 45.0 (TID 35). 5233 bytes result sent to driver\n",
      "25/06/08 22:41:56 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 35) in 18 ms on 192.168.18.245 (executor driver) (1/1)\n",
      "25/06/08 22:41:56 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool \n",
      "25/06/08 22:41:56 INFO DAGScheduler: ResultStage 45 (show at cmd13.sc:43) finished in 0.021 s\n",
      "25/06/08 22:41:56 INFO DAGScheduler: Job 27 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/06/08 22:41:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 45: Stage finished\n",
      "25/06/08 22:41:56 INFO DAGScheduler: Job 27 finished: show at cmd13.sc:43, took 0.022813 s\n",
      "25/06/08 22:41:56 INFO CodeGenerator: Code generated in 3.386542 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+---------+-------------------+-----------------------+--------------------+--------------------+----------------+----------------+\n",
      "|periodo|  distrito|registros|eficiencia_promedio|variabilidad_eficiencia|         total_bruto|          total_neto|ratio_neto_bruto|score_eficiencia|\n",
      "+-------+----------+---------+-------------------+-----------------------+--------------------+--------------------+----------------+----------------+\n",
      "|   2025|JESUS MARI|    78294|              64.94|                  47.63|2.0792564919987515E7|2.0706617919987597E7|          0.9959|          1.3578|\n",
      "|   2024|JESUS MARI|    73329|              63.93|                  46.48| 1.949122926999415E7|1.8854118889998067E7|          0.9673|          1.3305|\n",
      "|   2023|JESUS MARI|    69172|               57.3|                  41.83| 1.783041607999438E7|1.5352710509994695E7|           0.861|          1.1794|\n",
      "+-------+----------+---------+-------------------+-----------------------+--------------------+--------------------+----------------+----------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.functions._\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.expressions.Window\u001b[39m\n",
       "\u001b[36mdf\u001b[39m: \u001b[32mDataFrame\u001b[39m = [fecha_corte: int, periodo: int ... 16 more fields]\n",
       "\u001b[36mmapReduce1_Eficiencia\u001b[39m: \u001b[32mDataFrame\u001b[39m = [periodo: int, distrito: string ... 5 more fields]\n",
       "\u001b[36mmapReduce2_EficienciaPeriodo\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mDataset\u001b[39m[\u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mRow\u001b[39m] = [periodo: int, distrito: string ... 5 more fields]\n",
       "\u001b[36mmapReduce3_Tendencias\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mDataset\u001b[39m[\u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mRow\u001b[39m] = [periodo: int, distrito: string ... 7 more fields]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// CONSULTA DECIMAL 3: Análisis de eficiencia temporal (3 MapReduce)\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.expressions.Window\n",
    "\n",
    "println(\"💰 CONSULTA DECIMAL 3: Análisis de eficiencia temporal (3 MapReduce)\")\n",
    "\n",
    "val df = spark.table(\"arbitrios_jm\")\n",
    "\n",
    "// MapReduce 1: Calcular eficiencia por período y registro\n",
    "val mapReduce1_Eficiencia = df.select(\n",
    "  col(\"periodo\").cast(\"int\").as(\"periodo\"),\n",
    "  col(\"distrito\"),\n",
    "  col(\"monto_serenazgo\").cast(\"double\").as(\"monto_bruto\"),\n",
    "  col(\"descuento_tope_serenazgo\").cast(\"double\").as(\"descuento\"),\n",
    "  col(\"porcentaje_condominio\").cast(\"double\").as(\"participacion\")\n",
    ").filter(col(\"periodo\").isNotNull && col(\"monto_serenazgo\").isNotNull)\n",
    ".withColumn(\"monto_neto\", col(\"monto_bruto\") - col(\"descuento\"))\n",
    ".withColumn(\"eficiencia_cobro\", \n",
    "            round(when(col(\"monto_bruto\") =!= 0, col(\"monto_neto\") / col(\"monto_bruto\") * 100).otherwise(0), 2))\n",
    "\n",
    "// MapReduce 2: Agrupar por período y distrito\n",
    "val mapReduce2_EficienciaPeriodo = mapReduce1_Eficiencia.groupBy(\"periodo\", \"distrito\")\n",
    "  .agg(\n",
    "    count(\"*\").as(\"registros\"),\n",
    "    round(avg(\"eficiencia_cobro\"), 2).as(\"eficiencia_promedio\"),\n",
    "    round(stddev(\"eficiencia_cobro\"), 2).as(\"variabilidad_eficiencia\"),\n",
    "    sum(\"monto_bruto\").as(\"total_bruto\"),\n",
    "    sum(\"monto_neto\").as(\"total_neto\")\n",
    "  )\n",
    "  .filter(col(\"registros\") > 10)\n",
    "\n",
    "// MapReduce 3: Calcular métricas comparativas y tendencias\n",
    "val mapReduce3_Tendencias = mapReduce2_EficienciaPeriodo\n",
    "  .withColumn(\"ratio_neto_bruto\", \n",
    "              round(when(col(\"total_bruto\") =!= 0, col(\"total_neto\") / col(\"total_bruto\")).otherwise(0), 4))\n",
    "  .withColumn(\"score_eficiencia\", \n",
    "              round(when(col(\"variabilidad_eficiencia\") =!= 0, \n",
    "                         col(\"eficiencia_promedio\") * col(\"ratio_neto_bruto\") / col(\"variabilidad_eficiencia\"))\n",
    "                    .otherwise(0), 4))\n",
    "  .orderBy(desc(\"score_eficiencia\"))\n",
    "\n",
    "println(\"📊 Resultado Consulta Decimal 3:\")\n",
    "mapReduce3_Tendencias.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8e658eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 1. MOSTRAR COLUMNAS ESPECÍFICAS\n",
      "📊 Columnas específicas seleccionadas:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/08 22:41:56 INFO CodeGenerator: Code generated in 3.770292 ms\n",
      "25/06/08 22:41:56 INFO SparkContext: Starting job: show at cmd14.sc:18\n",
      "25/06/08 22:41:56 INFO DAGScheduler: Got job 28 (show at cmd14.sc:18) with 1 output partitions\n",
      "25/06/08 22:41:56 INFO DAGScheduler: Final stage: ResultStage 46 (show at cmd14.sc:18)\n",
      "25/06/08 22:41:56 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/06/08 22:41:56 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/08 22:41:56 INFO DAGScheduler: Submitting ResultStage 46 (MapPartitionsRDD[97] at show at cmd14.sc:18), which has no missing parents\n",
      "25/06/08 22:41:56 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 12.9 KiB, free 2004.4 MiB)\n",
      "25/06/08 22:41:56 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 2004.4 MiB)\n",
      "25/06/08 22:41:56 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 192.168.18.245:57344 (size: 6.4 KiB, free: 2004.5 MiB)\n",
      "25/06/08 22:41:56 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1611\n",
      "25/06/08 22:41:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 46 (MapPartitionsRDD[97] at show at cmd14.sc:18) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/08 22:41:56 INFO TaskSchedulerImpl: Adding task set 46.0 with 1 tasks resource profile 0\n",
      "25/06/08 22:41:56 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 36) (192.168.18.245, executor driver, partition 0, PROCESS_LOCAL, 8845 bytes) \n",
      "25/06/08 22:41:56 INFO Executor: Running task 0.0 in stage 46.0 (TID 36)\n",
      "25/06/08 22:41:56 INFO CodeGenerator: Code generated in 2.606791 ms\n",
      "25/06/08 22:41:56 INFO JDBCRDD: closed connection\n",
      "25/06/08 22:41:56 INFO Executor: Finished task 0.0 in stage 46.0 (TID 36). 2161 bytes result sent to driver\n",
      "25/06/08 22:41:56 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 36) in 124 ms on 192.168.18.245 (executor driver) (1/1)\n",
      "25/06/08 22:41:56 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool \n",
      "25/06/08 22:41:56 INFO DAGScheduler: ResultStage 46 (show at cmd14.sc:18) finished in 0.127 s\n",
      "25/06/08 22:41:56 INFO DAGScheduler: Job 28 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/06/08 22:41:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 46: Stage finished\n",
      "25/06/08 22:41:56 INFO DAGScheduler: Job 28 finished: show at cmd14.sc:18, took 0.128822 s\n",
      "25/06/08 22:41:56 INFO CodeGenerator: Code generated in 2.348166 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+-------+---------------+-------------------+\n",
      "|   cod_contribuyente|  distrito|periodo|monto_serenazgo|monto_parque_jardin|\n",
      "+--------------------+----------+-------+---------------+-------------------+\n",
      "|1185ae73bff8b13e1...|JESUS MARI|   2025|         333.36|             272.40|\n",
      "|8d8953f65b09e4c51...|JESUS MARI|   2025|         333.36|             272.40|\n",
      "|4ae0fb6f97d77457c...|JESUS MARI|   2025|         333.36|             272.40|\n",
      "|c2b54eb47f53d21f8...|JESUS MARI|   2025|         333.36|             272.40|\n",
      "|23e90633bf8fc6a60...|JESUS MARI|   2025|         333.36|             272.40|\n",
      "|23e90633bf8fc6a60...|JESUS MARI|   2025|           0.00|               0.00|\n",
      "|358a3d5cd904ff2c1...|JESUS MARI|   2025|         333.36|             272.40|\n",
      "|fb88c78fcbaa2f891...|JESUS MARI|   2025|         333.36|             272.40|\n",
      "|8ee43da603a07ac3b...|JESUS MARI|   2025|           0.00|               0.00|\n",
      "|8ee43da603a07ac3b...|JESUS MARI|   2025|           0.00|               0.00|\n",
      "+--------------------+----------+-------+---------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.functions._\u001b[39m\n",
       "\u001b[36mdf\u001b[39m: \u001b[32mDataFrame\u001b[39m = [fecha_corte: int, periodo: int ... 16 more fields]\n",
       "\u001b[36mcolumnasEspecificas\u001b[39m: \u001b[32mDataFrame\u001b[39m = [cod_contribuyente: string, distrito: string ... 3 more fields]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// 1. MOSTRAR COLUMNAS ESPECÍFICAS DE LAS TABLAS\n",
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "println(\"📋 1. MOSTRAR COLUMNAS ESPECÍFICAS\")\n",
    "\n",
    "val df = spark.table(\"arbitrios_jm\")\n",
    "\n",
    "// Seleccionar columnas específicas\n",
    "val columnasEspecificas = df.select(\n",
    "  col(\"cod_contribuyente\"), \n",
    "  col(\"distrito\"), \n",
    "  col(\"periodo\"),\n",
    "  col(\"monto_serenazgo\"),\n",
    "  col(\"monto_parque_jardin\")\n",
    ")\n",
    "\n",
    "println(\"📊 Columnas específicas seleccionadas:\")\n",
    "columnasEspecificas.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7802a0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 2. UTILIZAR COMANDO FILTER\n",
      "📊 Registros filtrados por distrito JESUS MARIA y monto_serenazgo > 100:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/08 22:41:56 INFO CodeGenerator: Code generated in 4.510542 ms\n",
      "25/06/08 22:41:56 INFO SparkContext: Starting job: show at cmd15.sc:11\n",
      "25/06/08 22:41:56 INFO DAGScheduler: Got job 29 (show at cmd15.sc:11) with 1 output partitions\n",
      "25/06/08 22:41:56 INFO DAGScheduler: Final stage: ResultStage 47 (show at cmd15.sc:11)\n",
      "25/06/08 22:41:56 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/06/08 22:41:56 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/08 22:41:56 INFO DAGScheduler: Submitting ResultStage 47 (MapPartitionsRDD[100] at show at cmd15.sc:11), which has no missing parents\n",
      "25/06/08 22:41:56 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 14.3 KiB, free 2004.4 MiB)\n",
      "25/06/08 22:41:56 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 7.1 KiB, free 2004.4 MiB)\n",
      "25/06/08 22:41:56 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 192.168.18.245:57344 (size: 7.1 KiB, free: 2004.5 MiB)\n",
      "25/06/08 22:41:56 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1611\n",
      "25/06/08 22:41:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 47 (MapPartitionsRDD[100] at show at cmd15.sc:11) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/08 22:41:56 INFO TaskSchedulerImpl: Adding task set 47.0 with 1 tasks resource profile 0\n",
      "25/06/08 22:41:56 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 37) (192.168.18.245, executor driver, partition 0, PROCESS_LOCAL, 8845 bytes) \n",
      "25/06/08 22:41:56 INFO Executor: Running task 0.0 in stage 47.0 (TID 37)\n",
      "25/06/08 22:41:56 INFO CodeGenerator: Code generated in 10.153125 ms\n",
      "25/06/08 22:41:56 INFO JDBCRDD: closed connection\n",
      "25/06/08 22:41:56 INFO Executor: Finished task 0.0 in stage 47.0 (TID 37). 1465 bytes result sent to driver\n",
      "25/06/08 22:41:56 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 37) in 42 ms on 192.168.18.245 (executor driver) (1/1)\n",
      "25/06/08 22:41:56 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool \n",
      "25/06/08 22:41:56 INFO DAGScheduler: ResultStage 47 (show at cmd15.sc:11) finished in 0.046 s\n",
      "25/06/08 22:41:56 INFO DAGScheduler: Job 29 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/06/08 22:41:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 47: Stage finished\n",
      "25/06/08 22:41:56 INFO DAGScheduler: Job 29 finished: show at cmd15.sc:11, took 0.047796 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------+---------------+-------+\n",
      "|cod_contribuyente|distrito|monto_serenazgo|periodo|\n",
      "+-----------------+--------+---------------+-------+\n",
      "+-----------------+--------+---------------+-------+\n",
      "\n",
      "📊 Registros filtrados con condiciones múltiples:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/08 22:41:56 INFO CodeGenerator: Code generated in 3.768958 ms\n",
      "25/06/08 22:41:56 INFO SparkContext: Starting job: show at cmd15.sc:21\n",
      "25/06/08 22:41:56 INFO DAGScheduler: Got job 30 (show at cmd15.sc:21) with 1 output partitions\n",
      "25/06/08 22:41:56 INFO DAGScheduler: Final stage: ResultStage 48 (show at cmd15.sc:21)\n",
      "25/06/08 22:41:56 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/06/08 22:41:56 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/08 22:41:56 INFO DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[103] at show at cmd15.sc:21), which has no missing parents\n",
      "25/06/08 22:41:56 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 13.9 KiB, free 2004.4 MiB)\n",
      "25/06/08 22:41:56 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 6.9 KiB, free 2004.3 MiB)\n",
      "25/06/08 22:41:56 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 192.168.18.245:57344 (size: 6.9 KiB, free: 2004.5 MiB)\n",
      "25/06/08 22:41:56 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1611\n",
      "25/06/08 22:41:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 48 (MapPartitionsRDD[103] at show at cmd15.sc:21) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/08 22:41:56 INFO TaskSchedulerImpl: Adding task set 48.0 with 1 tasks resource profile 0\n",
      "25/06/08 22:41:56 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 38) (192.168.18.245, executor driver, partition 0, PROCESS_LOCAL, 8845 bytes) \n",
      "25/06/08 22:41:56 INFO Executor: Running task 0.0 in stage 48.0 (TID 38)\n",
      "25/06/08 22:41:56 INFO CodeGenerator: Code generated in 4.0745 ms\n",
      "25/06/08 22:41:56 INFO JDBCRDD: closed connection\n",
      "25/06/08 22:41:56 INFO Executor: Finished task 0.0 in stage 48.0 (TID 38). 1593 bytes result sent to driver\n",
      "25/06/08 22:41:56 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 38) in 73 ms on 192.168.18.245 (executor driver) (1/1)\n",
      "25/06/08 22:41:56 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool \n",
      "25/06/08 22:41:56 INFO DAGScheduler: ResultStage 48 (show at cmd15.sc:21) finished in 0.078 s\n",
      "25/06/08 22:41:56 INFO DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/06/08 22:41:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 48: Stage finished\n",
      "25/06/08 22:41:56 INFO DAGScheduler: Job 30 finished: show at cmd15.sc:21, took 0.079434 s\n",
      "25/06/08 22:41:56 INFO CodeGenerator: Code generated in 1.754709 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+-------------------+\n",
      "|  distrito|periodo|monto_parque_jardin|\n",
      "+----------+-------+-------------------+\n",
      "|JESUS MARI|   2025|             272.40|\n",
      "|JESUS MARI|   2025|             272.40|\n",
      "|JESUS MARI|   2025|             272.40|\n",
      "|JESUS MARI|   2025|             272.40|\n",
      "|JESUS MARI|   2025|             272.40|\n",
      "|JESUS MARI|   2025|             272.40|\n",
      "|JESUS MARI|   2025|             272.40|\n",
      "|JESUS MARI|   2025|             136.20|\n",
      "|JESUS MARI|   2025|             136.20|\n",
      "|JESUS MARI|   2025|             272.40|\n",
      "+----------+-------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mfiltradoPorDistrito\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mDataset\u001b[39m[\u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mRow\u001b[39m] = [fecha_corte: int, periodo: int ... 16 more fields]\n",
       "\u001b[36mfiltroComplejo\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mDataset\u001b[39m[\u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mRow\u001b[39m] = [fecha_corte: int, periodo: int ... 16 more fields]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// 2. UTILIZAR EL COMANDO FILTER\n",
    "println(\"🔍 2. UTILIZAR COMANDO FILTER\")\n",
    "\n",
    "// Filter por distrito y montos mayores a cierto valor\n",
    "val filtradoPorDistrito = df.filter(\n",
    "  col(\"distrito\") === \"JESUS MARIA\" && \n",
    "  col(\"monto_serenazgo\").cast(\"double\") > 100\n",
    ")\n",
    "\n",
    "println(\"📊 Registros filtrados por distrito JESUS MARIA y monto_serenazgo > 100:\")\n",
    "filtradoPorDistrito.select(\"cod_contribuyente\", \"distrito\", \"monto_serenazgo\", \"periodo\").show(10)\n",
    "\n",
    "// Filter con múltiples condiciones\n",
    "val filtroComplejo = df.filter(\n",
    "  col(\"periodo\").cast(\"int\") >= 2020 && \n",
    "  col(\"monto_parque_jardin\").cast(\"double\") > 50 &&\n",
    "  col(\"distrito\").isNotNull\n",
    ")\n",
    "\n",
    "println(\"📊 Registros filtrados con condiciones múltiples:\")\n",
    "filtroComplejo.select(\"distrito\", \"periodo\", \"monto_parque_jardin\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a9e8da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈 3. MOSTRAR INFORMACIÓN ORDENADA\n",
      "📊 Registros ordenados por monto_serenazgo (descendente):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/08 22:41:56 INFO CodeGenerator: Code generated in 2.234708 ms\n",
      "25/06/08 22:41:56 INFO SparkContext: Starting job: show at cmd16.sc:12\n",
      "25/06/08 22:41:56 INFO DAGScheduler: Got job 31 (show at cmd16.sc:12) with 1 output partitions\n",
      "25/06/08 22:41:56 INFO DAGScheduler: Final stage: ResultStage 49 (show at cmd16.sc:12)\n",
      "25/06/08 22:41:56 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/06/08 22:41:56 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/08 22:41:56 INFO DAGScheduler: Submitting ResultStage 49 (MapPartitionsRDD[107] at show at cmd16.sc:12), which has no missing parents\n",
      "25/06/08 22:41:56 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 14.4 KiB, free 2004.3 MiB)\n",
      "25/06/08 22:41:56 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 7.1 KiB, free 2004.3 MiB)\n",
      "25/06/08 22:41:56 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 192.168.18.245:57344 (size: 7.1 KiB, free: 2004.5 MiB)\n",
      "25/06/08 22:41:56 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1611\n",
      "25/06/08 22:41:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 49 (MapPartitionsRDD[107] at show at cmd16.sc:12) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/08 22:41:56 INFO TaskSchedulerImpl: Adding task set 49.0 with 1 tasks resource profile 0\n",
      "25/06/08 22:41:56 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 39) (192.168.18.245, executor driver, partition 0, PROCESS_LOCAL, 8845 bytes) \n",
      "25/06/08 22:41:56 INFO Executor: Running task 0.0 in stage 49.0 (TID 39)\n",
      "25/06/08 22:41:56 INFO CodeGenerator: Code generated in 2.0245 ms\n",
      "25/06/08 22:41:56 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 192.168.18.245:57344 in memory (size: 6.4 KiB, free: 2004.5 MiB)\n",
      "25/06/08 22:41:56 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 192.168.18.245:57344 in memory (size: 26.1 KiB, free: 2004.5 MiB)\n",
      "25/06/08 22:41:56 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 192.168.18.245:57344 in memory (size: 31.6 KiB, free: 2004.6 MiB)\n",
      "25/06/08 22:41:56 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 192.168.18.245:57344 in memory (size: 7.1 KiB, free: 2004.6 MiB)\n",
      "25/06/08 22:41:56 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 192.168.18.245:57344 in memory (size: 6.9 KiB, free: 2004.6 MiB)\n",
      "25/06/08 22:41:56 INFO JDBCRDD: closed connection\n",
      "25/06/08 22:41:56 INFO Executor: Finished task 0.0 in stage 49.0 (TID 39). 3576 bytes result sent to driver\n",
      "25/06/08 22:41:56 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 39) in 149 ms on 192.168.18.245 (executor driver) (1/1)\n",
      "25/06/08 22:41:56 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool \n",
      "25/06/08 22:41:56 INFO DAGScheduler: ResultStage 49 (show at cmd16.sc:12) finished in 0.154 s\n",
      "25/06/08 22:41:56 INFO DAGScheduler: Job 31 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/06/08 22:41:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 49: Stage finished\n",
      "25/06/08 22:41:56 INFO DAGScheduler: Job 31 finished: show at cmd16.sc:12, took 0.155343 s\n",
      "25/06/08 22:41:56 INFO CodeGenerator: Code generated in 2.711334 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+---------------+\n",
      "|   cod_contribuyente|  distrito|monto_serenazgo|\n",
      "+--------------------+----------+---------------+\n",
      "|539811369851406ad...|JESUS MARI|       27102.12|\n",
      "|904441682e97b7666...|JESUS MARI|       27102.12|\n",
      "|8b23a5f47f37eaa52...|JESUS MARI|        26716.8|\n",
      "|19134531c323f03ab...|JESUS MARI|        26716.8|\n",
      "|8fd3ec468552fdda2...|JESUS MARI|        26716.8|\n",
      "|2a0199bb8f20b9035...|JESUS MARI|        26716.8|\n",
      "|2a0199bb8f20b9035...|JESUS MARI|        26716.8|\n",
      "|2a0199bb8f20b9035...|JESUS MARI|        26716.8|\n",
      "|2a0199bb8f20b9035...|JESUS MARI|        26716.8|\n",
      "|8b23a5f47f37eaa52...|JESUS MARI|        26716.8|\n",
      "|8b23a5f47f37eaa52...|JESUS MARI|        26716.8|\n",
      "|8b23a5f47f37eaa52...|JESUS MARI|        26716.8|\n",
      "|8b23a5f47f37eaa52...|JESUS MARI|        26716.8|\n",
      "|8b23a5f47f37eaa52...|JESUS MARI|        26716.8|\n",
      "|8b23a5f47f37eaa52...|JESUS MARI|        26716.8|\n",
      "+--------------------+----------+---------------+\n",
      "only showing top 15 rows\n",
      "\n",
      "📊 Registros ordenados por distrito (asc), período (desc), monto_parque (desc):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/08 22:41:56 INFO CodeGenerator: Code generated in 7.025667 ms\n",
      "25/06/08 22:41:56 INFO DAGScheduler: Registering RDD 110 (show at cmd16.sc:27) as input to shuffle 15\n",
      "25/06/08 22:41:56 INFO DAGScheduler: Got map stage job 32 (show at cmd16.sc:27) with 1 output partitions\n",
      "25/06/08 22:41:56 INFO DAGScheduler: Final stage: ShuffleMapStage 50 (show at cmd16.sc:27)\n",
      "25/06/08 22:41:56 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/06/08 22:41:56 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/08 22:41:56 INFO DAGScheduler: Submitting ShuffleMapStage 50 (MapPartitionsRDD[110] at show at cmd16.sc:27), which has no missing parents\n",
      "25/06/08 22:41:56 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 39.7 KiB, free 2004.5 MiB)\n",
      "25/06/08 22:41:56 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 18.3 KiB, free 2004.5 MiB)\n",
      "25/06/08 22:41:56 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 192.168.18.245:57344 (size: 18.3 KiB, free: 2004.6 MiB)\n",
      "25/06/08 22:41:56 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1611\n",
      "25/06/08 22:41:56 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 50 (MapPartitionsRDD[110] at show at cmd16.sc:27) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/08 22:41:56 INFO TaskSchedulerImpl: Adding task set 50.0 with 1 tasks resource profile 0\n",
      "25/06/08 22:41:56 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 40) (192.168.18.245, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) \n",
      "25/06/08 22:41:56 INFO Executor: Running task 0.0 in stage 50.0 (TID 40)\n",
      "25/06/08 22:41:57 INFO CodeGenerator: Code generated in 7.433917 ms\n",
      "25/06/08 22:41:57 INFO CodeGenerator: Code generated in 3.178458 ms\n",
      "25/06/08 22:41:57 INFO CodeGenerator: Code generated in 1.121958 ms\n",
      "25/06/08 22:41:57 INFO JDBCRDD: closed connection\n",
      "25/06/08 22:41:57 INFO Executor: Finished task 0.0 in stage 50.0 (TID 40). 2450 bytes result sent to driver\n",
      "25/06/08 22:41:57 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 40) in 190 ms on 192.168.18.245 (executor driver) (1/1)\n",
      "25/06/08 22:41:57 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool \n",
      "25/06/08 22:41:57 INFO DAGScheduler: ShuffleMapStage 50 (show at cmd16.sc:27) finished in 0.193 s\n",
      "25/06/08 22:41:57 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/06/08 22:41:57 INFO DAGScheduler: running: Set()\n",
      "25/06/08 22:41:57 INFO DAGScheduler: waiting: Set()\n",
      "25/06/08 22:41:57 INFO DAGScheduler: failed: Set()\n",
      "25/06/08 22:41:57 INFO ShufflePartitionsUtil: For shuffle(15), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "25/06/08 22:41:57 INFO CodeGenerator: Code generated in 3.485 ms\n",
      "25/06/08 22:41:57 INFO CodeGenerator: Code generated in 6.896542 ms\n",
      "25/06/08 22:41:57 INFO SparkContext: Starting job: show at cmd16.sc:27\n",
      "25/06/08 22:41:57 INFO DAGScheduler: Got job 33 (show at cmd16.sc:27) with 1 output partitions\n",
      "25/06/08 22:41:57 INFO DAGScheduler: Final stage: ResultStage 52 (show at cmd16.sc:27)\n",
      "25/06/08 22:41:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 51)\n",
      "25/06/08 22:41:57 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/08 22:41:57 INFO DAGScheduler: Submitting ResultStage 52 (MapPartitionsRDD[114] at show at cmd16.sc:27), which has no missing parents\n",
      "25/06/08 22:41:57 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 49.0 KiB, free 2004.5 MiB)\n",
      "25/06/08 22:41:57 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 22.0 KiB, free 2004.5 MiB)\n",
      "25/06/08 22:41:57 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 192.168.18.245:57344 (size: 22.0 KiB, free: 2004.6 MiB)\n",
      "25/06/08 22:41:57 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1611\n",
      "25/06/08 22:41:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 52 (MapPartitionsRDD[114] at show at cmd16.sc:27) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/08 22:41:57 INFO TaskSchedulerImpl: Adding task set 52.0 with 1 tasks resource profile 0\n",
      "25/06/08 22:41:57 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 41) (192.168.18.245, executor driver, partition 0, NODE_LOCAL, 8999 bytes) \n",
      "25/06/08 22:41:57 INFO Executor: Running task 0.0 in stage 52.0 (TID 41)\n",
      "25/06/08 22:41:57 INFO CodeGenerator: Code generated in 4.11425 ms\n",
      "25/06/08 22:41:57 INFO ShuffleBlockFetcherIterator: Getting 1 (33.0 KiB) non-empty blocks including 1 (33.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:41:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:41:57 INFO CodeGenerator: Code generated in 7.198792 ms\n",
      "25/06/08 22:41:57 INFO Executor: Finished task 0.0 in stage 52.0 (TID 41). 5883 bytes result sent to driver\n",
      "25/06/08 22:41:57 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 41) in 24 ms on 192.168.18.245 (executor driver) (1/1)\n",
      "25/06/08 22:41:57 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool \n",
      "25/06/08 22:41:57 INFO DAGScheduler: ResultStage 52 (show at cmd16.sc:27) finished in 0.027 s\n",
      "25/06/08 22:41:57 INFO DAGScheduler: Job 33 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/06/08 22:41:57 INFO TaskSchedulerImpl: Killing all running tasks in stage 52: Stage finished\n",
      "25/06/08 22:41:57 INFO DAGScheduler: Job 33 finished: show at cmd16.sc:27, took 0.029712 s\n",
      "25/06/08 22:41:57 INFO CodeGenerator: Code generated in 2.710958 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+------------+\n",
      "|  distrito|periodo|monto_parque|\n",
      "+----------+-------+------------+\n",
      "|JESUS MARI|   2025|       284.4|\n",
      "|JESUS MARI|   2025|      275.53|\n",
      "|JESUS MARI|   2025|       272.4|\n",
      "|JESUS MARI|   2025|      269.68|\n",
      "|JESUS MARI|   2025|       264.8|\n",
      "|JESUS MARI|   2025|      261.04|\n",
      "|JESUS MARI|   2025|      260.71|\n",
      "|JESUS MARI|   2025|      254.26|\n",
      "|JESUS MARI|   2025|      250.92|\n",
      "|JESUS MARI|   2025|      249.71|\n",
      "|JESUS MARI|   2025|      249.68|\n",
      "|JESUS MARI|   2025|      248.85|\n",
      "|JESUS MARI|   2025|      248.07|\n",
      "|JESUS MARI|   2025|      245.16|\n",
      "|JESUS MARI|   2025|      239.71|\n",
      "+----------+-------+------------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mordenadoPorMonto\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mDataset\u001b[39m[\u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mRow\u001b[39m] = [cod_contribuyente: string, distrito: string ... 1 more field]\n",
       "\u001b[36mordenMultiple\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mDataset\u001b[39m[\u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mRow\u001b[39m] = [distrito: string, periodo: int ... 1 more field]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// 3. MOSTRAR INFORMACIÓN ORDENADA\n",
    "println(\"📈 3. MOSTRAR INFORMACIÓN ORDENADA\")\n",
    "\n",
    "// Ordenar por monto_serenazgo descendente\n",
    "val ordenadoPorMonto = df.select(\n",
    "  col(\"cod_contribuyente\"),\n",
    "  col(\"distrito\"),\n",
    "  col(\"monto_serenazgo\").cast(\"double\").as(\"monto_serenazgo\")\n",
    ").orderBy(desc(\"monto_serenazgo\"))\n",
    "\n",
    "println(\"📊 Registros ordenados por monto_serenazgo (descendente):\")\n",
    "ordenadoPorMonto.show(15)\n",
    "\n",
    "// Ordenar por múltiples columnas\n",
    "val ordenMultiple = df.select(\n",
    "  col(\"distrito\"),\n",
    "  col(\"periodo\").cast(\"int\").as(\"periodo\"),\n",
    "  col(\"monto_parque_jardin\").cast(\"double\").as(\"monto_parque\")\n",
    ").filter(\n",
    "  col(\"distrito\").isNotNull && \n",
    "  col(\"periodo\").isNotNull && \n",
    "  col(\"monto_parque_jardin\").isNotNull\n",
    ").dropDuplicates()\n",
    ".orderBy(asc(\"distrito\"), desc(\"periodo\"), desc(\"monto_parque\"))\n",
    "\n",
    "println(\"📊 Registros ordenados por distrito (asc), período (desc), monto_parque (desc):\")\n",
    "ordenMultiple.show(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "608b3627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 4. UTILIZAR GROUPBY Y COUNT\n",
      "📊 Conteo por distrito:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/08 22:41:57 INFO CodeGenerator: Code generated in 6.833958 ms\n",
      "25/06/08 22:41:57 INFO DAGScheduler: Registering RDD 117 (show at cmd17.sc:10) as input to shuffle 16\n",
      "25/06/08 22:41:57 INFO DAGScheduler: Got map stage job 34 (show at cmd17.sc:10) with 1 output partitions\n",
      "25/06/08 22:41:57 INFO DAGScheduler: Final stage: ShuffleMapStage 53 (show at cmd17.sc:10)\n",
      "25/06/08 22:41:57 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/06/08 22:41:57 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/08 22:41:57 INFO DAGScheduler: Submitting ShuffleMapStage 53 (MapPartitionsRDD[117] at show at cmd17.sc:10), which has no missing parents\n",
      "25/06/08 22:41:57 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 34.9 KiB, free 2004.4 MiB)\n",
      "25/06/08 22:41:57 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 16.5 KiB, free 2004.4 MiB)\n",
      "25/06/08 22:41:57 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 192.168.18.245:57344 (size: 16.5 KiB, free: 2004.5 MiB)\n",
      "25/06/08 22:41:57 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1611\n",
      "25/06/08 22:41:57 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 53 (MapPartitionsRDD[117] at show at cmd17.sc:10) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/08 22:41:57 INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks resource profile 0\n",
      "25/06/08 22:41:57 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 42) (192.168.18.245, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) \n",
      "25/06/08 22:41:57 INFO Executor: Running task 0.0 in stage 53.0 (TID 42)\n",
      "25/06/08 22:41:57 INFO CodeGenerator: Code generated in 5.883917 ms\n",
      "25/06/08 22:41:57 INFO CodeGenerator: Code generated in 1.098542 ms\n",
      "25/06/08 22:41:57 INFO CodeGenerator: Code generated in 1.057708 ms\n",
      "25/06/08 22:41:57 INFO JDBCRDD: closed connection\n",
      "25/06/08 22:41:57 INFO Executor: Finished task 0.0 in stage 53.0 (TID 42). 2450 bytes result sent to driver\n",
      "25/06/08 22:41:57 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 42) in 102 ms on 192.168.18.245 (executor driver) (1/1)\n",
      "25/06/08 22:41:57 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool \n",
      "25/06/08 22:41:57 INFO DAGScheduler: ShuffleMapStage 53 (show at cmd17.sc:10) finished in 0.106 s\n",
      "25/06/08 22:41:57 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/06/08 22:41:57 INFO DAGScheduler: running: Set()\n",
      "25/06/08 22:41:57 INFO DAGScheduler: waiting: Set()\n",
      "25/06/08 22:41:57 INFO DAGScheduler: failed: Set()\n",
      "25/06/08 22:41:57 INFO ShufflePartitionsUtil: For shuffle(16), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "25/06/08 22:41:57 INFO CodeGenerator: Code generated in 1.8595 ms\n",
      "25/06/08 22:41:57 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.\n",
      "25/06/08 22:41:57 INFO CodeGenerator: Code generated in 2.588125 ms\n",
      "25/06/08 22:41:57 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 192.168.18.245:57344 in memory (size: 16.5 KiB, free: 2004.6 MiB)\n",
      "25/06/08 22:41:57 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 192.168.18.245:57344 in memory (size: 7.1 KiB, free: 2004.6 MiB)\n",
      "25/06/08 22:41:57 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 192.168.18.245:57344 in memory (size: 18.3 KiB, free: 2004.6 MiB)\n",
      "25/06/08 22:41:57 INFO SparkContext: Starting job: show at cmd17.sc:10\n",
      "25/06/08 22:41:57 INFO DAGScheduler: Got job 35 (show at cmd17.sc:10) with 1 output partitions\n",
      "25/06/08 22:41:57 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 192.168.18.245:57344 in memory (size: 22.0 KiB, free: 2004.6 MiB)\n",
      "25/06/08 22:41:57 INFO DAGScheduler: Final stage: ResultStage 55 (show at cmd17.sc:10)\n",
      "25/06/08 22:41:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 54)\n",
      "25/06/08 22:41:57 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/08 22:41:57 INFO DAGScheduler: Submitting ResultStage 55 (MapPartitionsRDD[121] at show at cmd17.sc:10), which has no missing parents\n",
      "25/06/08 22:41:57 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 39.1 KiB, free 2004.6 MiB)\n",
      "25/06/08 22:41:57 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 18.5 KiB, free 2004.5 MiB)\n",
      "25/06/08 22:41:57 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 192.168.18.245:57344 (size: 18.5 KiB, free: 2004.6 MiB)\n",
      "25/06/08 22:41:57 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1611\n",
      "25/06/08 22:41:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 55 (MapPartitionsRDD[121] at show at cmd17.sc:10) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/08 22:41:57 INFO TaskSchedulerImpl: Adding task set 55.0 with 1 tasks resource profile 0\n",
      "25/06/08 22:41:57 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 43) (192.168.18.245, executor driver, partition 0, NODE_LOCAL, 8999 bytes) \n",
      "25/06/08 22:41:57 INFO Executor: Running task 0.0 in stage 55.0 (TID 43)\n",
      "25/06/08 22:41:57 INFO CodeGenerator: Code generated in 2.233167 ms\n",
      "25/06/08 22:41:57 INFO ShuffleBlockFetcherIterator: Getting 1 (148.0 B) non-empty blocks including 1 (148.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:41:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:41:57 INFO CodeGenerator: Code generated in 3.404542 ms\n",
      "25/06/08 22:41:57 INFO Executor: Finished task 0.0 in stage 55.0 (TID 43). 4936 bytes result sent to driver\n",
      "25/06/08 22:41:57 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 43) in 13 ms on 192.168.18.245 (executor driver) (1/1)\n",
      "25/06/08 22:41:57 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool \n",
      "25/06/08 22:41:57 INFO DAGScheduler: ResultStage 55 (show at cmd17.sc:10) finished in 0.015 s\n",
      "25/06/08 22:41:57 INFO DAGScheduler: Job 35 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/06/08 22:41:57 INFO TaskSchedulerImpl: Killing all running tasks in stage 55: Stage finished\n",
      "25/06/08 22:41:57 INFO DAGScheduler: Job 35 finished: show at cmd17.sc:10, took 0.017934 s\n",
      "25/06/08 22:41:57 INFO CodeGenerator: Code generated in 3.567042 ms\n",
      "25/06/08 22:41:57 INFO CodeGenerator: Code generated in 1.368416 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|  distrito| count|\n",
      "+----------+------+\n",
      "|JESUS MARI|220795|\n",
      "|      NULL|    37|\n",
      "+----------+------+\n",
      "\n",
      "📊 Conteo por período:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/08 22:41:57 INFO CodeGenerator: Code generated in 6.841708 ms\n",
      "25/06/08 22:41:57 INFO DAGScheduler: Registering RDD 124 (show at cmd17.sc:18) as input to shuffle 17\n",
      "25/06/08 22:41:57 INFO DAGScheduler: Got map stage job 36 (show at cmd17.sc:18) with 1 output partitions\n",
      "25/06/08 22:41:57 INFO DAGScheduler: Final stage: ShuffleMapStage 56 (show at cmd17.sc:18)\n",
      "25/06/08 22:41:57 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/06/08 22:41:57 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/08 22:41:57 INFO DAGScheduler: Submitting ShuffleMapStage 56 (MapPartitionsRDD[124] at show at cmd17.sc:18), which has no missing parents\n",
      "25/06/08 22:41:57 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 34.5 KiB, free 2004.5 MiB)\n",
      "25/06/08 22:41:57 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 16.3 KiB, free 2004.5 MiB)\n",
      "25/06/08 22:41:57 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 192.168.18.245:57344 (size: 16.3 KiB, free: 2004.6 MiB)\n",
      "25/06/08 22:41:57 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1611\n",
      "25/06/08 22:41:57 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 56 (MapPartitionsRDD[124] at show at cmd17.sc:18) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/08 22:41:57 INFO TaskSchedulerImpl: Adding task set 56.0 with 1 tasks resource profile 0\n",
      "25/06/08 22:41:57 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 44) (192.168.18.245, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) \n",
      "25/06/08 22:41:57 INFO Executor: Running task 0.0 in stage 56.0 (TID 44)\n",
      "25/06/08 22:41:57 INFO CodeGenerator: Code generated in 10.913166 ms\n",
      "25/06/08 22:41:57 INFO CodeGenerator: Code generated in 2.991333 ms\n",
      "25/06/08 22:41:57 INFO CodeGenerator: Code generated in 1.8855 ms\n",
      "25/06/08 22:41:57 INFO JDBCRDD: closed connection\n",
      "25/06/08 22:41:57 INFO Executor: Finished task 0.0 in stage 56.0 (TID 44). 2450 bytes result sent to driver\n",
      "25/06/08 22:41:57 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 44) in 148 ms on 192.168.18.245 (executor driver) (1/1)\n",
      "25/06/08 22:41:57 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool \n",
      "25/06/08 22:41:57 INFO DAGScheduler: ShuffleMapStage 56 (show at cmd17.sc:18) finished in 0.151 s\n",
      "25/06/08 22:41:57 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/06/08 22:41:57 INFO DAGScheduler: running: Set()\n",
      "25/06/08 22:41:57 INFO DAGScheduler: waiting: Set()\n",
      "25/06/08 22:41:57 INFO DAGScheduler: failed: Set()\n",
      "25/06/08 22:41:57 INFO ShufflePartitionsUtil: For shuffle(17), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "25/06/08 22:41:57 INFO CodeGenerator: Code generated in 1.907791 ms\n",
      "25/06/08 22:41:57 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.\n",
      "25/06/08 22:41:57 INFO CodeGenerator: Code generated in 2.324875 ms\n",
      "25/06/08 22:41:57 INFO SparkContext: Starting job: show at cmd17.sc:18\n",
      "25/06/08 22:41:57 INFO DAGScheduler: Got job 37 (show at cmd17.sc:18) with 1 output partitions\n",
      "25/06/08 22:41:57 INFO DAGScheduler: Final stage: ResultStage 58 (show at cmd17.sc:18)\n",
      "25/06/08 22:41:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 57)\n",
      "25/06/08 22:41:57 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/08 22:41:57 INFO DAGScheduler: Submitting ResultStage 58 (MapPartitionsRDD[128] at show at cmd17.sc:18), which has no missing parents\n",
      "25/06/08 22:41:57 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 39.1 KiB, free 2004.5 MiB)\n",
      "25/06/08 22:41:57 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 18.4 KiB, free 2004.4 MiB)\n",
      "25/06/08 22:41:57 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 192.168.18.245:57344 (size: 18.4 KiB, free: 2004.5 MiB)\n",
      "25/06/08 22:41:57 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1611\n",
      "25/06/08 22:41:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 58 (MapPartitionsRDD[128] at show at cmd17.sc:18) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/08 22:41:57 INFO TaskSchedulerImpl: Adding task set 58.0 with 1 tasks resource profile 0\n",
      "25/06/08 22:41:57 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 45) (192.168.18.245, executor driver, partition 0, NODE_LOCAL, 8999 bytes) \n",
      "25/06/08 22:41:57 INFO Executor: Running task 0.0 in stage 58.0 (TID 45)\n",
      "25/06/08 22:41:57 INFO CodeGenerator: Code generated in 1.782667 ms\n",
      "25/06/08 22:41:57 INFO ShuffleBlockFetcherIterator: Getting 1 (198.0 B) non-empty blocks including 1 (198.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:41:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:41:57 INFO CodeGenerator: Code generated in 2.458541 ms\n",
      "25/06/08 22:41:57 INFO Executor: Finished task 0.0 in stage 58.0 (TID 45). 4961 bytes result sent to driver\n",
      "25/06/08 22:41:57 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 45) in 10 ms on 192.168.18.245 (executor driver) (1/1)\n",
      "25/06/08 22:41:57 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool \n",
      "25/06/08 22:41:57 INFO DAGScheduler: ResultStage 58 (show at cmd17.sc:18) finished in 0.014 s\n",
      "25/06/08 22:41:57 INFO DAGScheduler: Job 37 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/06/08 22:41:57 INFO TaskSchedulerImpl: Killing all running tasks in stage 58: Stage finished\n",
      "25/06/08 22:41:57 INFO DAGScheduler: Job 37 finished: show at cmd17.sc:18, took 0.015236 s\n",
      "25/06/08 22:41:57 INFO CodeGenerator: Code generated in 2.011458 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|periodo|count|\n",
      "+-------+-----+\n",
      "|   2023|69183|\n",
      "|   2024|73341|\n",
      "|   2025|78308|\n",
      "+-------+-----+\n",
      "\n",
      "📊 Conteo por distrito y período (más de 100 registros):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/08 22:41:57 INFO CodeGenerator: Code generated in 6.716291 ms\n",
      "25/06/08 22:41:57 INFO DAGScheduler: Registering RDD 131 (show at cmd17.sc:27) as input to shuffle 18\n",
      "25/06/08 22:41:57 INFO DAGScheduler: Got map stage job 38 (show at cmd17.sc:27) with 1 output partitions\n",
      "25/06/08 22:41:57 INFO DAGScheduler: Final stage: ShuffleMapStage 59 (show at cmd17.sc:27)\n",
      "25/06/08 22:41:57 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/06/08 22:41:57 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/08 22:41:57 INFO DAGScheduler: Submitting ShuffleMapStage 59 (MapPartitionsRDD[131] at show at cmd17.sc:27), which has no missing parents\n",
      "25/06/08 22:41:57 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 36.2 KiB, free 2004.4 MiB)\n",
      "25/06/08 22:41:57 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 17.0 KiB, free 2004.4 MiB)\n",
      "25/06/08 22:41:57 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 192.168.18.245:57344 (size: 17.0 KiB, free: 2004.5 MiB)\n",
      "25/06/08 22:41:57 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1611\n",
      "25/06/08 22:41:57 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 59 (MapPartitionsRDD[131] at show at cmd17.sc:27) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/08 22:41:57 INFO TaskSchedulerImpl: Adding task set 59.0 with 1 tasks resource profile 0\n",
      "25/06/08 22:41:57 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 46) (192.168.18.245, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) \n",
      "25/06/08 22:41:57 INFO Executor: Running task 0.0 in stage 59.0 (TID 46)\n",
      "25/06/08 22:41:57 INFO CodeGenerator: Code generated in 5.960667 ms\n",
      "25/06/08 22:41:57 INFO CodeGenerator: Code generated in 3.158166 ms\n",
      "25/06/08 22:41:57 INFO CodeGenerator: Code generated in 1.344834 ms\n",
      "25/06/08 22:41:57 INFO JDBCRDD: closed connection\n",
      "25/06/08 22:41:57 INFO Executor: Finished task 0.0 in stage 59.0 (TID 46). 2450 bytes result sent to driver\n",
      "25/06/08 22:41:57 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 46) in 123 ms on 192.168.18.245 (executor driver) (1/1)\n",
      "25/06/08 22:41:57 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool \n",
      "25/06/08 22:41:57 INFO DAGScheduler: ShuffleMapStage 59 (show at cmd17.sc:27) finished in 0.126 s\n",
      "25/06/08 22:41:57 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/06/08 22:41:57 INFO DAGScheduler: running: Set()\n",
      "25/06/08 22:41:57 INFO DAGScheduler: waiting: Set()\n",
      "25/06/08 22:41:57 INFO DAGScheduler: failed: Set()\n",
      "25/06/08 22:41:57 INFO ShufflePartitionsUtil: For shuffle(18), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "25/06/08 22:41:57 INFO CodeGenerator: Code generated in 1.724958 ms\n",
      "25/06/08 22:41:57 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.\n",
      "25/06/08 22:41:57 INFO CodeGenerator: Code generated in 2.406291 ms\n",
      "25/06/08 22:41:57 INFO SparkContext: Starting job: show at cmd17.sc:27\n",
      "25/06/08 22:41:57 INFO DAGScheduler: Got job 39 (show at cmd17.sc:27) with 1 output partitions\n",
      "25/06/08 22:41:57 INFO DAGScheduler: Final stage: ResultStage 61 (show at cmd17.sc:27)\n",
      "25/06/08 22:41:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 60)\n",
      "25/06/08 22:41:57 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/08 22:41:57 INFO DAGScheduler: Submitting ResultStage 61 (MapPartitionsRDD[135] at show at cmd17.sc:27), which has no missing parents\n",
      "25/06/08 22:41:57 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 41.2 KiB, free 2004.3 MiB)\n",
      "25/06/08 22:41:57 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 19.4 KiB, free 2004.3 MiB)\n",
      "25/06/08 22:41:57 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 192.168.18.245:57344 (size: 19.4 KiB, free: 2004.5 MiB)\n",
      "25/06/08 22:41:57 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1611\n",
      "25/06/08 22:41:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 61 (MapPartitionsRDD[135] at show at cmd17.sc:27) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/08 22:41:57 INFO TaskSchedulerImpl: Adding task set 61.0 with 1 tasks resource profile 0\n",
      "25/06/08 22:41:57 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 47) (192.168.18.245, executor driver, partition 0, NODE_LOCAL, 8999 bytes) \n",
      "25/06/08 22:41:57 INFO Executor: Running task 0.0 in stage 61.0 (TID 47)\n",
      "25/06/08 22:41:57 INFO CodeGenerator: Code generated in 1.827125 ms\n",
      "25/06/08 22:41:57 INFO ShuffleBlockFetcherIterator: Getting 1 (462.0 B) non-empty blocks including 1 (462.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:41:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:41:57 INFO CodeGenerator: Code generated in 3.149291 ms\n",
      "25/06/08 22:41:57 INFO Executor: Finished task 0.0 in stage 61.0 (TID 47). 5089 bytes result sent to driver\n",
      "25/06/08 22:41:57 INFO TaskSetManager: Finished task 0.0 in stage 61.0 (TID 47) in 11 ms on 192.168.18.245 (executor driver) (1/1)\n",
      "25/06/08 22:41:57 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool \n",
      "25/06/08 22:41:57 INFO DAGScheduler: ResultStage 61 (show at cmd17.sc:27) finished in 0.015 s\n",
      "25/06/08 22:41:57 INFO DAGScheduler: Job 39 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/06/08 22:41:57 INFO TaskSchedulerImpl: Killing all running tasks in stage 61: Stage finished\n",
      "25/06/08 22:41:57 INFO DAGScheduler: Job 39 finished: show at cmd17.sc:27, took 0.031404 s\n",
      "25/06/08 22:41:57 INFO CodeGenerator: Code generated in 3.669959 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+-----+\n",
      "|  distrito|periodo|count|\n",
      "+----------+-------+-----+\n",
      "|JESUS MARI|   2025|78294|\n",
      "|JESUS MARI|   2024|73329|\n",
      "|JESUS MARI|   2023|69172|\n",
      "+----------+-------+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mcontadoPorDistrito\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mDataset\u001b[39m[\u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mRow\u001b[39m] = [distrito: string, count: bigint]\n",
       "\u001b[36mcontadoPorPeriodo\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mDataset\u001b[39m[\u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mRow\u001b[39m] = [periodo: int, count: bigint]\n",
       "\u001b[36mconteoPorDistritoPeriodo\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mDataset\u001b[39m[\u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mRow\u001b[39m] = [distrito: string, periodo: int ... 1 more field]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// 4. UTILIZAR GROUPBY Y COUNT\n",
    "println(\"📊 4. UTILIZAR GROUPBY Y COUNT\")\n",
    "\n",
    "// GroupBy por distrito\n",
    "val contadoPorDistrito = df.groupBy(\"distrito\")\n",
    "  .count()\n",
    "  .orderBy(desc(\"count\"))\n",
    "\n",
    "println(\"📊 Conteo por distrito:\")\n",
    "contadoPorDistrito.show()\n",
    "\n",
    "// GroupBy por período\n",
    "val contadoPorPeriodo = df.groupBy(\"periodo\")\n",
    "  .count()\n",
    "  .orderBy(\"periodo\")\n",
    "\n",
    "println(\"📊 Conteo por período:\")\n",
    "contadoPorPeriodo.show()\n",
    "\n",
    "// GroupBy múltiple: distrito y período\n",
    "val conteoPorDistritoPeriodo = df.groupBy(\"distrito\", \"periodo\")\n",
    "  .count()\n",
    "  .filter(col(\"count\") > 100)\n",
    "  .orderBy(desc(\"count\"))\n",
    "\n",
    "println(\"📊 Conteo por distrito y período (más de 100 registros):\")\n",
    "conteoPorDistritoPeriodo.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4525467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 5. CONSULTA CON PROMEDIO\n",
      "📊 Promedios por distrito:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/08 22:41:58 INFO CodeGenerator: Code generated in 8.283625 ms\n",
      "25/06/08 22:41:58 INFO DAGScheduler: Registering RDD 138 (show at cmd18.sc:16) as input to shuffle 19\n",
      "25/06/08 22:41:58 INFO DAGScheduler: Got map stage job 40 (show at cmd18.sc:16) with 1 output partitions\n",
      "25/06/08 22:41:58 INFO DAGScheduler: Final stage: ShuffleMapStage 62 (show at cmd18.sc:16)\n",
      "25/06/08 22:41:58 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/06/08 22:41:58 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/08 22:41:58 INFO DAGScheduler: Submitting ShuffleMapStage 62 (MapPartitionsRDD[138] at show at cmd18.sc:16), which has no missing parents\n",
      "25/06/08 22:41:58 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 50.3 KiB, free 2004.3 MiB)\n",
      "25/06/08 22:41:58 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 21.5 KiB, free 2004.3 MiB)\n",
      "25/06/08 22:41:58 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 192.168.18.245:57344 (size: 21.5 KiB, free: 2004.5 MiB)\n",
      "25/06/08 22:41:58 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1611\n",
      "25/06/08 22:41:58 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 62 (MapPartitionsRDD[138] at show at cmd18.sc:16) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/08 22:41:58 INFO TaskSchedulerImpl: Adding task set 62.0 with 1 tasks resource profile 0\n",
      "25/06/08 22:41:58 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 48) (192.168.18.245, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) \n",
      "25/06/08 22:41:58 INFO Executor: Running task 0.0 in stage 62.0 (TID 48)\n",
      "25/06/08 22:41:58 INFO CodeGenerator: Code generated in 7.594458 ms\n",
      "25/06/08 22:41:58 INFO CodeGenerator: Code generated in 1.274 ms\n",
      "25/06/08 22:41:58 INFO CodeGenerator: Code generated in 1.308917 ms\n",
      "25/06/08 22:41:58 INFO JDBCRDD: closed connection\n",
      "25/06/08 22:41:58 INFO Executor: Finished task 0.0 in stage 62.0 (TID 48). 2450 bytes result sent to driver\n",
      "25/06/08 22:41:58 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 48) in 217 ms on 192.168.18.245 (executor driver) (1/1)\n",
      "25/06/08 22:41:58 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool \n",
      "25/06/08 22:41:58 INFO DAGScheduler: ShuffleMapStage 62 (show at cmd18.sc:16) finished in 0.220 s\n",
      "25/06/08 22:41:58 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/06/08 22:41:58 INFO DAGScheduler: running: Set()\n",
      "25/06/08 22:41:58 INFO DAGScheduler: waiting: Set()\n",
      "25/06/08 22:41:58 INFO DAGScheduler: failed: Set()\n",
      "25/06/08 22:41:58 INFO ShufflePartitionsUtil: For shuffle(19), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "25/06/08 22:41:58 INFO CodeGenerator: Code generated in 4.690708 ms\n",
      "25/06/08 22:41:58 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.\n",
      "25/06/08 22:41:58 INFO CodeGenerator: Code generated in 3.233542 ms\n",
      "25/06/08 22:41:58 INFO SparkContext: Starting job: show at cmd18.sc:16\n",
      "25/06/08 22:41:58 INFO DAGScheduler: Got job 41 (show at cmd18.sc:16) with 1 output partitions\n",
      "25/06/08 22:41:58 INFO DAGScheduler: Final stage: ResultStage 64 (show at cmd18.sc:16)\n",
      "25/06/08 22:41:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 63)\n",
      "25/06/08 22:41:58 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/08 22:41:58 INFO DAGScheduler: Submitting ResultStage 64 (MapPartitionsRDD[142] at show at cmd18.sc:16), which has no missing parents\n",
      "25/06/08 22:41:58 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 58.8 KiB, free 2004.2 MiB)\n",
      "25/06/08 22:41:58 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 24.6 KiB, free 2004.2 MiB)\n",
      "25/06/08 22:41:58 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 192.168.18.245:57344 (size: 24.6 KiB, free: 2004.5 MiB)\n",
      "25/06/08 22:41:58 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1611\n",
      "25/06/08 22:41:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 64 (MapPartitionsRDD[142] at show at cmd18.sc:16) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/08 22:41:58 INFO TaskSchedulerImpl: Adding task set 64.0 with 1 tasks resource profile 0\n",
      "25/06/08 22:41:58 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 49) (192.168.18.245, executor driver, partition 0, NODE_LOCAL, 8999 bytes) \n",
      "25/06/08 22:41:58 INFO Executor: Running task 0.0 in stage 64.0 (TID 49)\n",
      "25/06/08 22:41:58 INFO CodeGenerator: Code generated in 3.228 ms\n",
      "25/06/08 22:41:58 INFO ShuffleBlockFetcherIterator: Getting 1 (183.0 B) non-empty blocks including 1 (183.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:41:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:41:58 INFO CodeGenerator: Code generated in 3.190958 ms\n",
      "25/06/08 22:41:58 INFO Executor: Finished task 0.0 in stage 64.0 (TID 49). 4975 bytes result sent to driver\n",
      "25/06/08 22:41:58 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 49) in 12 ms on 192.168.18.245 (executor driver) (1/1)\n",
      "25/06/08 22:41:58 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool \n",
      "25/06/08 22:41:58 INFO DAGScheduler: ResultStage 64 (show at cmd18.sc:16) finished in 0.015 s\n",
      "25/06/08 22:41:58 INFO DAGScheduler: Job 41 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/06/08 22:41:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 64: Stage finished\n",
      "25/06/08 22:41:58 INFO DAGScheduler: Job 41 finished: show at cmd18.sc:16, took 0.018603 s\n",
      "25/06/08 22:41:58 INFO CodeGenerator: Code generated in 3.537709 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+------------------+----------------------+---------------+\n",
      "|  distrito|promedio_serenazgo|   promedio_parque|promedio_participacion|total_registros|\n",
      "+----------+------------------+------------------+----------------------+---------------+\n",
      "|JESUS MARI|263.20437632220467|161.62826495171697|     83.28701863719598|         220795|\n",
      "+----------+------------------+------------------+----------------------+---------------+\n",
      "\n",
      "📊 Promedios por período:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/08 22:41:58 INFO CodeGenerator: Code generated in 6.740375 ms\n",
      "25/06/08 22:41:58 INFO DAGScheduler: Registering RDD 145 (show at cmd18.sc:28) as input to shuffle 20\n",
      "25/06/08 22:41:58 INFO DAGScheduler: Got map stage job 42 (show at cmd18.sc:28) with 1 output partitions\n",
      "25/06/08 22:41:58 INFO DAGScheduler: Final stage: ShuffleMapStage 65 (show at cmd18.sc:28)\n",
      "25/06/08 22:41:58 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/06/08 22:41:58 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/08 22:41:58 INFO DAGScheduler: Submitting ShuffleMapStage 65 (MapPartitionsRDD[145] at show at cmd18.sc:28), which has no missing parents\n",
      "25/06/08 22:41:58 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 45.4 KiB, free 2004.1 MiB)\n",
      "25/06/08 22:41:58 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 20.3 KiB, free 2004.1 MiB)\n",
      "25/06/08 22:41:58 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 192.168.18.245:57344 (size: 20.3 KiB, free: 2004.4 MiB)\n",
      "25/06/08 22:41:58 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1611\n",
      "25/06/08 22:41:58 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 65 (MapPartitionsRDD[145] at show at cmd18.sc:28) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/08 22:41:58 INFO TaskSchedulerImpl: Adding task set 65.0 with 1 tasks resource profile 0\n",
      "25/06/08 22:41:58 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 50) (192.168.18.245, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) \n",
      "25/06/08 22:41:58 INFO Executor: Running task 0.0 in stage 65.0 (TID 50)\n",
      "25/06/08 22:41:58 INFO CodeGenerator: Code generated in 6.582292 ms\n",
      "25/06/08 22:41:58 INFO CodeGenerator: Code generated in 1.171584 ms\n",
      "25/06/08 22:41:58 INFO CodeGenerator: Code generated in 1.145208 ms\n",
      "25/06/08 22:41:58 INFO JDBCRDD: closed connection\n",
      "25/06/08 22:41:58 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 192.168.18.245:57344 in memory (size: 16.3 KiB, free: 2004.5 MiB)\n",
      "25/06/08 22:41:58 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 192.168.18.245:57344 in memory (size: 21.5 KiB, free: 2004.5 MiB)\n",
      "25/06/08 22:41:58 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 192.168.18.245:57344 in memory (size: 18.5 KiB, free: 2004.5 MiB)\n",
      "25/06/08 22:41:58 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 192.168.18.245:57344 in memory (size: 19.4 KiB, free: 2004.5 MiB)\n",
      "25/06/08 22:41:58 INFO Executor: Finished task 0.0 in stage 65.0 (TID 50). 2493 bytes result sent to driver\n",
      "25/06/08 22:41:58 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 192.168.18.245:57344 in memory (size: 18.4 KiB, free: 2004.5 MiB)\n",
      "25/06/08 22:41:58 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 50) in 151 ms on 192.168.18.245 (executor driver) (1/1)\n",
      "25/06/08 22:41:58 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool \n",
      "25/06/08 22:41:58 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 192.168.18.245:57344 in memory (size: 24.6 KiB, free: 2004.6 MiB)\n",
      "25/06/08 22:41:58 INFO DAGScheduler: ShuffleMapStage 65 (show at cmd18.sc:28) finished in 0.156 s\n",
      "25/06/08 22:41:58 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/06/08 22:41:58 INFO DAGScheduler: running: Set()\n",
      "25/06/08 22:41:58 INFO DAGScheduler: waiting: Set()\n",
      "25/06/08 22:41:58 INFO DAGScheduler: failed: Set()\n",
      "25/06/08 22:41:58 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 192.168.18.245:57344 in memory (size: 17.0 KiB, free: 2004.6 MiB)\n",
      "25/06/08 22:41:58 INFO ShufflePartitionsUtil: For shuffle(20), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "25/06/08 22:41:58 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.\n",
      "25/06/08 22:41:58 INFO CodeGenerator: Code generated in 4.197917 ms\n",
      "25/06/08 22:41:58 INFO SparkContext: Starting job: show at cmd18.sc:28\n",
      "25/06/08 22:41:58 INFO DAGScheduler: Got job 43 (show at cmd18.sc:28) with 1 output partitions\n",
      "25/06/08 22:41:58 INFO DAGScheduler: Final stage: ResultStage 67 (show at cmd18.sc:28)\n",
      "25/06/08 22:41:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 66)\n",
      "25/06/08 22:41:58 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/08 22:41:58 INFO DAGScheduler: Submitting ResultStage 67 (MapPartitionsRDD[149] at show at cmd18.sc:28), which has no missing parents\n",
      "25/06/08 22:41:58 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 53.9 KiB, free 2004.5 MiB)\n",
      "25/06/08 22:41:58 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 23.8 KiB, free 2004.5 MiB)\n",
      "25/06/08 22:41:58 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 192.168.18.245:57344 (size: 23.8 KiB, free: 2004.6 MiB)\n",
      "25/06/08 22:41:58 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1611\n",
      "25/06/08 22:41:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 67 (MapPartitionsRDD[149] at show at cmd18.sc:28) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/08 22:41:58 INFO TaskSchedulerImpl: Adding task set 67.0 with 1 tasks resource profile 0\n",
      "25/06/08 22:41:58 INFO TaskSetManager: Starting task 0.0 in stage 67.0 (TID 51) (192.168.18.245, executor driver, partition 0, NODE_LOCAL, 8999 bytes) \n",
      "25/06/08 22:41:58 INFO Executor: Running task 0.0 in stage 67.0 (TID 51)\n",
      "25/06/08 22:41:58 INFO ShuffleBlockFetcherIterator: Getting 1 (264.0 B) non-empty blocks including 1 (264.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:41:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:41:58 INFO CodeGenerator: Code generated in 3.838042 ms\n",
      "25/06/08 22:41:58 INFO Executor: Finished task 0.0 in stage 67.0 (TID 51). 5009 bytes result sent to driver\n",
      "25/06/08 22:41:58 INFO TaskSetManager: Finished task 0.0 in stage 67.0 (TID 51) in 9 ms on 192.168.18.245 (executor driver) (1/1)\n",
      "25/06/08 22:41:58 INFO TaskSchedulerImpl: Removed TaskSet 67.0, whose tasks have all completed, from pool \n",
      "25/06/08 22:41:58 INFO DAGScheduler: ResultStage 67 (show at cmd18.sc:28) finished in 0.013 s\n",
      "25/06/08 22:41:58 INFO DAGScheduler: Job 43 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/06/08 22:41:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 67: Stage finished\n",
      "25/06/08 22:41:58 INFO DAGScheduler: Job 43 finished: show at cmd18.sc:28, took 0.014187 s\n",
      "25/06/08 22:41:58 INFO CodeGenerator: Code generated in 2.271333 ms\n",
      "25/06/08 22:41:58 INFO CodeGenerator: Code generated in 1.242166 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+----------------+---------+\n",
      "|periodo|promedio_residuos|promedio_barrido|registros|\n",
      "+-------+-----------------+----------------+---------+\n",
      "|   2023|            61.12|           26.52|    69183|\n",
      "|   2024|            54.25|           27.08|    73341|\n",
      "|   2025|             58.7|            29.4|    78308|\n",
      "+-------+-----------------+----------------+---------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mpromediosPorDistrito\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mDataset\u001b[39m[\u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mRow\u001b[39m] = [distrito: string, promedio_serenazgo: double ... 3 more fields]\n",
       "\u001b[36mpromediosPorPeriodo\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mDataset\u001b[39m[\u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mRow\u001b[39m] = [periodo: int, promedio_residuos: double ... 2 more fields]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// 5. CONSULTA CON PROMEDIO\n",
    "println(\"📊 5. CONSULTA CON PROMEDIO\")\n",
    "\n",
    "// Promedio de montos por distrito\n",
    "val promediosPorDistrito = df.groupBy(\"distrito\")\n",
    "  .agg(\n",
    "    avg(col(\"monto_serenazgo\").cast(\"double\")).as(\"promedio_serenazgo\"),\n",
    "    avg(col(\"monto_parque_jardin\").cast(\"double\")).as(\"promedio_parque\"),\n",
    "    avg(col(\"porcentaje_condominio\").cast(\"double\")).as(\"promedio_participacion\"),\n",
    "    count(\"*\").as(\"total_registros\")\n",
    "  )\n",
    "  .filter(col(\"total_registros\") > 50)\n",
    "  .orderBy(desc(\"promedio_serenazgo\"))\n",
    "\n",
    "println(\"📊 Promedios por distrito:\")\n",
    "promediosPorDistrito.show()\n",
    "\n",
    "// Promedio por período\n",
    "val promediosPorPeriodo = df.groupBy(\"periodo\")\n",
    "  .agg(\n",
    "    round(avg(col(\"monto_residuos_solidos\").cast(\"double\")), 2).as(\"promedio_residuos\"),\n",
    "    round(avg(col(\"monto_barrido_calles\").cast(\"double\")), 2).as(\"promedio_barrido\"),\n",
    "    count(\"*\").as(\"registros\")\n",
    "  )\n",
    "  .orderBy(\"periodo\")\n",
    "\n",
    "println(\"📊 Promedios por período:\")\n",
    "promediosPorPeriodo.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15e56379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔗 6. TRES CONSULTAS CON JOIN\n",
      "📊 JOIN 1 - Contribuyentes vs Promedio de distrito:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/08 22:41:58 INFO CodeGenerator: Code generated in 7.318875 ms\n",
      "25/06/08 22:41:58 INFO DAGScheduler: Registering RDD 153 (show at cmd19.sc:25) as input to shuffle 21\n",
      "25/06/08 22:41:58 INFO DAGScheduler: Got map stage job 44 (show at cmd19.sc:25) with 1 output partitions\n",
      "25/06/08 22:41:58 INFO DAGScheduler: Final stage: ShuffleMapStage 68 (show at cmd19.sc:25)\n",
      "25/06/08 22:41:58 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/06/08 22:41:58 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/08 22:41:58 INFO DAGScheduler: Submitting ShuffleMapStage 68 (MapPartitionsRDD[153] at show at cmd19.sc:25), which has no missing parents\n",
      "25/06/08 22:41:58 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 42.6 KiB, free 2004.4 MiB)\n",
      "25/06/08 22:41:58 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 19.7 KiB, free 2004.4 MiB)\n",
      "25/06/08 22:41:58 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 192.168.18.245:57344 (size: 19.7 KiB, free: 2004.5 MiB)\n",
      "25/06/08 22:41:58 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1611\n",
      "25/06/08 22:41:58 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 68 (MapPartitionsRDD[153] at show at cmd19.sc:25) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/08 22:41:58 INFO TaskSchedulerImpl: Adding task set 68.0 with 1 tasks resource profile 0\n",
      "25/06/08 22:41:58 INFO TaskSetManager: Starting task 0.0 in stage 68.0 (TID 52) (192.168.18.245, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) \n",
      "25/06/08 22:41:58 INFO Executor: Running task 0.0 in stage 68.0 (TID 52)\n",
      "25/06/08 22:41:58 INFO CodeGenerator: Code generated in 37.539167 ms\n",
      "25/06/08 22:41:58 INFO DAGScheduler: Registering RDD 155 (show at cmd19.sc:25) as input to shuffle 22\n",
      "25/06/08 22:41:58 INFO DAGScheduler: Got map stage job 45 (show at cmd19.sc:25) with 1 output partitions\n",
      "25/06/08 22:41:58 INFO DAGScheduler: Final stage: ShuffleMapStage 69 (show at cmd19.sc:25)\n",
      "25/06/08 22:41:58 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/06/08 22:41:58 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/08 22:41:58 INFO DAGScheduler: Submitting ShuffleMapStage 69 (MapPartitionsRDD[155] at show at cmd19.sc:25), which has no missing parents\n",
      "25/06/08 22:41:58 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 40.8 KiB, free 2004.4 MiB)\n",
      "25/06/08 22:41:58 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 19.0 KiB, free 2004.3 MiB)\n",
      "25/06/08 22:41:58 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 192.168.18.245:57344 (size: 19.0 KiB, free: 2004.5 MiB)\n",
      "25/06/08 22:41:58 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1611\n",
      "25/06/08 22:41:58 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 69 (MapPartitionsRDD[155] at show at cmd19.sc:25) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/08 22:41:58 INFO TaskSchedulerImpl: Adding task set 69.0 with 1 tasks resource profile 0\n",
      "25/06/08 22:41:58 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 53) (192.168.18.245, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) \n",
      "25/06/08 22:41:58 INFO Executor: Running task 0.0 in stage 69.0 (TID 53)\n",
      "25/06/08 22:41:58 INFO CodeGenerator: Code generated in 8.778375 ms\n",
      "25/06/08 22:41:58 INFO CodeGenerator: Code generated in 2.790833 ms\n",
      "25/06/08 22:41:58 INFO CodeGenerator: Code generated in 11.198667 ms\n",
      "25/06/08 22:41:58 INFO CodeGenerator: Code generated in 1.552375 ms\n",
      "25/06/08 22:41:58 INFO JDBCRDD: closed connection\n",
      "25/06/08 22:41:58 INFO Executor: Finished task 0.0 in stage 69.0 (TID 53). 2450 bytes result sent to driver\n",
      "25/06/08 22:41:58 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 53) in 158 ms on 192.168.18.245 (executor driver) (1/1)\n",
      "25/06/08 22:41:58 INFO TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool \n",
      "25/06/08 22:41:58 INFO DAGScheduler: ShuffleMapStage 69 (show at cmd19.sc:25) finished in 0.164 s\n",
      "25/06/08 22:41:58 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/06/08 22:41:58 INFO DAGScheduler: running: Set(ShuffleMapStage 68)\n",
      "25/06/08 22:41:58 INFO DAGScheduler: waiting: Set()\n",
      "25/06/08 22:41:58 INFO DAGScheduler: failed: Set()\n",
      "25/06/08 22:41:58 INFO ShufflePartitionsUtil: For shuffle(22), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "25/06/08 22:41:58 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.\n",
      "25/06/08 22:41:58 INFO CodeGenerator: Code generated in 2.98575 ms\n",
      "25/06/08 22:41:58 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266\n",
      "25/06/08 22:41:58 INFO DAGScheduler: Got job 46 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions\n",
      "25/06/08 22:41:58 INFO DAGScheduler: Final stage: ResultStage 71 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)\n",
      "25/06/08 22:41:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 70)\n",
      "25/06/08 22:41:58 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/08 22:41:58 INFO DAGScheduler: Submitting ResultStage 71 (MapPartitionsRDD[158] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents\n",
      "25/06/08 22:41:58 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 44.3 KiB, free 1988.0 MiB)\n",
      "25/06/08 22:41:58 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 20.6 KiB, free 1988.0 MiB)\n",
      "25/06/08 22:41:58 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 192.168.18.245:57344 (size: 20.6 KiB, free: 2004.5 MiB)\n",
      "25/06/08 22:41:58 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1611\n",
      "25/06/08 22:41:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 71 (MapPartitionsRDD[158] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/08 22:41:59 INFO TaskSchedulerImpl: Adding task set 71.0 with 1 tasks resource profile 0\n",
      "25/06/08 22:41:59 INFO TaskSetManager: Starting task 0.0 in stage 71.0 (TID 54) (192.168.18.245, executor driver, partition 0, NODE_LOCAL, 8999 bytes) \n",
      "25/06/08 22:41:59 INFO Executor: Running task 0.0 in stage 71.0 (TID 54)\n",
      "25/06/08 22:41:59 INFO ShuffleBlockFetcherIterator: Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:41:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:41:59 INFO CodeGenerator: Code generated in 3.426583 ms\n",
      "25/06/08 22:41:59 INFO Executor: Finished task 0.0 in stage 71.0 (TID 54). 4909 bytes result sent to driver\n",
      "25/06/08 22:41:59 INFO TaskSetManager: Finished task 0.0 in stage 71.0 (TID 54) in 10 ms on 192.168.18.245 (executor driver) (1/1)\n",
      "25/06/08 22:41:59 INFO TaskSchedulerImpl: Removed TaskSet 71.0, whose tasks have all completed, from pool \n",
      "25/06/08 22:41:59 INFO DAGScheduler: ResultStage 71 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.014 s\n",
      "25/06/08 22:41:59 INFO DAGScheduler: Job 46 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/06/08 22:41:59 INFO TaskSchedulerImpl: Killing all running tasks in stage 71: Stage finished\n",
      "25/06/08 22:41:59 INFO DAGScheduler: Job 46 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.015830 s\n",
      "25/06/08 22:41:59 INFO CodeGenerator: Code generated in 1.734833 ms\n",
      "25/06/08 22:41:59 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 8.0 MiB, free 1980.0 MiB)\n",
      "25/06/08 22:41:59 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 204.0 B, free 1980.0 MiB)\n",
      "25/06/08 22:41:59 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 192.168.18.245:57344 (size: 204.0 B, free: 2004.5 MiB)\n",
      "25/06/08 22:41:59 INFO SparkContext: Created broadcast 47 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266\n",
      "25/06/08 22:41:59 INFO JDBCRDD: closed connection\n",
      "25/06/08 22:41:59 INFO Executor: Finished task 0.0 in stage 68.0 (TID 52). 2450 bytes result sent to driver\n",
      "25/06/08 22:41:59 INFO TaskSetManager: Finished task 0.0 in stage 68.0 (TID 52) in 325 ms on 192.168.18.245 (executor driver) (1/1)\n",
      "25/06/08 22:41:59 INFO TaskSchedulerImpl: Removed TaskSet 68.0, whose tasks have all completed, from pool \n",
      "25/06/08 22:41:59 INFO DAGScheduler: ShuffleMapStage 68 (show at cmd19.sc:25) finished in 0.329 s\n",
      "25/06/08 22:41:59 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/06/08 22:41:59 INFO DAGScheduler: running: Set()\n",
      "25/06/08 22:41:59 INFO DAGScheduler: waiting: Set()\n",
      "25/06/08 22:41:59 INFO DAGScheduler: failed: Set()\n",
      "25/06/08 22:41:59 INFO ShufflePartitionsUtil: For shuffle(21), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "25/06/08 22:41:59 INFO CodeGenerator: Code generated in 4.946166 ms\n",
      "25/06/08 22:41:59 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.\n",
      "25/06/08 22:41:59 INFO CodeGenerator: Code generated in 5.375917 ms\n",
      "25/06/08 22:41:59 INFO SparkContext: Starting job: show at cmd19.sc:25\n",
      "25/06/08 22:41:59 INFO DAGScheduler: Got job 47 (show at cmd19.sc:25) with 3 output partitions\n",
      "25/06/08 22:41:59 INFO DAGScheduler: Final stage: ResultStage 73 (show at cmd19.sc:25)\n",
      "25/06/08 22:41:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 72)\n",
      "25/06/08 22:41:59 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/08 22:41:59 INFO DAGScheduler: Submitting ResultStage 73 (MapPartitionsRDD[162] at show at cmd19.sc:25), which has no missing parents\n",
      "25/06/08 22:41:59 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 65.9 KiB, free 1996.2 MiB)\n",
      "25/06/08 22:41:59 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 28.9 KiB, free 1996.2 MiB)\n",
      "25/06/08 22:41:59 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 192.168.18.245:57344 (size: 28.9 KiB, free: 2004.5 MiB)\n",
      "25/06/08 22:41:59 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1611\n",
      "25/06/08 22:41:59 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 73 (MapPartitionsRDD[162] at show at cmd19.sc:25) (first 15 tasks are for partitions Vector(0, 1, 2))\n",
      "25/06/08 22:41:59 INFO TaskSchedulerImpl: Adding task set 73.0 with 3 tasks resource profile 0\n",
      "25/06/08 22:41:59 INFO TaskSetManager: Starting task 0.0 in stage 73.0 (TID 55) (192.168.18.245, executor driver, partition 0, NODE_LOCAL, 8999 bytes) \n",
      "25/06/08 22:41:59 INFO TaskSetManager: Starting task 1.0 in stage 73.0 (TID 56) (192.168.18.245, executor driver, partition 1, NODE_LOCAL, 8999 bytes) \n",
      "25/06/08 22:41:59 INFO TaskSetManager: Starting task 2.0 in stage 73.0 (TID 57) (192.168.18.245, executor driver, partition 2, NODE_LOCAL, 8999 bytes) \n",
      "25/06/08 22:41:59 INFO Executor: Running task 1.0 in stage 73.0 (TID 56)\n",
      "25/06/08 22:41:59 INFO Executor: Running task 2.0 in stage 73.0 (TID 57)\n",
      "25/06/08 22:41:59 INFO Executor: Running task 0.0 in stage 73.0 (TID 55)\n",
      "25/06/08 22:41:59 INFO CodeGenerator: Code generated in 3.989834 ms\n",
      "25/06/08 22:41:59 INFO ShuffleBlockFetcherIterator: Getting 1 (1330.7 KiB) non-empty blocks including 1 (1330.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:41:59 INFO ShuffleBlockFetcherIterator: Getting 1 (1033.6 KiB) non-empty blocks including 1 (1033.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:41:59 INFO ShuffleBlockFetcherIterator: Getting 1 (1032.4 KiB) non-empty blocks including 1 (1032.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:41:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:41:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:41:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:41:59 INFO CodeGenerator: Code generated in 5.098375 ms\n",
      "25/06/08 22:41:59 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 192.168.18.245:57344 in memory (size: 20.3 KiB, free: 2004.5 MiB)\n",
      "25/06/08 22:41:59 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 192.168.18.245:57344 in memory (size: 20.6 KiB, free: 2004.5 MiB)\n",
      "25/06/08 22:41:59 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 192.168.18.245:57344 in memory (size: 19.0 KiB, free: 2004.5 MiB)\n",
      "25/06/08 22:41:59 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 192.168.18.245:57344 in memory (size: 23.8 KiB, free: 2004.6 MiB)\n",
      "25/06/08 22:41:59 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 192.168.18.245:57344 in memory (size: 19.7 KiB, free: 2004.6 MiB)\n",
      "25/06/08 22:41:59 INFO Executor: Finished task 1.0 in stage 73.0 (TID 56). 9090 bytes result sent to driver\n",
      "25/06/08 22:41:59 INFO TaskSetManager: Finished task 1.0 in stage 73.0 (TID 56) in 92 ms on 192.168.18.245 (executor driver) (1/3)\n",
      "25/06/08 22:41:59 INFO Executor: Finished task 0.0 in stage 73.0 (TID 55). 9090 bytes result sent to driver\n",
      "25/06/08 22:41:59 INFO TaskSetManager: Finished task 0.0 in stage 73.0 (TID 55) in 93 ms on 192.168.18.245 (executor driver) (2/3)\n",
      "25/06/08 22:41:59 INFO Executor: Finished task 2.0 in stage 73.0 (TID 57). 9090 bytes result sent to driver\n",
      "25/06/08 22:41:59 INFO TaskSetManager: Finished task 2.0 in stage 73.0 (TID 57) in 94 ms on 192.168.18.245 (executor driver) (3/3)\n",
      "25/06/08 22:41:59 INFO TaskSchedulerImpl: Removed TaskSet 73.0, whose tasks have all completed, from pool \n",
      "25/06/08 22:41:59 INFO DAGScheduler: ResultStage 73 (show at cmd19.sc:25) finished in 0.098 s\n",
      "25/06/08 22:41:59 INFO DAGScheduler: Job 47 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/06/08 22:41:59 INFO TaskSchedulerImpl: Killing all running tasks in stage 73: Stage finished\n",
      "25/06/08 22:41:59 INFO DAGScheduler: Job 47 finished: show at cmd19.sc:25, took 0.100920 s\n",
      "25/06/08 22:41:59 INFO CodeGenerator: Code generated in 3.737625 ms\n",
      "25/06/08 22:41:59 INFO CodeGenerator: Code generated in 1.946209 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+------------------+-----------+---------------------------+-------------------+\n",
      "|  distrito|   cod_contribuyente|   total_serenazgo|num_predios|promedio_distrito_serenazgo|diferencia_promedio|\n",
      "+----------+--------------------+------------------+-----------+---------------------------+-------------------+\n",
      "|JESUS MARI|8b23a5f47f37eaa52...| 709412.4000000006|         33|          263.2043763221368|           709149.2|\n",
      "|JESUS MARI|55351ada81c0f27f8...| 657369.2400000077|        599|          263.2043763221368|          657106.04|\n",
      "|JESUS MARI|2a0199bb8f20b9035...| 288995.5199999999|         19|          263.2043763221368|          288732.32|\n",
      "|JESUS MARI|2119b2fb48bfa34d8...|286145.27999999997|         11|          263.2043763221368|          285882.08|\n",
      "|JESUS MARI|9e17ffa1e26b269ea...| 283911.6000000009|        201|          263.2043763221368|           283648.4|\n",
      "|JESUS MARI|e50b873fbaacca239...|         277559.04|         12|          263.2043763221368|          277295.84|\n",
      "|JESUS MARI|c7d7cd94d59a8b17c...|275865.72000000044|        147|          263.2043763221368|          275602.52|\n",
      "|JESUS MARI|139af841d2e577a63...|204642.95999999982|        414|          263.2043763221368|          204379.76|\n",
      "|JESUS MARI|38548de48f1bfb8e5...|191669.75999999992|         39|          263.2043763221368|          191406.56|\n",
      "|JESUS MARI|39ed9d9016f301c73...| 190247.5199999979|        368|          263.2043763221368|          189984.32|\n",
      "+----------+--------------------+------------------+-----------+---------------------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "📊 JOIN 2 - Contribuyentes con múltiples períodos:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/08 22:41:59 INFO CodeGenerator: Code generated in 1.788875 ms\n",
      "25/06/08 22:41:59 INFO DAGScheduler: Registering RDD 167 (show at cmd19.sc:43) as input to shuffle 23\n",
      "25/06/08 22:41:59 INFO DAGScheduler: Got map stage job 48 (show at cmd19.sc:43) with 1 output partitions\n",
      "25/06/08 22:41:59 INFO DAGScheduler: Final stage: ShuffleMapStage 74 (show at cmd19.sc:43)\n",
      "25/06/08 22:41:59 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/06/08 22:41:59 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/08 22:41:59 INFO DAGScheduler: Submitting ShuffleMapStage 74 (MapPartitionsRDD[167] at show at cmd19.sc:43), which has no missing parents\n",
      "25/06/08 22:41:59 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 26.0 KiB, free 1996.5 MiB)\n",
      "25/06/08 22:41:59 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 1996.5 MiB)\n",
      "25/06/08 22:41:59 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 192.168.18.245:57344 (size: 12.7 KiB, free: 2004.6 MiB)\n",
      "25/06/08 22:41:59 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1611\n",
      "25/06/08 22:41:59 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 74 (MapPartitionsRDD[167] at show at cmd19.sc:43) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/08 22:41:59 INFO TaskSchedulerImpl: Adding task set 74.0 with 1 tasks resource profile 0\n",
      "25/06/08 22:41:59 INFO TaskSetManager: Starting task 0.0 in stage 74.0 (TID 58) (192.168.18.245, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) \n",
      "25/06/08 22:41:59 INFO Executor: Running task 0.0 in stage 74.0 (TID 58)\n",
      "25/06/08 22:41:59 INFO CodeGenerator: Code generated in 124.364625 ms\n",
      "25/06/08 22:41:59 INFO DAGScheduler: Registering RDD 169 (show at cmd19.sc:43) as input to shuffle 24\n",
      "25/06/08 22:41:59 INFO DAGScheduler: Got map stage job 49 (show at cmd19.sc:43) with 1 output partitions\n",
      "25/06/08 22:41:59 INFO DAGScheduler: Final stage: ShuffleMapStage 75 (show at cmd19.sc:43)\n",
      "25/06/08 22:41:59 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/06/08 22:41:59 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/08 22:41:59 INFO DAGScheduler: Submitting ShuffleMapStage 75 (MapPartitionsRDD[169] at show at cmd19.sc:43), which has no missing parents\n",
      "25/06/08 22:41:59 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 29.5 KiB, free 1996.4 MiB)\n",
      "25/06/08 22:41:59 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 13.3 KiB, free 1996.4 MiB)\n",
      "25/06/08 22:41:59 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 192.168.18.245:57344 (size: 13.3 KiB, free: 2004.5 MiB)\n",
      "25/06/08 22:41:59 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1611\n",
      "25/06/08 22:41:59 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 75 (MapPartitionsRDD[169] at show at cmd19.sc:43) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/08 22:41:59 INFO TaskSchedulerImpl: Adding task set 75.0 with 1 tasks resource profile 0\n",
      "25/06/08 22:41:59 INFO TaskSetManager: Starting task 0.0 in stage 75.0 (TID 59) (192.168.18.245, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) \n",
      "25/06/08 22:41:59 INFO Executor: Running task 0.0 in stage 75.0 (TID 59)\n",
      "25/06/08 22:41:59 INFO CodeGenerator: Code generated in 1.958375 ms\n",
      "25/06/08 22:41:59 INFO CodeGenerator: Code generated in 1.29925 ms\n",
      "25/06/08 22:41:59 INFO CodeGenerator: Code generated in 1.489042 ms\n",
      "25/06/08 22:41:59 INFO CodeGenerator: Code generated in 1.890583 ms\n",
      "25/06/08 22:41:59 INFO CodeGenerator: Code generated in 6.918792 ms\n",
      "25/06/08 22:41:59 INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold\n",
      "25/06/08 22:41:59 INFO CodeGenerator: Code generated in 3.616167 ms\n",
      "25/06/08 22:41:59 INFO CodeGenerator: Code generated in 4.252917 ms\n",
      "25/06/08 22:41:59 INFO CodeGenerator: Code generated in 1.7505 ms\n",
      "25/06/08 22:41:59 INFO CodeGenerator: Code generated in 1.936917 ms\n",
      "25/06/08 22:41:59 INFO CodeGenerator: Code generated in 1.120417 ms\n",
      "25/06/08 22:41:59 INFO CodeGenerator: Code generated in 1.9985 ms\n",
      "25/06/08 22:41:59 INFO JDBCRDD: closed connection\n",
      "25/06/08 22:41:59 INFO JDBCRDD: closed connection\n",
      "25/06/08 22:41:59 INFO Executor: Finished task 0.0 in stage 75.0 (TID 59). 2450 bytes result sent to driver\n",
      "25/06/08 22:41:59 INFO TaskSetManager: Finished task 0.0 in stage 75.0 (TID 59) in 328 ms on 192.168.18.245 (executor driver) (1/1)\n",
      "25/06/08 22:41:59 INFO TaskSchedulerImpl: Removed TaskSet 75.0, whose tasks have all completed, from pool \n",
      "25/06/08 22:41:59 INFO DAGScheduler: ShuffleMapStage 75 (show at cmd19.sc:43) finished in 0.331 s\n",
      "25/06/08 22:41:59 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/06/08 22:41:59 INFO DAGScheduler: running: Set(ShuffleMapStage 74)\n",
      "25/06/08 22:41:59 INFO DAGScheduler: waiting: Set()\n",
      "25/06/08 22:41:59 INFO DAGScheduler: failed: Set()\n",
      "25/06/08 22:41:59 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 192.168.18.245:57344 in memory (size: 13.3 KiB, free: 2004.6 MiB)\n",
      "25/06/08 22:41:59 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 192.168.18.245:57344 in memory (size: 204.0 B, free: 2004.6 MiB)\n",
      "25/06/08 22:41:59 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 192.168.18.245:57344 in memory (size: 28.9 KiB, free: 2004.6 MiB)\n",
      "25/06/08 22:41:59 INFO ShufflePartitionsUtil: For shuffle(24), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "25/06/08 22:41:59 INFO CodeGenerator: Code generated in 9.263208 ms\n",
      "25/06/08 22:41:59 INFO DAGScheduler: Registering RDD 172 (show at cmd19.sc:43) as input to shuffle 25\n",
      "25/06/08 22:41:59 INFO DAGScheduler: Got map stage job 50 (show at cmd19.sc:43) with 9 output partitions\n",
      "25/06/08 22:41:59 INFO DAGScheduler: Final stage: ShuffleMapStage 77 (show at cmd19.sc:43)\n",
      "25/06/08 22:41:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 76)\n",
      "25/06/08 22:41:59 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/08 22:41:59 INFO DAGScheduler: Submitting ShuffleMapStage 77 (MapPartitionsRDD[172] at show at cmd19.sc:43), which has no missing parents\n",
      "25/06/08 22:41:59 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 44.4 KiB, free 1948.5 MiB)\n",
      "25/06/08 22:41:59 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 19.9 KiB, free 1948.4 MiB)\n",
      "25/06/08 22:41:59 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 192.168.18.245:57344 (size: 19.9 KiB, free: 2004.6 MiB)\n",
      "25/06/08 22:41:59 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1611\n",
      "25/06/08 22:41:59 INFO DAGScheduler: Submitting 9 missing tasks from ShuffleMapStage 77 (MapPartitionsRDD[172] at show at cmd19.sc:43) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8))\n",
      "25/06/08 22:41:59 INFO TaskSchedulerImpl: Adding task set 77.0 with 9 tasks resource profile 0\n",
      "25/06/08 22:41:59 INFO TaskSetManager: Starting task 0.0 in stage 77.0 (TID 60) (192.168.18.245, executor driver, partition 0, NODE_LOCAL, 8988 bytes) \n",
      "25/06/08 22:41:59 INFO TaskSetManager: Starting task 1.0 in stage 77.0 (TID 61) (192.168.18.245, executor driver, partition 1, NODE_LOCAL, 8988 bytes) \n",
      "25/06/08 22:41:59 INFO TaskSetManager: Starting task 2.0 in stage 77.0 (TID 62) (192.168.18.245, executor driver, partition 2, NODE_LOCAL, 8988 bytes) \n",
      "25/06/08 22:41:59 INFO TaskSetManager: Starting task 3.0 in stage 77.0 (TID 63) (192.168.18.245, executor driver, partition 3, NODE_LOCAL, 8988 bytes) \n",
      "25/06/08 22:41:59 INFO TaskSetManager: Starting task 4.0 in stage 77.0 (TID 64) (192.168.18.245, executor driver, partition 4, NODE_LOCAL, 8988 bytes) \n",
      "25/06/08 22:41:59 INFO TaskSetManager: Starting task 5.0 in stage 77.0 (TID 65) (192.168.18.245, executor driver, partition 5, NODE_LOCAL, 8988 bytes) \n",
      "25/06/08 22:41:59 INFO TaskSetManager: Starting task 6.0 in stage 77.0 (TID 66) (192.168.18.245, executor driver, partition 6, NODE_LOCAL, 8988 bytes) \n",
      "25/06/08 22:41:59 INFO TaskSetManager: Starting task 7.0 in stage 77.0 (TID 67) (192.168.18.245, executor driver, partition 7, NODE_LOCAL, 8988 bytes) \n",
      "25/06/08 22:41:59 INFO TaskSetManager: Starting task 8.0 in stage 77.0 (TID 68) (192.168.18.245, executor driver, partition 8, NODE_LOCAL, 8988 bytes) \n",
      "25/06/08 22:41:59 INFO Executor: Running task 1.0 in stage 77.0 (TID 61)\n",
      "25/06/08 22:41:59 INFO Executor: Running task 0.0 in stage 77.0 (TID 60)\n",
      "25/06/08 22:41:59 INFO Executor: Running task 4.0 in stage 77.0 (TID 64)\n",
      "25/06/08 22:41:59 INFO Executor: Running task 3.0 in stage 77.0 (TID 63)\n",
      "25/06/08 22:41:59 INFO Executor: Running task 2.0 in stage 77.0 (TID 62)\n",
      "25/06/08 22:41:59 INFO Executor: Running task 6.0 in stage 77.0 (TID 66)\n",
      "25/06/08 22:41:59 INFO ShuffleBlockFetcherIterator: Getting 1 (1063.9 KiB) non-empty blocks including 1 (1063.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:41:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "25/06/08 22:41:59 INFO ShuffleBlockFetcherIterator: Getting 1 (1026.7 KiB) non-empty blocks including 1 (1026.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:41:59 INFO ShuffleBlockFetcherIterator: Getting 1 (1068.6 KiB) non-empty blocks including 1 (1068.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:41:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:41:59 INFO Executor: Running task 5.0 in stage 77.0 (TID 65)\n",
      "25/06/08 22:41:59 INFO ShuffleBlockFetcherIterator: Getting 1 (1031.4 KiB) non-empty blocks including 1 (1031.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:41:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:41:59 INFO ShuffleBlockFetcherIterator: Getting 1 (1040.7 KiB) non-empty blocks including 1 (1040.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:41:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:41:59 INFO Executor: Running task 8.0 in stage 77.0 (TID 68)\n",
      "25/06/08 22:41:59 INFO Executor: Running task 7.0 in stage 77.0 (TID 67)\n",
      "25/06/08 22:41:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:41:59 INFO ShuffleBlockFetcherIterator: Getting 1 (1063.9 KiB) non-empty blocks including 1 (1063.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:41:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms\n",
      "25/06/08 22:41:59 INFO ShuffleBlockFetcherIterator: Getting 1 (1417.0 KiB) non-empty blocks including 1 (1417.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:41:59 INFO ShuffleBlockFetcherIterator: Getting 1 (1036.0 KiB) non-empty blocks including 1 (1036.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:41:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:41:59 INFO ShuffleBlockFetcherIterator: Getting 1 (1055.1 KiB) non-empty blocks including 1 (1055.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:41:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:41:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "25/06/08 22:41:59 INFO CodeGenerator: Code generated in 16.503375 ms\n",
      "25/06/08 22:41:59 INFO Executor: Finished task 3.0 in stage 77.0 (TID 63). 5232 bytes result sent to driver\n",
      "25/06/08 22:41:59 INFO TaskSetManager: Finished task 3.0 in stage 77.0 (TID 63) in 168 ms on 192.168.18.245 (executor driver) (1/9)\n",
      "25/06/08 22:41:59 INFO Executor: Finished task 2.0 in stage 77.0 (TID 62). 5232 bytes result sent to driver\n",
      "25/06/08 22:41:59 INFO TaskSetManager: Finished task 2.0 in stage 77.0 (TID 62) in 202 ms on 192.168.18.245 (executor driver) (2/9)\n",
      "25/06/08 22:41:59 INFO Executor: Finished task 1.0 in stage 77.0 (TID 61). 5232 bytes result sent to driver\n",
      "25/06/08 22:41:59 INFO TaskSetManager: Finished task 1.0 in stage 77.0 (TID 61) in 204 ms on 192.168.18.245 (executor driver) (3/9)\n",
      "25/06/08 22:41:59 INFO Executor: Finished task 6.0 in stage 77.0 (TID 66). 5232 bytes result sent to driver\n",
      "25/06/08 22:42:00 INFO TaskSetManager: Finished task 6.0 in stage 77.0 (TID 66) in 209 ms on 192.168.18.245 (executor driver) (4/9)\n",
      "25/06/08 22:42:00 INFO Executor: Finished task 0.0 in stage 77.0 (TID 60). 5232 bytes result sent to driver\n",
      "25/06/08 22:42:00 INFO TaskSetManager: Finished task 0.0 in stage 77.0 (TID 60) in 229 ms on 192.168.18.245 (executor driver) (5/9)\n",
      "25/06/08 22:42:00 INFO Executor: Finished task 5.0 in stage 77.0 (TID 65). 5232 bytes result sent to driver\n",
      "25/06/08 22:42:00 INFO TaskSetManager: Finished task 5.0 in stage 77.0 (TID 65) in 262 ms on 192.168.18.245 (executor driver) (6/9)\n",
      "25/06/08 22:42:00 INFO Executor: Finished task 7.0 in stage 77.0 (TID 67). 5232 bytes result sent to driver\n",
      "25/06/08 22:42:00 INFO TaskSetManager: Finished task 7.0 in stage 77.0 (TID 67) in 267 ms on 192.168.18.245 (executor driver) (7/9)\n",
      "25/06/08 22:42:00 INFO Executor: Finished task 8.0 in stage 77.0 (TID 68). 5232 bytes result sent to driver\n",
      "25/06/08 22:42:00 INFO TaskSetManager: Finished task 8.0 in stage 77.0 (TID 68) in 268 ms on 192.168.18.245 (executor driver) (8/9)\n",
      "25/06/08 22:42:00 INFO Executor: Finished task 4.0 in stage 77.0 (TID 64). 5232 bytes result sent to driver\n",
      "25/06/08 22:42:00 INFO TaskSetManager: Finished task 4.0 in stage 77.0 (TID 64) in 299 ms on 192.168.18.245 (executor driver) (9/9)\n",
      "25/06/08 22:42:00 INFO TaskSchedulerImpl: Removed TaskSet 77.0, whose tasks have all completed, from pool \n",
      "25/06/08 22:42:00 INFO DAGScheduler: ShuffleMapStage 77 (show at cmd19.sc:43) finished in 0.305 s\n",
      "25/06/08 22:42:00 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/06/08 22:42:00 INFO DAGScheduler: running: Set(ShuffleMapStage 74)\n",
      "25/06/08 22:42:00 INFO DAGScheduler: waiting: Set()\n",
      "25/06/08 22:42:00 INFO DAGScheduler: failed: Set()\n",
      "25/06/08 22:42:00 INFO Executor: Finished task 0.0 in stage 74.0 (TID 58). 2291 bytes result sent to driver\n",
      "25/06/08 22:42:00 INFO TaskSetManager: Finished task 0.0 in stage 74.0 (TID 58) in 811 ms on 192.168.18.245 (executor driver) (1/1)\n",
      "25/06/08 22:42:00 INFO TaskSchedulerImpl: Removed TaskSet 74.0, whose tasks have all completed, from pool \n",
      "25/06/08 22:42:00 INFO DAGScheduler: ShuffleMapStage 74 (show at cmd19.sc:43) finished in 0.817 s\n",
      "25/06/08 22:42:00 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/06/08 22:42:00 INFO DAGScheduler: running: Set()\n",
      "25/06/08 22:42:00 INFO DAGScheduler: waiting: Set()\n",
      "25/06/08 22:42:00 INFO DAGScheduler: failed: Set()\n",
      "25/06/08 22:42:00 INFO ShufflePartitionsUtil: For shuffle(23), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "25/06/08 22:42:00 INFO DAGScheduler: Registering RDD 176 (show at cmd19.sc:43) as input to shuffle 26\n",
      "25/06/08 22:42:00 INFO DAGScheduler: Got map stage job 51 (show at cmd19.sc:43) with 9 output partitions\n",
      "25/06/08 22:42:00 INFO DAGScheduler: Final stage: ShuffleMapStage 79 (show at cmd19.sc:43)\n",
      "25/06/08 22:42:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 78)\n",
      "25/06/08 22:42:00 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/08 22:42:00 INFO DAGScheduler: Submitting ShuffleMapStage 79 (MapPartitionsRDD[176] at show at cmd19.sc:43), which has no missing parents\n",
      "25/06/08 22:42:00 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 31.6 KiB, free 2004.5 MiB)\n",
      "25/06/08 22:42:00 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 15.0 KiB, free 2004.5 MiB)\n",
      "25/06/08 22:42:00 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 192.168.18.245:57344 (size: 15.0 KiB, free: 2004.6 MiB)\n",
      "25/06/08 22:42:00 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1611\n",
      "25/06/08 22:42:00 INFO DAGScheduler: Submitting 9 missing tasks from ShuffleMapStage 79 (MapPartitionsRDD[176] at show at cmd19.sc:43) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8))\n",
      "25/06/08 22:42:00 INFO TaskSchedulerImpl: Adding task set 79.0 with 9 tasks resource profile 0\n",
      "25/06/08 22:42:00 INFO TaskSetManager: Starting task 0.0 in stage 79.0 (TID 69) (192.168.18.245, executor driver, partition 0, NODE_LOCAL, 8988 bytes) \n",
      "25/06/08 22:42:00 INFO TaskSetManager: Starting task 1.0 in stage 79.0 (TID 70) (192.168.18.245, executor driver, partition 1, NODE_LOCAL, 8988 bytes) \n",
      "25/06/08 22:42:00 INFO TaskSetManager: Starting task 2.0 in stage 79.0 (TID 71) (192.168.18.245, executor driver, partition 2, NODE_LOCAL, 8988 bytes) \n",
      "25/06/08 22:42:00 INFO TaskSetManager: Starting task 3.0 in stage 79.0 (TID 72) (192.168.18.245, executor driver, partition 3, NODE_LOCAL, 8988 bytes) \n",
      "25/06/08 22:42:00 INFO TaskSetManager: Starting task 4.0 in stage 79.0 (TID 73) (192.168.18.245, executor driver, partition 4, NODE_LOCAL, 8988 bytes) \n",
      "25/06/08 22:42:00 INFO TaskSetManager: Starting task 5.0 in stage 79.0 (TID 74) (192.168.18.245, executor driver, partition 5, NODE_LOCAL, 8988 bytes) \n",
      "25/06/08 22:42:00 INFO TaskSetManager: Starting task 6.0 in stage 79.0 (TID 75) (192.168.18.245, executor driver, partition 6, NODE_LOCAL, 8988 bytes) \n",
      "25/06/08 22:42:00 INFO TaskSetManager: Starting task 7.0 in stage 79.0 (TID 76) (192.168.18.245, executor driver, partition 7, NODE_LOCAL, 8988 bytes) \n",
      "25/06/08 22:42:00 INFO TaskSetManager: Starting task 8.0 in stage 79.0 (TID 77) (192.168.18.245, executor driver, partition 8, NODE_LOCAL, 8988 bytes) \n",
      "25/06/08 22:42:00 INFO Executor: Running task 1.0 in stage 79.0 (TID 70)\n",
      "25/06/08 22:42:00 INFO Executor: Running task 8.0 in stage 79.0 (TID 77)\n",
      "25/06/08 22:42:00 INFO Executor: Running task 6.0 in stage 79.0 (TID 75)\n",
      "25/06/08 22:42:00 INFO Executor: Running task 2.0 in stage 79.0 (TID 71)\n",
      "25/06/08 22:42:00 INFO Executor: Running task 5.0 in stage 79.0 (TID 74)\n",
      "25/06/08 22:42:00 INFO Executor: Running task 4.0 in stage 79.0 (TID 73)\n",
      "25/06/08 22:42:00 INFO Executor: Running task 3.0 in stage 79.0 (TID 72)\n",
      "25/06/08 22:42:00 INFO Executor: Running task 0.0 in stage 79.0 (TID 69)\n",
      "25/06/08 22:42:00 INFO Executor: Running task 7.0 in stage 79.0 (TID 76)\n",
      "25/06/08 22:42:00 INFO ShuffleBlockFetcherIterator: Getting 1 (1472.7 KiB) non-empty blocks including 1 (1472.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:42:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:42:00 INFO ShuffleBlockFetcherIterator: Getting 1 (1026.7 KiB) non-empty blocks including 1 (1026.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:42:00 INFO ShuffleBlockFetcherIterator: Getting 1 (1045.3 KiB) non-empty blocks including 1 (1045.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:42:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "25/06/08 22:42:00 INFO ShuffleBlockFetcherIterator: Getting 1 (1040.7 KiB) non-empty blocks including 1 (1040.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:42:00 INFO ShuffleBlockFetcherIterator: Getting 1 (1036.0 KiB) non-empty blocks including 1 (1036.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:42:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "25/06/08 22:42:00 INFO ShuffleBlockFetcherIterator: Getting 1 (1068.6 KiB) non-empty blocks including 1 (1068.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:42:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:42:00 INFO ShuffleBlockFetcherIterator: Getting 1 (1026.7 KiB) non-empty blocks including 1 (1026.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:42:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "25/06/08 22:42:00 INFO ShuffleBlockFetcherIterator: Getting 1 (1026.7 KiB) non-empty blocks including 1 (1026.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:42:00 INFO ShuffleBlockFetcherIterator: Getting 1 (1063.9 KiB) non-empty blocks including 1 (1063.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:42:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "25/06/08 22:42:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms\n",
      "25/06/08 22:42:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "25/06/08 22:42:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms\n",
      "25/06/08 22:42:00 INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold\n",
      "25/06/08 22:42:00 INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold\n",
      "25/06/08 22:42:00 INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold\n",
      "25/06/08 22:42:00 INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold\n",
      "25/06/08 22:42:00 INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold\n",
      "25/06/08 22:42:00 INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold\n",
      "25/06/08 22:42:00 INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold\n",
      "25/06/08 22:42:00 INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold\n",
      "25/06/08 22:42:00 INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold\n",
      "25/06/08 22:42:00 INFO CodeGenerator: Code generated in 1.844083 ms\n",
      "25/06/08 22:42:00 INFO CodeGenerator: Code generated in 3.242792 ms\n",
      "25/06/08 22:42:00 INFO CodeGenerator: Code generated in 4.246708 ms\n",
      "25/06/08 22:42:00 INFO CodeGenerator: Code generated in 4.079834 ms\n",
      "25/06/08 22:42:00 INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold\n",
      "25/06/08 22:42:00 INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold\n",
      "25/06/08 22:42:00 INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold\n",
      "25/06/08 22:42:00 INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold\n",
      "25/06/08 22:42:00 INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold\n",
      "25/06/08 22:42:00 INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold\n",
      "25/06/08 22:42:00 INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold\n",
      "25/06/08 22:42:00 INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold\n",
      "25/06/08 22:42:00 INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold\n",
      "25/06/08 22:42:00 INFO CodeGenerator: Code generated in 3.819667 ms\n",
      "25/06/08 22:42:00 INFO CodeGenerator: Code generated in 1.678625 ms\n",
      "25/06/08 22:42:00 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 192.168.18.245:57344 in memory (size: 19.9 KiB, free: 2004.6 MiB)\n",
      "25/06/08 22:42:00 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 192.168.18.245:57344 in memory (size: 12.7 KiB, free: 2004.6 MiB)\n",
      "25/06/08 22:42:00 INFO Executor: Finished task 5.0 in stage 79.0 (TID 74). 5129 bytes result sent to driver\n",
      "25/06/08 22:42:00 INFO TaskSetManager: Finished task 5.0 in stage 79.0 (TID 74) in 300 ms on 192.168.18.245 (executor driver) (1/9)\n",
      "25/06/08 22:42:00 INFO Executor: Finished task 0.0 in stage 79.0 (TID 69). 5129 bytes result sent to driver\n",
      "25/06/08 22:42:00 INFO TaskSetManager: Finished task 0.0 in stage 79.0 (TID 69) in 317 ms on 192.168.18.245 (executor driver) (2/9)\n",
      "25/06/08 22:42:00 INFO Executor: Finished task 6.0 in stage 79.0 (TID 75). 5129 bytes result sent to driver\n",
      "25/06/08 22:42:00 INFO TaskSetManager: Finished task 6.0 in stage 79.0 (TID 75) in 329 ms on 192.168.18.245 (executor driver) (3/9)\n",
      "25/06/08 22:42:00 INFO Executor: Finished task 2.0 in stage 79.0 (TID 71). 5129 bytes result sent to driver\n",
      "25/06/08 22:42:00 INFO Executor: Finished task 3.0 in stage 79.0 (TID 72). 5129 bytes result sent to driver\n",
      "25/06/08 22:42:00 INFO TaskSetManager: Finished task 2.0 in stage 79.0 (TID 71) in 342 ms on 192.168.18.245 (executor driver) (4/9)\n",
      "25/06/08 22:42:00 INFO TaskSetManager: Finished task 3.0 in stage 79.0 (TID 72) in 344 ms on 192.168.18.245 (executor driver) (5/9)\n",
      "25/06/08 22:42:00 INFO Executor: Finished task 4.0 in stage 79.0 (TID 73). 5129 bytes result sent to driver\n",
      "25/06/08 22:42:00 INFO TaskSetManager: Finished task 4.0 in stage 79.0 (TID 73) in 348 ms on 192.168.18.245 (executor driver) (6/9)\n",
      "25/06/08 22:42:00 INFO Executor: Finished task 8.0 in stage 79.0 (TID 77). 5129 bytes result sent to driver\n",
      "25/06/08 22:42:00 INFO TaskSetManager: Finished task 8.0 in stage 79.0 (TID 77) in 355 ms on 192.168.18.245 (executor driver) (7/9)\n",
      "25/06/08 22:42:00 INFO Executor: Finished task 1.0 in stage 79.0 (TID 70). 5129 bytes result sent to driver\n",
      "25/06/08 22:42:00 INFO Executor: Finished task 7.0 in stage 79.0 (TID 76). 5129 bytes result sent to driver\n",
      "25/06/08 22:42:00 INFO TaskSetManager: Finished task 1.0 in stage 79.0 (TID 70) in 363 ms on 192.168.18.245 (executor driver) (8/9)\n",
      "25/06/08 22:42:00 INFO TaskSetManager: Finished task 7.0 in stage 79.0 (TID 76) in 363 ms on 192.168.18.245 (executor driver) (9/9)\n",
      "25/06/08 22:42:00 INFO TaskSchedulerImpl: Removed TaskSet 79.0, whose tasks have all completed, from pool \n",
      "25/06/08 22:42:00 INFO DAGScheduler: ShuffleMapStage 79 (show at cmd19.sc:43) finished in 0.369 s\n",
      "25/06/08 22:42:00 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/06/08 22:42:00 INFO DAGScheduler: running: Set()\n",
      "25/06/08 22:42:00 INFO DAGScheduler: waiting: Set()\n",
      "25/06/08 22:42:00 INFO DAGScheduler: failed: Set()\n",
      "25/06/08 22:42:00 INFO ShufflePartitionsUtil: For shuffle(26, 25), advisory target size: 67108864, actual target size 1876677, minimum partition size: 1048576\n",
      "25/06/08 22:42:00 INFO CodeGenerator: Code generated in 3.362166 ms\n",
      "25/06/08 22:42:00 INFO CodeGenerator: Code generated in 2.886083 ms\n",
      "25/06/08 22:42:00 INFO CodeGenerator: Code generated in 2.622333 ms\n",
      "25/06/08 22:42:00 INFO SparkContext: Starting job: show at cmd19.sc:43\n",
      "25/06/08 22:42:00 INFO DAGScheduler: Got job 52 (show at cmd19.sc:43) with 10 output partitions\n",
      "25/06/08 22:42:00 INFO DAGScheduler: Final stage: ResultStage 84 (show at cmd19.sc:43)\n",
      "25/06/08 22:42:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 81, ShuffleMapStage 83)\n",
      "25/06/08 22:42:00 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/08 22:42:00 INFO DAGScheduler: Submitting ResultStage 84 (MapPartitionsRDD[185] at show at cmd19.sc:43), which has no missing parents\n",
      "25/06/08 22:42:00 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 69.5 KiB, free 2004.5 MiB)\n",
      "25/06/08 22:42:00 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 29.1 KiB, free 2004.5 MiB)\n",
      "25/06/08 22:42:00 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 192.168.18.245:57344 (size: 29.1 KiB, free: 2004.6 MiB)\n",
      "25/06/08 22:42:00 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1611\n",
      "25/06/08 22:42:00 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 84 (MapPartitionsRDD[185] at show at cmd19.sc:43) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))\n",
      "25/06/08 22:42:00 INFO TaskSchedulerImpl: Adding task set 84.0 with 10 tasks resource profile 0\n",
      "25/06/08 22:42:00 INFO TaskSetManager: Starting task 0.0 in stage 84.0 (TID 78) (192.168.18.245, executor driver, partition 0, NODE_LOCAL, 9281 bytes) \n",
      "25/06/08 22:42:00 INFO TaskSetManager: Starting task 1.0 in stage 84.0 (TID 79) (192.168.18.245, executor driver, partition 1, NODE_LOCAL, 9281 bytes) \n",
      "25/06/08 22:42:00 INFO TaskSetManager: Starting task 2.0 in stage 84.0 (TID 80) (192.168.18.245, executor driver, partition 2, NODE_LOCAL, 9281 bytes) \n",
      "25/06/08 22:42:00 INFO TaskSetManager: Starting task 3.0 in stage 84.0 (TID 81) (192.168.18.245, executor driver, partition 3, NODE_LOCAL, 9281 bytes) \n",
      "25/06/08 22:42:00 INFO TaskSetManager: Starting task 4.0 in stage 84.0 (TID 82) (192.168.18.245, executor driver, partition 4, NODE_LOCAL, 9281 bytes) \n",
      "25/06/08 22:42:00 INFO TaskSetManager: Starting task 5.0 in stage 84.0 (TID 83) (192.168.18.245, executor driver, partition 5, NODE_LOCAL, 9281 bytes) \n",
      "25/06/08 22:42:00 INFO TaskSetManager: Starting task 6.0 in stage 84.0 (TID 84) (192.168.18.245, executor driver, partition 6, NODE_LOCAL, 9281 bytes) \n",
      "25/06/08 22:42:00 INFO TaskSetManager: Starting task 7.0 in stage 84.0 (TID 85) (192.168.18.245, executor driver, partition 7, NODE_LOCAL, 9281 bytes) \n",
      "25/06/08 22:42:00 INFO TaskSetManager: Starting task 8.0 in stage 84.0 (TID 86) (192.168.18.245, executor driver, partition 8, NODE_LOCAL, 9281 bytes) \n",
      "25/06/08 22:42:00 INFO TaskSetManager: Starting task 9.0 in stage 84.0 (TID 87) (192.168.18.245, executor driver, partition 9, NODE_LOCAL, 9281 bytes) \n",
      "25/06/08 22:42:00 INFO Executor: Running task 0.0 in stage 84.0 (TID 78)\n",
      "25/06/08 22:42:00 INFO Executor: Running task 6.0 in stage 84.0 (TID 84)\n",
      "25/06/08 22:42:00 INFO Executor: Running task 9.0 in stage 84.0 (TID 87)\n",
      "25/06/08 22:42:00 INFO Executor: Running task 8.0 in stage 84.0 (TID 86)\n",
      "25/06/08 22:42:00 INFO Executor: Running task 5.0 in stage 84.0 (TID 83)\n",
      "25/06/08 22:42:00 INFO Executor: Running task 7.0 in stage 84.0 (TID 85)\n",
      "25/06/08 22:42:00 INFO Executor: Running task 4.0 in stage 84.0 (TID 82)\n",
      "25/06/08 22:42:00 INFO Executor: Running task 3.0 in stage 84.0 (TID 81)\n",
      "25/06/08 22:42:00 INFO Executor: Running task 1.0 in stage 84.0 (TID 79)\n",
      "25/06/08 22:42:00 INFO Executor: Running task 2.0 in stage 84.0 (TID 80)\n",
      "25/06/08 22:42:00 INFO ShuffleBlockFetcherIterator: Getting 9 (879.1 KiB) non-empty blocks including 9 (879.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:42:00 INFO ShuffleBlockFetcherIterator: Getting 9 (878.4 KiB) non-empty blocks including 9 (878.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:42:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:42:00 INFO ShuffleBlockFetcherIterator: Getting 9 (910.1 KiB) non-empty blocks including 9 (910.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:42:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:42:00 INFO ShuffleBlockFetcherIterator: Getting 9 (889.2 KiB) non-empty blocks including 9 (889.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:42:00 INFO ShuffleBlockFetcherIterator: Getting 9 (914.1 KiB) non-empty blocks including 9 (914.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:42:00 INFO ShuffleBlockFetcherIterator: Getting 9 (879.2 KiB) non-empty blocks including 9 (879.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:42:00 INFO ShuffleBlockFetcherIterator: Getting 9 (905.3 KiB) non-empty blocks including 9 (905.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:42:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:42:00 INFO ShuffleBlockFetcherIterator: Getting 9 (902.5 KiB) non-empty blocks including 9 (902.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:42:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:42:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:42:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:42:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:42:00 INFO ShuffleBlockFetcherIterator: Getting 9 (1110.5 KiB) non-empty blocks including 9 (1110.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:42:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "25/06/08 22:42:00 INFO ShuffleBlockFetcherIterator: Getting 9 (893.5 KiB) non-empty blocks including 9 (893.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:42:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "25/06/08 22:42:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms\n",
      "25/06/08 22:42:00 INFO CodeGenerator: Code generated in 3.281667 ms\n",
      "25/06/08 22:42:00 INFO CodeGenerator: Code generated in 2.163417 ms\n",
      "25/06/08 22:42:00 INFO CodeGenerator: Code generated in 1.770958 ms\n",
      "25/06/08 22:42:00 INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold\n",
      "25/06/08 22:42:00 INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold\n",
      "25/06/08 22:42:00 INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold\n",
      "25/06/08 22:42:00 INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold\n",
      "25/06/08 22:42:00 INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold\n",
      "25/06/08 22:42:00 INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold\n",
      "25/06/08 22:42:00 INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold\n",
      "25/06/08 22:42:00 INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold\n",
      "25/06/08 22:42:00 INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold\n",
      "25/06/08 22:42:00 INFO ObjectAggregationIterator: Aggregation hash map size 128 reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold\n",
      "25/06/08 22:42:00 INFO CodeGenerator: Code generated in 6.085959 ms\n",
      "25/06/08 22:42:00 INFO ShuffleBlockFetcherIterator: Getting 9 (895.8 KiB) non-empty blocks including 9 (895.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:42:00 INFO ShuffleBlockFetcherIterator: Getting 9 (1117.0 KiB) non-empty blocks including 9 (1117.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:42:00 INFO ShuffleBlockFetcherIterator: Getting 9 (877.6 KiB) non-empty blocks including 9 (877.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:42:00 INFO ShuffleBlockFetcherIterator: Getting 9 (912.4 KiB) non-empty blocks including 9 (912.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:42:00 INFO ShuffleBlockFetcherIterator: Getting 9 (886.3 KiB) non-empty blocks including 9 (886.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:42:00 INFO ShuffleBlockFetcherIterator: Getting 9 (907.1 KiB) non-empty blocks including 9 (907.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:42:00 INFO ShuffleBlockFetcherIterator: Getting 9 (875.1 KiB) non-empty blocks including 9 (875.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:42:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:42:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:42:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:42:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:42:00 INFO ShuffleBlockFetcherIterator: Getting 9 (920.1 KiB) non-empty blocks including 9 (920.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:42:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:42:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:42:00 INFO ShuffleBlockFetcherIterator: Getting 9 (895.1 KiB) non-empty blocks including 9 (895.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:42:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:42:00 INFO ShuffleBlockFetcherIterator: Getting 9 (878.6 KiB) non-empty blocks including 9 (878.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:42:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:42:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:42:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "25/06/08 22:42:00 INFO CodeGenerator: Code generated in 5.039209 ms\n",
      "25/06/08 22:42:00 INFO CodeGenerator: Code generated in 4.561125 ms\n",
      "25/06/08 22:42:00 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 192.168.18.245:57344 in memory (size: 15.0 KiB, free: 2004.6 MiB)\n",
      "25/06/08 22:42:00 INFO Executor: Finished task 0.0 in stage 84.0 (TID 78). 12355 bytes result sent to driver\n",
      "25/06/08 22:42:00 INFO Executor: Finished task 6.0 in stage 84.0 (TID 84). 12355 bytes result sent to driver\n",
      "25/06/08 22:42:00 INFO Executor: Finished task 1.0 in stage 84.0 (TID 79). 12339 bytes result sent to driver\n",
      "25/06/08 22:42:00 INFO Executor: Finished task 7.0 in stage 84.0 (TID 85). 12240 bytes result sent to driver\n",
      "25/06/08 22:42:00 INFO Executor: Finished task 3.0 in stage 84.0 (TID 81). 12331 bytes result sent to driver\n",
      "25/06/08 22:42:00 INFO TaskSetManager: Finished task 6.0 in stage 84.0 (TID 84) in 367 ms on 192.168.18.245 (executor driver) (1/10)\n",
      "25/06/08 22:42:00 INFO Executor: Finished task 5.0 in stage 84.0 (TID 83). 12288 bytes result sent to driver\n",
      "25/06/08 22:42:00 INFO TaskSetManager: Finished task 7.0 in stage 84.0 (TID 85) in 367 ms on 192.168.18.245 (executor driver) (2/10)\n",
      "25/06/08 22:42:00 INFO TaskSetManager: Finished task 1.0 in stage 84.0 (TID 79) in 372 ms on 192.168.18.245 (executor driver) (3/10)\n",
      "25/06/08 22:42:00 INFO TaskSetManager: Finished task 0.0 in stage 84.0 (TID 78) in 373 ms on 192.168.18.245 (executor driver) (4/10)\n",
      "25/06/08 22:42:00 INFO TaskSetManager: Finished task 3.0 in stage 84.0 (TID 81) in 371 ms on 192.168.18.245 (executor driver) (5/10)\n",
      "25/06/08 22:42:00 INFO TaskSetManager: Finished task 5.0 in stage 84.0 (TID 83) in 370 ms on 192.168.18.245 (executor driver) (6/10)\n",
      "25/06/08 22:42:00 INFO Executor: Finished task 4.0 in stage 84.0 (TID 82). 12355 bytes result sent to driver\n",
      "25/06/08 22:42:00 INFO Executor: Finished task 8.0 in stage 84.0 (TID 86). 12347 bytes result sent to driver\n",
      "25/06/08 22:42:00 INFO TaskSetManager: Finished task 4.0 in stage 84.0 (TID 82) in 374 ms on 192.168.18.245 (executor driver) (7/10)\n",
      "25/06/08 22:42:00 INFO TaskSetManager: Finished task 8.0 in stage 84.0 (TID 86) in 371 ms on 192.168.18.245 (executor driver) (8/10)\n",
      "25/06/08 22:42:00 INFO Executor: Finished task 2.0 in stage 84.0 (TID 80). 12355 bytes result sent to driver\n",
      "25/06/08 22:42:00 INFO Executor: Finished task 9.0 in stage 84.0 (TID 87). 12443 bytes result sent to driver\n",
      "25/06/08 22:42:00 INFO TaskSetManager: Finished task 9.0 in stage 84.0 (TID 87) in 372 ms on 192.168.18.245 (executor driver) (9/10)\n",
      "25/06/08 22:42:00 INFO TaskSetManager: Finished task 2.0 in stage 84.0 (TID 80) in 378 ms on 192.168.18.245 (executor driver) (10/10)\n",
      "25/06/08 22:42:00 INFO TaskSchedulerImpl: Removed TaskSet 84.0, whose tasks have all completed, from pool \n",
      "25/06/08 22:42:00 INFO DAGScheduler: ResultStage 84 (show at cmd19.sc:43) finished in 0.384 s\n",
      "25/06/08 22:42:00 INFO DAGScheduler: Job 52 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/06/08 22:42:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 84: Stage finished\n",
      "25/06/08 22:42:00 INFO DAGScheduler: Job 52 finished: show at cmd19.sc:43, took 0.402682 s\n",
      "25/06/08 22:42:00 INFO CodeGenerator: Code generated in 6.044292 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+--------------------+----------+-------------------+\n",
      "|   cod_contribuyente|num_periodos|            periodos|  distrito|monto_parque_jardin|\n",
      "+--------------------+------------+--------------------+----------+-------------------+\n",
      "|00193f7b6fa1046bd...|           3|  [2023, 2025, 2024]|JESUS MARI|             272.40|\n",
      "|00272324be15fed92...|           3|  [2024, 2023, 2025]|JESUS MARI|             273.00|\n",
      "|002edb71726eeee06...|           3|  [2023, 2025, 2024]|JESUS MARI|             272.40|\n",
      "|00272324be15fed92...|           3|  [2024, 2023, 2025]|JESUS MARI|             282.00|\n",
      "|00058fda87076ff60...|           3|[2024, 2024, 2023...|JESUS MARI|               0.00|\n",
      "|00272324be15fed92...|           3|  [2024, 2023, 2025]|JESUS MARI|             250.92|\n",
      "|0053b08719900f22c...|           3|[2023, 2023, 2024...|JESUS MARI|             272.40|\n",
      "|0046a5cb0241f5c03...|           3|[2025, 2025, 2023...|JESUS MARI|             250.92|\n",
      "|0001d6f5871abfe10...|           3|[2025, 2025, 2023...|JESUS MARI|             282.00|\n",
      "|0046a5cb0241f5c03...|           3|[2025, 2025, 2023...|JESUS MARI|               0.00|\n",
      "+--------------------+------------+--------------------+----------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "📊 JOIN 3 - Comparación entre períodos 2024-2025:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/08 22:42:00 INFO CodeGenerator: Code generated in 1.992959 ms\n",
      "25/06/08 22:42:00 INFO DAGScheduler: Registering RDD 189 (show at cmd19.sc:70) as input to shuffle 27\n",
      "25/06/08 22:42:00 INFO DAGScheduler: Got map stage job 53 (show at cmd19.sc:70) with 1 output partitions\n",
      "25/06/08 22:42:00 INFO DAGScheduler: Final stage: ShuffleMapStage 85 (show at cmd19.sc:70)\n",
      "25/06/08 22:42:00 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/06/08 22:42:00 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/08 22:42:00 INFO DAGScheduler: Submitting ShuffleMapStage 85 (MapPartitionsRDD[189] at show at cmd19.sc:70), which has no missing parents\n",
      "25/06/08 22:42:00 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 15.9 KiB, free 2004.5 MiB)\n",
      "25/06/08 22:42:00 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 8.1 KiB, free 2004.5 MiB)\n",
      "25/06/08 22:42:00 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 192.168.18.245:57344 (size: 8.1 KiB, free: 2004.6 MiB)\n",
      "25/06/08 22:42:00 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1611\n",
      "25/06/08 22:42:00 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 85 (MapPartitionsRDD[189] at show at cmd19.sc:70) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/08 22:42:00 INFO TaskSchedulerImpl: Adding task set 85.0 with 1 tasks resource profile 0\n",
      "25/06/08 22:42:00 INFO TaskSetManager: Starting task 0.0 in stage 85.0 (TID 88) (192.168.18.245, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) \n",
      "25/06/08 22:42:00 INFO Executor: Running task 0.0 in stage 85.0 (TID 88)\n",
      "25/06/08 22:42:00 INFO CodeGenerator: Code generated in 3.731708 ms\n",
      "25/06/08 22:42:01 INFO DAGScheduler: Registering RDD 191 (show at cmd19.sc:70) as input to shuffle 28\n",
      "25/06/08 22:42:01 INFO DAGScheduler: Got map stage job 54 (show at cmd19.sc:70) with 1 output partitions\n",
      "25/06/08 22:42:01 INFO DAGScheduler: Final stage: ShuffleMapStage 86 (show at cmd19.sc:70)\n",
      "25/06/08 22:42:01 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/06/08 22:42:01 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/08 22:42:01 INFO DAGScheduler: Submitting ShuffleMapStage 86 (MapPartitionsRDD[191] at show at cmd19.sc:70), which has no missing parents\n",
      "25/06/08 22:42:01 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 15.9 KiB, free 2004.5 MiB)\n",
      "25/06/08 22:42:01 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 8.1 KiB, free 2004.5 MiB)\n",
      "25/06/08 22:42:01 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 192.168.18.245:57344 (size: 8.1 KiB, free: 2004.6 MiB)\n",
      "25/06/08 22:42:01 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1611\n",
      "25/06/08 22:42:01 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 86 (MapPartitionsRDD[191] at show at cmd19.sc:70) (first 15 tasks are for partitions Vector(0))\n",
      "25/06/08 22:42:01 INFO TaskSchedulerImpl: Adding task set 86.0 with 1 tasks resource profile 0\n",
      "25/06/08 22:42:01 INFO TaskSetManager: Starting task 0.0 in stage 86.0 (TID 89) (192.168.18.245, executor driver, partition 0, PROCESS_LOCAL, 8834 bytes) \n",
      "25/06/08 22:42:01 INFO Executor: Running task 0.0 in stage 86.0 (TID 89)\n",
      "25/06/08 22:42:01 INFO CodeGenerator: Code generated in 2.62025 ms\n",
      "25/06/08 22:42:01 INFO JDBCRDD: closed connection\n",
      "25/06/08 22:42:01 INFO JDBCRDD: closed connection\n",
      "25/06/08 22:42:01 INFO Executor: Finished task 0.0 in stage 85.0 (TID 88). 1948 bytes result sent to driver\n",
      "25/06/08 22:42:01 INFO TaskSetManager: Finished task 0.0 in stage 85.0 (TID 88) in 174 ms on 192.168.18.245 (executor driver) (1/1)\n",
      "25/06/08 22:42:01 INFO TaskSchedulerImpl: Removed TaskSet 85.0, whose tasks have all completed, from pool \n",
      "25/06/08 22:42:01 INFO DAGScheduler: ShuffleMapStage 85 (show at cmd19.sc:70) finished in 0.177 s\n",
      "25/06/08 22:42:01 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/06/08 22:42:01 INFO DAGScheduler: running: Set(ShuffleMapStage 86)\n",
      "25/06/08 22:42:01 INFO DAGScheduler: waiting: Set()\n",
      "25/06/08 22:42:01 INFO DAGScheduler: failed: Set()\n",
      "25/06/08 22:42:01 INFO ShufflePartitionsUtil: For shuffle(27), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "25/06/08 22:42:01 INFO Executor: Finished task 0.0 in stage 86.0 (TID 89). 1948 bytes result sent to driver\n",
      "25/06/08 22:42:01 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266\n",
      "25/06/08 22:42:01 INFO TaskSetManager: Finished task 0.0 in stage 86.0 (TID 89) in 146 ms on 192.168.18.245 (executor driver) (1/1)\n",
      "25/06/08 22:42:01 INFO TaskSchedulerImpl: Removed TaskSet 86.0, whose tasks have all completed, from pool \n",
      "25/06/08 22:42:01 INFO DAGScheduler: ShuffleMapStage 86 (show at cmd19.sc:70) finished in 0.182 s\n",
      "25/06/08 22:42:01 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/06/08 22:42:01 INFO DAGScheduler: running: Set()\n",
      "25/06/08 22:42:01 INFO DAGScheduler: waiting: Set()\n",
      "25/06/08 22:42:01 INFO DAGScheduler: failed: Set()\n",
      "25/06/08 22:42:01 INFO DAGScheduler: Got job 55 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 3 output partitions\n",
      "25/06/08 22:42:01 INFO DAGScheduler: Final stage: ResultStage 88 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)\n",
      "25/06/08 22:42:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 87)\n",
      "25/06/08 22:42:01 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/08 22:42:01 INFO DAGScheduler: Submitting ResultStage 88 (MapPartitionsRDD[193] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents\n",
      "25/06/08 22:42:01 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 8.3 KiB, free 2004.4 MiB)\n",
      "25/06/08 22:42:01 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 2004.4 MiB)\n",
      "25/06/08 22:42:01 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 192.168.18.245:57344 (size: 4.2 KiB, free: 2004.6 MiB)\n",
      "25/06/08 22:42:01 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1611\n",
      "25/06/08 22:42:01 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 88 (MapPartitionsRDD[193] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0, 1, 2))\n",
      "25/06/08 22:42:01 INFO TaskSchedulerImpl: Adding task set 88.0 with 3 tasks resource profile 0\n",
      "25/06/08 22:42:01 INFO TaskSetManager: Starting task 0.0 in stage 88.0 (TID 90) (192.168.18.245, executor driver, partition 0, NODE_LOCAL, 9018 bytes) \n",
      "25/06/08 22:42:01 INFO TaskSetManager: Starting task 1.0 in stage 88.0 (TID 91) (192.168.18.245, executor driver, partition 1, NODE_LOCAL, 9018 bytes) \n",
      "25/06/08 22:42:01 INFO TaskSetManager: Starting task 2.0 in stage 88.0 (TID 92) (192.168.18.245, executor driver, partition 2, NODE_LOCAL, 9018 bytes) \n",
      "25/06/08 22:42:01 INFO Executor: Running task 1.0 in stage 88.0 (TID 91)\n",
      "25/06/08 22:42:01 INFO Executor: Running task 2.0 in stage 88.0 (TID 92)\n",
      "25/06/08 22:42:01 INFO Executor: Running task 0.0 in stage 88.0 (TID 90)\n",
      "25/06/08 22:42:01 INFO ShuffleBlockFetcherIterator: Getting 1 (1034.0 KiB) non-empty blocks including 1 (1034.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:42:01 INFO ShuffleBlockFetcherIterator: Getting 1 (1021.4 KiB) non-empty blocks including 1 (1021.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:42:01 INFO ShuffleBlockFetcherIterator: Getting 1 (1041.0 KiB) non-empty blocks including 1 (1041.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:42:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:42:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:42:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:42:01 INFO Executor: Finished task 2.0 in stage 88.0 (TID 92). 1001874 bytes result sent to driver\n",
      "25/06/08 22:42:01 INFO Executor: Finished task 1.0 in stage 88.0 (TID 91). 1024244 bytes result sent to driver\n",
      "25/06/08 22:42:01 INFO TaskSetManager: Finished task 1.0 in stage 88.0 (TID 91) in 15 ms on 192.168.18.245 (executor driver) (1/3)\n",
      "25/06/08 22:42:01 INFO TaskSetManager: Finished task 2.0 in stage 88.0 (TID 92) in 16 ms on 192.168.18.245 (executor driver) (2/3)\n",
      "25/06/08 22:42:01 INFO Executor: Finished task 0.0 in stage 88.0 (TID 90). 1019346 bytes result sent to driver\n",
      "25/06/08 22:42:01 INFO TaskSetManager: Finished task 0.0 in stage 88.0 (TID 90) in 17 ms on 192.168.18.245 (executor driver) (3/3)\n",
      "25/06/08 22:42:01 INFO TaskSchedulerImpl: Removed TaskSet 88.0, whose tasks have all completed, from pool \n",
      "25/06/08 22:42:01 INFO DAGScheduler: ResultStage 88 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.021 s\n",
      "25/06/08 22:42:01 INFO DAGScheduler: Job 55 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/06/08 22:42:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 88: Stage finished\n",
      "25/06/08 22:42:01 INFO DAGScheduler: Job 55 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.023991 s\n",
      "25/06/08 22:42:01 INFO CodeGenerator: Code generated in 2.6765 ms\n",
      "25/06/08 22:42:01 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 26.0 MiB, free 1978.4 MiB)\n",
      "25/06/08 22:42:01 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 3.5 MiB, free 1974.9 MiB)\n",
      "25/06/08 22:42:01 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 192.168.18.245:57344 (size: 3.5 MiB, free: 2001.0 MiB)\n",
      "25/06/08 22:42:01 INFO SparkContext: Created broadcast 57 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266\n",
      "25/06/08 22:42:01 INFO ShufflePartitionsUtil: For shuffle(28), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "25/06/08 22:42:01 INFO CodeGenerator: Code generated in 4.138208 ms\n",
      "25/06/08 22:42:01 INFO CodeGenerator: Code generated in 3.309833 ms\n",
      "25/06/08 22:42:01 INFO SparkContext: Starting job: show at cmd19.sc:70\n",
      "25/06/08 22:42:01 INFO DAGScheduler: Got job 56 (show at cmd19.sc:70) with 3 output partitions\n",
      "25/06/08 22:42:01 INFO DAGScheduler: Final stage: ResultStage 90 (show at cmd19.sc:70)\n",
      "25/06/08 22:42:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 89)\n",
      "25/06/08 22:42:01 INFO DAGScheduler: Missing parents: List()\n",
      "25/06/08 22:42:01 INFO DAGScheduler: Submitting ResultStage 90 (MapPartitionsRDD[197] at show at cmd19.sc:70), which has no missing parents\n",
      "25/06/08 22:42:01 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 17.9 KiB, free 1974.9 MiB)\n",
      "25/06/08 22:42:01 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 8.0 KiB, free 1974.9 MiB)\n",
      "25/06/08 22:42:01 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 192.168.18.245:57344 (size: 8.0 KiB, free: 2001.0 MiB)\n",
      "25/06/08 22:42:01 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1611\n",
      "25/06/08 22:42:01 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 90 (MapPartitionsRDD[197] at show at cmd19.sc:70) (first 15 tasks are for partitions Vector(0, 1, 2))\n",
      "25/06/08 22:42:01 INFO TaskSchedulerImpl: Adding task set 90.0 with 3 tasks resource profile 0\n",
      "25/06/08 22:42:01 INFO TaskSetManager: Starting task 0.0 in stage 90.0 (TID 93) (192.168.18.245, executor driver, partition 0, NODE_LOCAL, 9018 bytes) \n",
      "25/06/08 22:42:01 INFO TaskSetManager: Starting task 1.0 in stage 90.0 (TID 94) (192.168.18.245, executor driver, partition 1, NODE_LOCAL, 9018 bytes) \n",
      "25/06/08 22:42:01 INFO TaskSetManager: Starting task 2.0 in stage 90.0 (TID 95) (192.168.18.245, executor driver, partition 2, NODE_LOCAL, 9018 bytes) \n",
      "25/06/08 22:42:01 INFO Executor: Running task 0.0 in stage 90.0 (TID 93)\n",
      "25/06/08 22:42:01 INFO Executor: Running task 1.0 in stage 90.0 (TID 94)\n",
      "25/06/08 22:42:01 INFO Executor: Running task 2.0 in stage 90.0 (TID 95)\n",
      "25/06/08 22:42:01 INFO CodeGenerator: Code generated in 4.267583 ms\n",
      "25/06/08 22:42:01 INFO ShuffleBlockFetcherIterator: Getting 1 (1090.8 KiB) non-empty blocks including 1 (1090.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:42:01 INFO ShuffleBlockFetcherIterator: Getting 1 (1076.3 KiB) non-empty blocks including 1 (1076.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:42:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:42:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:42:01 INFO ShuffleBlockFetcherIterator: Getting 1 (1092.3 KiB) non-empty blocks including 1 (1092.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/06/08 22:42:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/06/08 22:42:01 INFO CodeGenerator: Code generated in 3.994958 ms\n",
      "25/06/08 22:42:01 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 192.168.18.245:57344 in memory (size: 4.2 KiB, free: 2001.0 MiB)\n",
      "25/06/08 22:42:01 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 192.168.18.245:57344 in memory (size: 8.1 KiB, free: 2001.0 MiB)\n",
      "25/06/08 22:42:01 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 192.168.18.245:57344 in memory (size: 8.1 KiB, free: 2001.0 MiB)\n",
      "25/06/08 22:42:01 INFO Executor: Finished task 2.0 in stage 90.0 (TID 95). 6611 bytes result sent to driver\n",
      "25/06/08 22:42:01 INFO TaskSetManager: Finished task 2.0 in stage 90.0 (TID 95) in 75 ms on 192.168.18.245 (executor driver) (1/3)\n",
      "25/06/08 22:42:01 INFO Executor: Finished task 1.0 in stage 90.0 (TID 94). 6611 bytes result sent to driver\n",
      "25/06/08 22:42:01 INFO TaskSetManager: Finished task 1.0 in stage 90.0 (TID 94) in 87 ms on 192.168.18.245 (executor driver) (2/3)\n",
      "25/06/08 22:42:01 INFO Executor: Finished task 0.0 in stage 90.0 (TID 93). 6611 bytes result sent to driver\n",
      "25/06/08 22:42:01 INFO TaskSetManager: Finished task 0.0 in stage 90.0 (TID 93) in 92 ms on 192.168.18.245 (executor driver) (3/3)\n",
      "25/06/08 22:42:01 INFO TaskSchedulerImpl: Removed TaskSet 90.0, whose tasks have all completed, from pool \n",
      "25/06/08 22:42:01 INFO DAGScheduler: ResultStage 90 (show at cmd19.sc:70) finished in 0.094 s\n",
      "25/06/08 22:42:01 INFO DAGScheduler: Job 56 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/06/08 22:42:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 90: Stage finished\n",
      "25/06/08 22:42:01 INFO DAGScheduler: Job 56 finished: show at cmd19.sc:70, took 0.096154 s\n",
      "25/06/08 22:42:01 INFO CodeGenerator: Code generated in 2.586792 ms\n",
      "25/06/08 22:42:01 INFO CodeGenerator: Code generated in 2.026833 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+----------+--------------------+-------------+----------+---------------+\n",
      "|  contribuyente_2024|distrito_2024|monto_2024|  contribuyente_2025|distrito_2025|monto_2025|variacion_monto|\n",
      "+--------------------+-------------+----------+--------------------+-------------+----------+---------------+\n",
      "|61dfe35d8fa6fc29d...|   JESUS MARI|    331.56|61dfe35d8fa6fc29d...|   JESUS MARI|   26716.8|       26385.24|\n",
      "|61dfe35d8fa6fc29d...|   JESUS MARI|    331.56|61dfe35d8fa6fc29d...|   JESUS MARI|   26716.8|       26385.24|\n",
      "|61dfe35d8fa6fc29d...|   JESUS MARI|    331.56|61dfe35d8fa6fc29d...|   JESUS MARI|   26716.8|       26385.24|\n",
      "|61dfe35d8fa6fc29d...|   JESUS MARI|    331.56|61dfe35d8fa6fc29d...|   JESUS MARI|   26716.8|       26385.24|\n",
      "|8b23a5f47f37eaa52...|   JESUS MARI|    915.48|8b23a5f47f37eaa52...|   JESUS MARI|   26716.8|       25801.32|\n",
      "|8b23a5f47f37eaa52...|   JESUS MARI|    915.48|8b23a5f47f37eaa52...|   JESUS MARI|   26716.8|       25801.32|\n",
      "|8b23a5f47f37eaa52...|   JESUS MARI|    915.48|8b23a5f47f37eaa52...|   JESUS MARI|   26716.8|       25801.32|\n",
      "|8b23a5f47f37eaa52...|   JESUS MARI|    915.48|8b23a5f47f37eaa52...|   JESUS MARI|   26716.8|       25801.32|\n",
      "|8b23a5f47f37eaa52...|   JESUS MARI|    915.48|8b23a5f47f37eaa52...|   JESUS MARI|   26716.8|       25801.32|\n",
      "|8b23a5f47f37eaa52...|   JESUS MARI|    915.48|8b23a5f47f37eaa52...|   JESUS MARI|   26716.8|       25801.32|\n",
      "+--------------------+-------------+----------+--------------------+-------------+----------+---------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mtotalPorContribuyente\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mDataset\u001b[39m[\u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mRow\u001b[39m] = [cod_contribuyente: string, distrito: string ... 2 more fields]\n",
       "\u001b[36mpromedioDistrito\u001b[39m: \u001b[32mDataFrame\u001b[39m = [distrito: string, promedio_distrito_serenazgo: double]\n",
       "\u001b[36mjoin1\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mDataset\u001b[39m[\u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mRow\u001b[39m] = [distrito: string, cod_contribuyente: string ... 4 more fields]\n",
       "\u001b[36mcontribuyentesPeriodos\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mDataset\u001b[39m[\u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mRow\u001b[39m] = [cod_contribuyente: string, num_periodos: bigint ... 1 more field]\n",
       "\u001b[36mdatosContribuyente\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mDataset\u001b[39m[\u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mRow\u001b[39m] = [cod_contribuyente: string, distrito: string ... 1 more field]\n",
       "\u001b[36mjoin2\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mDataset\u001b[39m[\u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mRow\u001b[39m] = [cod_contribuyente: string, num_periodos: bigint ... 3 more fields]\n",
       "\u001b[36mperiodo2024\u001b[39m: \u001b[32mDataFrame\u001b[39m = [contribuyente_2024: string, distrito_2024: string ... 1 more field]\n",
       "\u001b[36mperiodo2025\u001b[39m: \u001b[32mDataFrame\u001b[39m = [contribuyente_2025: string, distrito_2025: string ... 1 more field]\n",
       "\u001b[36mjoin3\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mDataset\u001b[39m[\u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mRow\u001b[39m] = [contribuyente_2024: string, distrito_2024: string ... 5 more fields]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// 6. TRES CONSULTAS CON JOIN\n",
    "println(\"🔗 6. TRES CONSULTAS CON JOIN\")\n",
    "\n",
    "// Crear DataFrames derivados para hacer JOIN\n",
    "// JOIN 1: Unir contribuyentes con sus totales por distrito\n",
    "val totalPorContribuyente = df.groupBy(\"cod_contribuyente\", \"distrito\")\n",
    "  .agg(\n",
    "    sum(col(\"monto_serenazgo\").cast(\"double\")).as(\"total_serenazgo\"),\n",
    "    count(\"*\").as(\"num_predios\")\n",
    "  )\n",
    "  .filter(col(\"num_predios\") > 1)\n",
    "\n",
    "val promedioDistrito = df.groupBy(\"distrito\")\n",
    "  .agg(\n",
    "    avg(col(\"monto_serenazgo\").cast(\"double\")).as(\"promedio_distrito_serenazgo\")\n",
    "  )\n",
    "\n",
    "val join1 = totalPorContribuyente\n",
    "  .join(promedioDistrito, Seq(\"distrito\"), \"inner\")\n",
    "  .withColumn(\"diferencia_promedio\", \n",
    "              round(col(\"total_serenazgo\") - col(\"promedio_distrito_serenazgo\"), 2))\n",
    "  .orderBy(desc(\"diferencia_promedio\"))\n",
    "\n",
    "println(\"📊 JOIN 1 - Contribuyentes vs Promedio de distrito:\")\n",
    "join1.show(10)\n",
    "\n",
    "// JOIN 2: Contribuyentes con múltiples períodos\n",
    "val contribuyentesPeriodos = df.groupBy(\"cod_contribuyente\")\n",
    "  .agg(\n",
    "    countDistinct(\"periodo\").as(\"num_periodos\"),\n",
    "    collect_list(\"periodo\").as(\"periodos\")\n",
    "  )\n",
    "  .filter(col(\"num_periodos\") > 1)\n",
    "\n",
    "val datosContribuyente = df.select(\"cod_contribuyente\", \"distrito\", \"monto_parque_jardin\")\n",
    "  .distinct()\n",
    "\n",
    "val join2 = contribuyentesPeriodos\n",
    "  .join(datosContribuyente, Seq(\"cod_contribuyente\"), \"inner\")\n",
    "  .orderBy(desc(\"num_periodos\"))\n",
    "\n",
    "println(\"📊 JOIN 2 - Contribuyentes con múltiples períodos:\")\n",
    "join2.show(10)\n",
    "\n",
    "// JOIN 3: Self-join para comparar períodos\n",
    "val periodo2024 = df.filter(col(\"periodo\") === \"2024\")\n",
    "  .select(\n",
    "    col(\"cod_contribuyente\").as(\"contribuyente_2024\"),\n",
    "    col(\"distrito\").as(\"distrito_2024\"),\n",
    "    col(\"monto_serenazgo\").cast(\"double\").as(\"monto_2024\")\n",
    "  )\n",
    "\n",
    "val periodo2025 = df.filter(col(\"periodo\") === \"2025\")\n",
    "  .select(\n",
    "    col(\"cod_contribuyente\").as(\"contribuyente_2025\"),\n",
    "    col(\"distrito\").as(\"distrito_2025\"),\n",
    "    col(\"monto_serenazgo\").cast(\"double\").as(\"monto_2025\")\n",
    "  )\n",
    "\n",
    "val join3 = periodo2024\n",
    "  .join(periodo2025, \n",
    "        col(\"contribuyente_2024\") === col(\"contribuyente_2025\") && \n",
    "        col(\"distrito_2024\") === col(\"distrito_2025\"), \n",
    "        \"inner\")\n",
    "  .withColumn(\"variacion_monto\", \n",
    "              round(col(\"monto_2025\") - col(\"monto_2024\"), 2))\n",
    "  .orderBy(desc(\"variacion_monto\"))\n",
    "\n",
    "println(\"📊 JOIN 3 - Comparación entre períodos 2024-2025:\")\n",
    "join3.show(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
